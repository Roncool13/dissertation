{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ae6d8e37",
      "metadata": {},
      "source": [
        "# Fusion Meta-Model (TCS 2021–2023, Sentiment-Gated)\n",
        "\n",
        "**Purpose.** Build and evaluate the single-symbol (TCS) fusion expert that stacks OHLCV, sentiment (lag-1 gated), and pattern models for the 2021–2023 horizon. The notebook recreates the same preprocessing used in production so that the meta learner can be re-run or audited without touching the larger orchestration code.\n",
        "\n",
        "**What this covers.**\n",
        "- Restores repo + DVC state, including the metadata that defines split boundaries and label semantics.\n",
        "- Loads the latest registered base experts from MLflow and generates leakage-safe OOF probabilities for the train period, plus gated predictions for validation/test.\n",
        "- Performs a grid search over logistic-regression meta parameters, selects via validation ROC-AUC, and evaluates the champion on both validation and holdout data.\n",
        "- Logs lineage artifacts, ROC metrics, and the frozen fusion model to `dissertation-fusion-prediction`, then registers the run for downstream consumption.\n",
        "\n",
        "**Artifacts emitted.** `meta_val_candidate_ranking.csv`, MLflow tags linking git+DVC hashes, and a registered model named `fusion_meta_lr_tcs_2021_2023_sent_lag_1_gated`.\n",
        "\n",
        "Run the cells sequentially (Colab friendly). If any dependency step fails, rerun from that cell to ensure consistent lineage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9f5f0c2",
      "metadata": {
        "id": "b9f5f0c2"
      },
      "source": [
        "## 0) Prerequisites: Pip Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1d57d86a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d57d86a",
        "outputId": "fa9e4c9d-f2ad-416d-d308-4da9c0ada49d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.3/261.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.3/113.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.5/445.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.2/214.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.1/74.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.7/469.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.3/788.3 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2026.1.0 which is incompatible.\n",
            "google-adk 1.21.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install deps (Colab)\n",
        "!pip -q install feast==0.58.0 s3fs boto3 pyarrow pandas scikit-learn \"mlflow>=2.12,<3\" \"dagshub==0.6.4\" \"dvc[s3]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acccc19d",
      "metadata": {
        "id": "acccc19d"
      },
      "source": [
        "## 1) Credentials / Environment\n",
        "Set these using Colab `userdata` (or replace with your own method)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6d13c401",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d13c401",
        "outputId": "5977cc53-7677-4c4c-d290-fe39e99fc10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Secrets loaded: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION, DAGSHUB_USER_TOKEN\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# AWS\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "os.environ['AWS_DEFAULT_REGION'] = userdata.get('AWS_DEFAULT_REGION') or 'us-east-1'\n",
        "\n",
        "# MLflow (DAGsHub)\n",
        "os.environ[\"DAGSHUB_USER_TOKEN\"] = userdata.get('DAGSHUB_TOKEN')\n",
        "\n",
        "missing = [k for k in ['AWS_ACCESS_KEY_ID','AWS_SECRET_ACCESS_KEY','DAGSHUB_USER_TOKEN'] if not os.environ.get(k)]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing secrets in Colab userdata: {missing}\")\n",
        "print('Secrets loaded:', ', '.join(['AWS_ACCESS_KEY_ID','AWS_SECRET_ACCESS_KEY','AWS_DEFAULT_REGION','DAGSHUB_USER_TOKEN']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63d74ac",
      "metadata": {
        "id": "d63d74ac"
      },
      "source": [
        "## 2) Setup + DVC pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b2a67d03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2a67d03",
        "outputId": "d7014d25-58dd-44d9-e003-abaff10787ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'dissertation'...\n",
            "remote: Enumerating objects: 815, done.\u001b[K\n",
            "remote: Counting objects: 100% (345/345), done.\u001b[K\n",
            "remote: Compressing objects: 100% (206/206), done.\u001b[K\n",
            "Receiving objects: 100% (815/815), 275.04 KiB | 7.86 MiB/s, done.\n",
            "remote: Total 815 (delta 196), reused 262 (delta 118), pack-reused 470 (from 1)\u001b[K\n",
            "Resolving deltas: 100% (493/493), done.\n",
            "/content/dissertation\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "\u001b[0mDVC pull done ✅\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "REPO_NAME = \"dissertation\"  # change if needed\n",
        "REPO_URL = f\"https://github.com/Roncool13/{REPO_NAME}.git\"\n",
        "BRANCH_OR_COMMIT = \"main\"  # or a specific commit hash for perfect reproducibility\n",
        "\n",
        "if not Path(REPO_NAME).exists():\n",
        "    !git clone {REPO_URL}\n",
        "%cd {REPO_NAME}\n",
        "!git checkout {BRANCH_OR_COMMIT}\n",
        "!git status\n",
        "\n",
        "!dvc pull -q\n",
        "print(\"DVC pull done ✅\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd53cb3",
      "metadata": {
        "id": "1fd53cb3"
      },
      "source": [
        "## 3) MLflow Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fc1ac095",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "id": "fc1ac095",
        "outputId": "bdbe4ca2-1a1b-409b-f32b-607925a81602"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Roncool13\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as Roncool13\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Roncool13/dissertation-mlflow\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"Roncool13/dissertation-mlflow\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Roncool13/dissertation-mlflow initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository Roncool13/dissertation-mlflow initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow tracking URI: https://dagshub.com/Roncool13/dissertation-mlflow.mlflow\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import dagshub\n",
        "\n",
        "dagshub.init(repo_owner='Roncool13', repo_name='dissertation-mlflow', mlflow=True)\n",
        "mlflow.set_experiment(\"dissertation-fusion-prediction\")\n",
        "mlflow.sklearn.autolog(disable=True)\n",
        "\n",
        "print('MLflow tracking URI:', mlflow.get_tracking_uri())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce07e899",
      "metadata": {
        "id": "ce07e899"
      },
      "source": [
        "## 4) Load datasets + metadata + label name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "bfefd9f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfefd9f7",
        "outputId": "ab9a547c-3745-4795-ae09-62fec9ef2478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using label: y_up_5d\n"
          ]
        }
      ],
      "source": [
        "meta_ohlcv = json.loads(Path(f\"data/features/ohlcv_feature_metadata.json\").read_text())\n",
        "horizon_days = int(meta_ohlcv.get(\"horizon_days\", 5))\n",
        "label_col = f\"y_up_{horizon_days}d\"\n",
        "\n",
        "ohlcv = pd.read_parquet(\"data/features/ohlcv_features.parquet\")\n",
        "sent  = pd.read_parquet(\"data/features/news_sentiment_features.parquet\")\n",
        "pat   = pd.read_parquet(\"data/features/pattern_features.parquet\")\n",
        "news_meta = json.loads(Path(\"data/features/news_sentiment_feature_metadata.json\").read_text())\n",
        "\n",
        "for df in (ohlcv, sent, pat):\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "\n",
        "assert label_col in ohlcv.columns, f\"{label_col} not found in ohlcv_features\"\n",
        "print(\"Using label:\", label_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1e8542",
      "metadata": {
        "id": "4b1e8542"
      },
      "source": [
        "## 5) Build X columns for each expert"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74e020e4",
      "metadata": {
        "id": "74e020e4"
      },
      "source": [
        "### 5.1) OHLCV X columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "70231291",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70231291",
        "outputId": "8841aac7-1f3e-414b-f427-6b9c697683da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OHLCV feature count: 85\n"
          ]
        }
      ],
      "source": [
        "# Exclude forward-looking columns to prevent leakage (matches your OHLCV notebook idea)\n",
        "exclude_prefixes = (\"close_fwd_\", \"ret_fwd_\")\n",
        "exclude_cols = {\"symbol\", \"date\", label_col}\n",
        "\n",
        "ohlcv_X_cols = [\n",
        "    c for c in ohlcv.columns\n",
        "    if c not in exclude_cols and not c.startswith(exclude_prefixes)\n",
        "]\n",
        "print(\"OHLCV feature count:\", len(ohlcv_X_cols))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-HsDRfYQnP2M",
      "metadata": {
        "id": "-HsDRfYQnP2M"
      },
      "source": [
        "### 5.2) Sentiment X columns (Building Gated Sentiment for 1 day lag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "iYs2dy29ny91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYs2dy29ny91",
        "outputId": "2c8d528d-92dc-4875-aec2-2ccc6174cd8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OHLCV feature count: 127\n"
          ]
        }
      ],
      "source": [
        "label_col = news_meta[\"supervision\"][\"label_col_name\"]\n",
        "sent_X_cols = [c for c in sent.columns if c not in {\"symbol\",\"date\", label_col}]\n",
        "print(\"OHLCV feature count:\", len(sent_X_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "ShAOWChNlkB-",
      "metadata": {
        "id": "ShAOWChNlkB-"
      },
      "outputs": [],
      "source": [
        "# All trading days (ground truth timeline)\n",
        "calendar = (\n",
        "    ohlcv[[\"symbol\", \"date\"]]\n",
        "    .drop_duplicates()\n",
        "    .sort_values([\"symbol\", \"date\"])\n",
        "    .reset_index(drop=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "cmUbSWfclz-g",
      "metadata": {
        "id": "cmUbSWfclz-g"
      },
      "outputs": [],
      "source": [
        "sent_full = calendar.merge(\n",
        "    sent,\n",
        "    on=[\"symbol\", \"date\"],\n",
        "    how=\"left\",\n",
        "    suffixes=(\"\", \"_sent\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "ITz2J5fql36E",
      "metadata": {
        "id": "ITz2J5fql36E"
      },
      "outputs": [],
      "source": [
        "# Binary gate\n",
        "sent_full[\"news_present\"] = sent_full[\"news_present\"].fillna(0.0)\n",
        "\n",
        "# Counts & intensities → 0 when no news\n",
        "zero_cols = [\n",
        "    \"article_count\", \"pos_count\", \"neg_count\", \"neu_count\",\n",
        "    \"highrel_count\", \"sent_cov\", \"sent_abs\",\n",
        "    \"highrel_impact\", \"imbalance\"\n",
        "]\n",
        "\n",
        "ratio_cols = [\n",
        "    \"pos_ratio\", \"neg_ratio\", \"neu_ratio\", \"highrel_ratio\"\n",
        "]\n",
        "\n",
        "polarity_cols = [\n",
        "    \"polarity_mean\", \"polarity_std\",\n",
        "    \"polarity_wmean\",\n",
        "    \"highrel_polarity_mean\",\n",
        "    \"highrel_polarity_wmean\"\n",
        "]\n",
        "\n",
        "for c in zero_cols + ratio_cols + polarity_cols:\n",
        "    if c in sent_full.columns:\n",
        "        sent_full[c] = sent_full[c].fillna(0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "A-uYO-xVl7BB",
      "metadata": {
        "id": "A-uYO-xVl7BB"
      },
      "outputs": [],
      "source": [
        "sent = sent_full.sort_values([\"symbol\", \"date\"])\n",
        "\n",
        "base_cols = [\n",
        "    \"article_count\", \"pos_ratio\", \"neg_ratio\", \"neu_ratio\",\n",
        "    \"highrel_ratio\", \"polarity_wmean\", \"sent_cov\",\n",
        "    \"imbalance\", \"news_present\"\n",
        "]\n",
        "\n",
        "for lag in range(1, 6):\n",
        "    for col in base_cols:\n",
        "        sent[f\"{col}_lag_{lag}\"] = (\n",
        "            sent.groupby(\"symbol\")[col].shift(lag)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3dad760",
      "metadata": {
        "id": "b3dad760"
      },
      "source": [
        "### 5.3) Pattern X columns (+ shift by 1 day)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "ad88a3c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad88a3c8",
        "outputId": "c89dcc1c-3b3d-416b-b63d-c0dc0091b870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pattern feature count: 17\n"
          ]
        }
      ],
      "source": [
        "pat_exclude = {\"symbol\", \"date\"}\n",
        "pat_X_cols = [c for c in pat.columns if c not in pat_exclude]\n",
        "\n",
        "pat = pat.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
        "pat[pat_X_cols] = pat.groupby(\"symbol\", sort=False)[pat_X_cols].shift(1)\n",
        "\n",
        "print(\"Pattern feature count:\", len(pat_X_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "d_rd1EJqJ60-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_rd1EJqJ60-",
        "outputId": "fcc03088-c13c-4003-ccde-884a70ab610a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Columns y_up_5d found in both sentiment and ohlcv dataframes. Removing it from sentiment to avoid clash\n",
            "Sentiment Columns: ['symbol', 'date', 'article_count', 'pos_count', 'neg_count', 'neu_count', 'highrel_count', 'rel_score_mean', 'sent_conf_mean', 'polarity_mean', 'polarity_std', 'polarity_wmean', 'highrel_polarity_mean', 'highrel_polarity_wmean', 'pos_ratio', 'neg_ratio', 'neu_ratio', 'highrel_ratio', 'sent_cov', 'sent_abs', 'imbalance', 'highrel_impact', 'news_present', 'article_count_lag_1', 'pos_ratio_lag_1', 'neg_ratio_lag_1', 'neu_ratio_lag_1', 'highrel_ratio_lag_1', 'rel_score_mean_lag_1', 'sent_conf_mean_lag_1', 'polarity_mean_lag_1', 'polarity_std_lag_1', 'polarity_wmean_lag_1', 'highrel_polarity_mean_lag_1', 'highrel_polarity_wmean_lag_1', 'sent_cov_lag_1', 'sent_abs_lag_1', 'imbalance_lag_1', 'highrel_impact_lag_1', 'news_present_lag_1', 'article_count_lag_2', 'pos_ratio_lag_2', 'neg_ratio_lag_2', 'neu_ratio_lag_2', 'highrel_ratio_lag_2', 'rel_score_mean_lag_2', 'sent_conf_mean_lag_2', 'polarity_mean_lag_2', 'polarity_std_lag_2', 'polarity_wmean_lag_2', 'highrel_polarity_mean_lag_2', 'highrel_polarity_wmean_lag_2', 'sent_cov_lag_2', 'sent_abs_lag_2', 'imbalance_lag_2', 'highrel_impact_lag_2', 'news_present_lag_2', 'article_count_lag_3', 'pos_ratio_lag_3', 'neg_ratio_lag_3', 'neu_ratio_lag_3', 'highrel_ratio_lag_3', 'rel_score_mean_lag_3', 'sent_conf_mean_lag_3', 'polarity_mean_lag_3', 'polarity_std_lag_3', 'polarity_wmean_lag_3', 'highrel_polarity_mean_lag_3', 'highrel_polarity_wmean_lag_3', 'sent_cov_lag_3', 'sent_abs_lag_3', 'imbalance_lag_3', 'highrel_impact_lag_3', 'news_present_lag_3', 'article_count_lag_4', 'pos_ratio_lag_4', 'neg_ratio_lag_4', 'neu_ratio_lag_4', 'highrel_ratio_lag_4', 'rel_score_mean_lag_4', 'sent_conf_mean_lag_4', 'polarity_mean_lag_4', 'polarity_std_lag_4', 'polarity_wmean_lag_4', 'highrel_polarity_mean_lag_4', 'highrel_polarity_wmean_lag_4', 'sent_cov_lag_4', 'sent_abs_lag_4', 'imbalance_lag_4', 'highrel_impact_lag_4', 'news_present_lag_4', 'article_count_lag_5', 'pos_ratio_lag_5', 'neg_ratio_lag_5', 'neu_ratio_lag_5', 'highrel_ratio_lag_5', 'rel_score_mean_lag_5', 'sent_conf_mean_lag_5', 'polarity_mean_lag_5', 'polarity_std_lag_5', 'polarity_wmean_lag_5', 'highrel_polarity_mean_lag_5', 'highrel_polarity_wmean_lag_5', 'sent_cov_lag_5', 'sent_abs_lag_5', 'imbalance_lag_5', 'highrel_impact_lag_5', 'news_present_lag_5', 'sent_cov_roll_mean_3', 'sent_cov_roll_std_3', 'article_count_roll_mean_3', 'sent_cov_roll_mean_5', 'sent_cov_roll_std_5', 'article_count_roll_mean_5', 'sent_cov_roll_mean_10', 'sent_cov_roll_std_10', 'article_count_roll_mean_10', 'sent_cov_roll_mean_20', 'sent_cov_roll_std_20', 'article_count_roll_mean_20', 'polarity_wmean_z20', 'polarity_wmean_pos_shock', 'polarity_wmean_neg_shock', 'sent_cov_z20', 'sent_cov_pos_shock', 'sent_cov_neg_shock', 'article_count_z20', 'article_count_pos_shock', 'article_count_neg_shock']\n"
          ]
        }
      ],
      "source": [
        "# ---------- Build df with a SINGLE label source (avoid _x/_y collisions) ----------\n",
        "if label_col in sent.columns and label_col in ohlcv.columns:\n",
        "    print(f\"Label Columns {label_col} found in both sentiment and ohlcv dataframes. Removing it from sentiment to avoid clash\")\n",
        "    # Drop label col from sentiment\n",
        "    sent.drop(columns=[label_col], inplace=True)\n",
        "    # Re-define sent_X_cols after dropping the label column\n",
        "    sent_X_cols = [c for c in sent.columns if c not in sent_exclude]\n",
        "\n",
        "assert label_col in ohlcv.columns, f\"{label_col} not found in ohlcv_features\"\n",
        "assert label_col not in sent.columns, f\"{label_col} found in sentiment_features even after dropping\"\n",
        "print(f\"Sentiment Columns: {sent.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "371b54b7",
      "metadata": {
        "id": "371b54b7"
      },
      "source": [
        "## 6) Merge all on (symbol, date) + create splits from OHLCV metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "seNwCXFOImdm",
      "metadata": {
        "id": "seNwCXFOImdm"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "aa780699",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa780699",
        "outputId": "8cf3102b-9121-493a-b4ca-e993e673faf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged rows: 598\n",
            "Date min/max: 2021-02-25 00:00:00 2023-09-07 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Keep label and key from OHLCV\n",
        "label_df = ohlcv[[\"symbol\",\"date\",label_col]].dropna().copy()\n",
        "\n",
        "# Merge expert feature tables (after their shifts)\n",
        "df = label_df.merge(\n",
        "    ohlcv[[\"symbol\",\"date\"] + ohlcv_X_cols], on=[\"symbol\",\"date\"], how=\"inner\"\n",
        ").merge(\n",
        "    sent[[\"symbol\",\"date\"] + sent_X_cols], on=[\"symbol\",\"date\"], how=\"inner\"\n",
        ").merge(\n",
        "    pat[[\"symbol\",\"date\"] + pat_X_cols], on=[\"symbol\",\"date\"], how=\"inner\"\n",
        ")\n",
        "\n",
        "df = df.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "print(\"Merged rows:\", len(df))\n",
        "print(\"Date min/max:\", df[\"date\"].min(), df[\"date\"].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "Yxs8t-rbIQUh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxs8t-rbIQUh",
        "outputId": "9622af4c-e783-4802-8399-7a1bcf228dcd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['symbol',\n",
              " 'date',\n",
              " 'article_count',\n",
              " 'pos_count',\n",
              " 'neg_count',\n",
              " 'neu_count',\n",
              " 'highrel_count',\n",
              " 'rel_score_mean',\n",
              " 'sent_conf_mean',\n",
              " 'polarity_mean',\n",
              " 'polarity_std',\n",
              " 'polarity_wmean',\n",
              " 'highrel_polarity_mean',\n",
              " 'highrel_polarity_wmean',\n",
              " 'pos_ratio',\n",
              " 'neg_ratio',\n",
              " 'neu_ratio',\n",
              " 'highrel_ratio',\n",
              " 'sent_cov',\n",
              " 'sent_abs',\n",
              " 'imbalance',\n",
              " 'highrel_impact',\n",
              " 'news_present',\n",
              " 'article_count_lag_1',\n",
              " 'pos_ratio_lag_1',\n",
              " 'neg_ratio_lag_1',\n",
              " 'neu_ratio_lag_1',\n",
              " 'highrel_ratio_lag_1',\n",
              " 'rel_score_mean_lag_1',\n",
              " 'sent_conf_mean_lag_1',\n",
              " 'polarity_mean_lag_1',\n",
              " 'polarity_std_lag_1',\n",
              " 'polarity_wmean_lag_1',\n",
              " 'highrel_polarity_mean_lag_1',\n",
              " 'highrel_polarity_wmean_lag_1',\n",
              " 'sent_cov_lag_1',\n",
              " 'sent_abs_lag_1',\n",
              " 'imbalance_lag_1',\n",
              " 'highrel_impact_lag_1',\n",
              " 'news_present_lag_1',\n",
              " 'article_count_lag_2',\n",
              " 'pos_ratio_lag_2',\n",
              " 'neg_ratio_lag_2',\n",
              " 'neu_ratio_lag_2',\n",
              " 'highrel_ratio_lag_2',\n",
              " 'rel_score_mean_lag_2',\n",
              " 'sent_conf_mean_lag_2',\n",
              " 'polarity_mean_lag_2',\n",
              " 'polarity_std_lag_2',\n",
              " 'polarity_wmean_lag_2',\n",
              " 'highrel_polarity_mean_lag_2',\n",
              " 'highrel_polarity_wmean_lag_2',\n",
              " 'sent_cov_lag_2',\n",
              " 'sent_abs_lag_2',\n",
              " 'imbalance_lag_2',\n",
              " 'highrel_impact_lag_2',\n",
              " 'news_present_lag_2',\n",
              " 'article_count_lag_3',\n",
              " 'pos_ratio_lag_3',\n",
              " 'neg_ratio_lag_3',\n",
              " 'neu_ratio_lag_3',\n",
              " 'highrel_ratio_lag_3',\n",
              " 'rel_score_mean_lag_3',\n",
              " 'sent_conf_mean_lag_3',\n",
              " 'polarity_mean_lag_3',\n",
              " 'polarity_std_lag_3',\n",
              " 'polarity_wmean_lag_3',\n",
              " 'highrel_polarity_mean_lag_3',\n",
              " 'highrel_polarity_wmean_lag_3',\n",
              " 'sent_cov_lag_3',\n",
              " 'sent_abs_lag_3',\n",
              " 'imbalance_lag_3',\n",
              " 'highrel_impact_lag_3',\n",
              " 'news_present_lag_3',\n",
              " 'article_count_lag_4',\n",
              " 'pos_ratio_lag_4',\n",
              " 'neg_ratio_lag_4',\n",
              " 'neu_ratio_lag_4',\n",
              " 'highrel_ratio_lag_4',\n",
              " 'rel_score_mean_lag_4',\n",
              " 'sent_conf_mean_lag_4',\n",
              " 'polarity_mean_lag_4',\n",
              " 'polarity_std_lag_4',\n",
              " 'polarity_wmean_lag_4',\n",
              " 'highrel_polarity_mean_lag_4',\n",
              " 'highrel_polarity_wmean_lag_4',\n",
              " 'sent_cov_lag_4',\n",
              " 'sent_abs_lag_4',\n",
              " 'imbalance_lag_4',\n",
              " 'highrel_impact_lag_4',\n",
              " 'news_present_lag_4',\n",
              " 'article_count_lag_5',\n",
              " 'pos_ratio_lag_5',\n",
              " 'neg_ratio_lag_5',\n",
              " 'neu_ratio_lag_5',\n",
              " 'highrel_ratio_lag_5',\n",
              " 'rel_score_mean_lag_5',\n",
              " 'sent_conf_mean_lag_5',\n",
              " 'polarity_mean_lag_5',\n",
              " 'polarity_std_lag_5',\n",
              " 'polarity_wmean_lag_5',\n",
              " 'highrel_polarity_mean_lag_5',\n",
              " 'highrel_polarity_wmean_lag_5',\n",
              " 'sent_cov_lag_5',\n",
              " 'sent_abs_lag_5',\n",
              " 'imbalance_lag_5',\n",
              " 'highrel_impact_lag_5',\n",
              " 'news_present_lag_5',\n",
              " 'sent_cov_roll_mean_3',\n",
              " 'sent_cov_roll_std_3',\n",
              " 'article_count_roll_mean_3',\n",
              " 'sent_cov_roll_mean_5',\n",
              " 'sent_cov_roll_std_5',\n",
              " 'article_count_roll_mean_5',\n",
              " 'sent_cov_roll_mean_10',\n",
              " 'sent_cov_roll_std_10',\n",
              " 'article_count_roll_mean_10',\n",
              " 'sent_cov_roll_mean_20',\n",
              " 'sent_cov_roll_std_20',\n",
              " 'article_count_roll_mean_20',\n",
              " 'polarity_wmean_z20',\n",
              " 'polarity_wmean_pos_shock',\n",
              " 'polarity_wmean_neg_shock',\n",
              " 'sent_cov_z20',\n",
              " 'sent_cov_pos_shock',\n",
              " 'sent_cov_neg_shock',\n",
              " 'article_count_z20',\n",
              " 'article_count_pos_shock',\n",
              " 'article_count_neg_shock',\n",
              " 'y_up_5d']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "7f706707",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f706707",
        "outputId": "6b297333-975f-4d22-ea68-d5f77999a619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train rows 205 2021-02-25 00:00:00 2021-12-31 00:00:00 pos_rate 0.6097560975609756\n",
            "val rows 231 2022-01-03 00:00:00 2022-12-30 00:00:00 pos_rate 0.49783549783549785\n",
            "test rows 162 2023-01-02 00:00:00 2023-09-07 00:00:00 pos_rate 0.5493827160493827\n"
          ]
        }
      ],
      "source": [
        "def parse_date(s):\n",
        "    return pd.to_datetime(s) if s else None\n",
        "\n",
        "splits = meta_ohlcv.get(\"splits\", {})\n",
        "train_start = parse_date(splits.get(\"train_start\"))\n",
        "train_end   = parse_date(splits.get(\"train_end\"))\n",
        "val_start   = parse_date(splits.get(\"val_start\"))\n",
        "val_end     = parse_date(splits.get(\"val_end\"))\n",
        "test_start  = parse_date(splits.get(\"test_start\"))\n",
        "test_end    = parse_date(splits.get(\"test_end\"))\n",
        "\n",
        "if all([train_start, train_end, val_start, val_end, test_start]):\n",
        "    train_df = df[(df[\"date\"]>=train_start) & (df[\"date\"]<=train_end)].copy()\n",
        "    val_df   = df[(df[\"date\"]>=val_start) & (df[\"date\"]<=val_end)].copy()\n",
        "    test_df  = df[(df[\"date\"]>=test_start) & ((df[\"date\"]<=test_end) if test_end is not None else True)].copy()\n",
        "else:\n",
        "    # fallback: 2021=train, 2022=val, 2023=test style\n",
        "    yrs = df[\"date\"].dt.year\n",
        "    train_df = df[yrs==2021].copy()\n",
        "    val_df   = df[yrs==2022].copy()\n",
        "    test_df  = df[yrs==2023].copy()\n",
        "\n",
        "print(\"train rows\", len(train_df), train_df[\"date\"].min(), train_df[\"date\"].max(), \"pos_rate\", float(train_df[label_col].mean()))\n",
        "print(\"val rows\", len(val_df), val_df[\"date\"].min(), val_df[\"date\"].max(), \"pos_rate\", float(val_df[label_col].mean()))\n",
        "print(\"test rows\", len(test_df), test_df[\"date\"].min(), test_df[\"date\"].max(), \"pos_rate\", float(test_df[label_col].mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "jqHgi9N-fVjE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqHgi9N-fVjE",
        "outputId": "4ae00a63-0237-4e9d-8119-8caf7d38e9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: rows=205 key_hash=15295034474200279777 pos_rate=0.6098 date_min=2021-02-25 date_max=2021-12-31\n",
            "val: rows=231 key_hash=9090236632237331621 pos_rate=0.4978 date_min=2022-01-03 date_max=2022-12-30\n",
            "test: rows=162 key_hash=10320201828196904199 pos_rate=0.5494 date_min=2023-01-02 date_max=2023-09-07\n"
          ]
        }
      ],
      "source": [
        "# Sanity checks: alignment across modalities + leakage guardrails\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Keys must be unique and sorted\n",
        "assert df[['symbol','date']].isna().sum().sum() == 0, \"Nulls in (symbol,date)\"\n",
        "assert not df.duplicated(['symbol','date']).any(), \"Duplicate (symbol,date) rows found\"\n",
        "df = df.sort_values(['symbol','date']).reset_index(drop=True)\n",
        "\n",
        "# 2) Feature sets exist and are non-empty\n",
        "for name, cols in [('OHLCV', ohlcv_X_cols), ('SENT', sent_X_cols), ('PAT', pat_X_cols)]:\n",
        "    missing = [c for c in cols if c not in df.columns]\n",
        "    assert len(missing) == 0, f\"{name} missing columns: {missing[:10]} (showing first 10)\"\n",
        "    assert len(cols) > 0, f\"{name} has 0 features\"\n",
        "\n",
        "# 3) Split frames must be perfectly aligned by construction (they come from df masks),\n",
        "# but we still verify shapes and key hashes so any accidental reordering is caught.\n",
        "def _key_hash(frame: pd.DataFrame) -> str:\n",
        "    # stable hash of (symbol,date) order\n",
        "    return pd.util.hash_pandas_object(frame[['symbol','date']], index=False).astype('uint64').sum().__str__()\n",
        "\n",
        "for name, part in [('train', train_df), ('val', val_df), ('test', test_df)]:\n",
        "    assert part[['symbol','date']].isna().sum().sum() == 0\n",
        "    assert not part.duplicated(['symbol','date']).any()\n",
        "    print(f\"{name}: rows={len(part)} key_hash={_key_hash(part)} \"\n",
        "          f\"pos_rate={float(part[label_col].mean()):.4f} \"\n",
        "          f\"date_min={part['date'].min().date()} date_max={part['date'].max().date()}\")\n",
        "\n",
        "# 4) Leakage sanity: features are shifted already, but we still ensure no forward-looking columns sneak in\n",
        "leaky = [c for c in df.columns if c.startswith(('close_fwd_', 'ret_fwd_'))]\n",
        "assert len(leaky) == 0, f\"Forward-looking columns present in df: {leaky[:10]}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb5ac76",
      "metadata": {
        "id": "cdb5ac76"
      },
      "source": [
        "## 7) Load expert models from MLflow Registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "ab7a35e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167,
          "referenced_widgets": [
            "1405a466765d4ad3a1d6d3b1ee17c3c1",
            "8690eb529a9d40a9afff68ce31c14fc0",
            "40d16bde6f9d4a4cb46e635af4e5a6e9",
            "e3f15103dc524433b028758d83d99dad",
            "10aabc8d687249c0b95309b2a4f994fb",
            "a2686011044f4eb8b0f924620d06f0ef",
            "0bf5a3f4d65846d386dff293fb4f7d10",
            "4618c18be6f1448593b215297eaa38e7",
            "8249495af45d431c9a8c49ffdf65f220",
            "2298b74e9f374e3da006a511f78f96c5",
            "4d1cec83311d40bdbe5193307716ed94",
            "7fd8606785064a908d007ee9b1eae888",
            "e2078371ab464b8c9dad81eaf17887e5",
            "5dc9c0540905464e8e77a50eb8a6c3fa",
            "8f851481543940a5b89f8c455f70cabb",
            "3db1feaf146f43f19a1cc3a7a44dd579",
            "d49a9d2bd670466caa56941104f4d9dc",
            "41b117c5e5334bd0bf192fc25efd0d45",
            "5ea0e8a9b1f44c49b56cb467114e0440",
            "39db53090f364c02a7c8985138ee8664",
            "3ba09500f02c412ba73d73c725bbf840",
            "0a5e872215b64135b6462d351e59e198",
            "bd8c8d02558a4a139e2ae262d72df1a7",
            "5e9035156bfc47dea619c3cf055331f6",
            "93fc4eadaff341e28d460352f1c8bf04",
            "095a0c876daf428ba171a2d7f43dbdb1",
            "d381cb361a7b4da6a3954a31c90ccc37",
            "451060c3c533419892c7f8daeac398ad",
            "44f715fdc4f44ec5a888bfdb3ed76a1c",
            "7d0fc5d83f5841c482009fac6f903f11",
            "003c7cfd1101406fa8df6ee7692f2728",
            "d620b44d5b7f41a885603123b2fd15e3",
            "f5acf5498b9c4949a1b1fe6583c5b909"
          ]
        },
        "id": "ab7a35e7",
        "outputId": "fe4e2bbb-f947-4622-f3b4-58dc80d3812e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ohlcv_lr_baseline_tcs_2021_2023 v2 -> models:/ohlcv_lr_baseline_tcs_2021_2023/2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1405a466765d4ad3a1d6d3b1ee17c3c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading sentiment_lr_baseline_tcs_2021_2023 v7 -> models:/sentiment_lr_baseline_tcs_2021_2023/7\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fd8606785064a908d007ee9b1eae888",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pattern_lr_baseline_tcs_2021_2023 v1 -> models:/pattern_lr_baseline_tcs_2021_2023/1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd8c8d02558a4a139e2ae262d72df1a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "def load_model_version(model_name: str, version: int = None):\n",
        "    if version is None:\n",
        "        # If no specific version is requested, find the latest\n",
        "        versions = client.search_model_versions(f\"name='{model_name}'\")\n",
        "        if not versions:\n",
        "            raise ValueError(f\"No registered model versions found for: {model_name}\")\n",
        "        v = max(int(m.version) for m in versions)\n",
        "    else:\n",
        "        # Use the specified version\n",
        "        v = version\n",
        "\n",
        "    uri = f\"models:/{model_name}/{v}\"\n",
        "    print(f\"Loading {model_name} v{v} -> {uri}\")\n",
        "\n",
        "    # Prefer native sklearn estimator so we can call predict_proba\n",
        "    try:\n",
        "        model = mlflow.sklearn.load_model(uri)\n",
        "        model_kind = \"sklearn\"\n",
        "    except Exception as e:\n",
        "        print(f\"mlflow.sklearn.load_model failed ({e}); falling back to pyfunc\")\n",
        "        model = mlflow.pyfunc.load_model(uri)\n",
        "        model_kind = \"pyfunc\"\n",
        "\n",
        "    return model, model_kind, uri\n",
        "\n",
        "m_ohlcv, kind_ohlcv, uri_ohlcv = load_model_version(\"ohlcv_lr_baseline_tcs_2021_2023\")\n",
        "m_sent,  kind_sent,  uri_sent  = load_model_version(\"sentiment_lr_baseline_tcs_2021_2023\", 7)\n",
        "m_pat,   kind_pat,   uri_pat   = load_model_version(\"pattern_lr_baseline_tcs_2021_2023\")  # change name if different\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vFKFJsFSgU8n",
      "metadata": {
        "id": "vFKFJsFSgU8n"
      },
      "source": [
        "## 8) Generate expert probabilities (meta features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "egEkhMBXfVjF",
      "metadata": {
        "id": "egEkhMBXfVjF",
        "tags": [
          "oof_safe"
        ]
      },
      "outputs": [],
      "source": [
        "# OOF helper for time-series stacking (expanding-window CV)\n",
        "import numpy as np\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "def _ensure_series(y):\n",
        "    # Accept pandas Series or array-like\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        if isinstance(y, (pd.Series, pd.DataFrame)):\n",
        "            return y.squeeze()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return y\n",
        "\n",
        "def oof_proba_timeseries(estimator, X, y, n_splits=5):\n",
        "    \"\"\"Generate out-of-fold probabilities for a time-ordered dataset.\n",
        "\n",
        "    Notes:\n",
        "    - Uses TimeSeriesSplit so each fold trains on past data and predicts a future block.\n",
        "    - Earliest rows will not receive OOF predictions (by design). We return a valid_mask.\n",
        "    \"\"\"\n",
        "    y = _ensure_series(y)\n",
        "\n",
        "    # Basic alignment sanity checks (when pandas is used)\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        if isinstance(X, (pd.DataFrame, pd.Series)) and isinstance(y, pd.Series):\n",
        "            if not X.index.equals(y.index):\n",
        "                raise ValueError(\"Index mismatch: X and y are not aligned. Ensure all modalities were merged on identical keys and sorted identically.\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    n = len(y)\n",
        "    oof = np.full(n, np.nan, dtype=float)\n",
        "\n",
        "    splitter = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    # If X is numpy, we still can index with arrays\n",
        "    for fold, (tr, te) in enumerate(splitter.split(np.arange(n))):\n",
        "        # Skip folds where train labels are single-class (predict_proba may fail)\n",
        "        y_tr = y.iloc[tr] if hasattr(y, \"iloc\") else y[tr]\n",
        "        uniq = np.unique(y_tr)\n",
        "        if len(uniq) < 2:\n",
        "            continue\n",
        "\n",
        "        m = clone(estimator)\n",
        "        X_tr = X.iloc[tr] if hasattr(X, \"iloc\") else X[tr]\n",
        "        X_te = X.iloc[te] if hasattr(X, \"iloc\") else X[te]\n",
        "        m.fit(X_tr, y_tr)\n",
        "        oof[te] = m.predict_proba(X_te)[:, 1]\n",
        "\n",
        "    valid_mask = ~np.isnan(oof)\n",
        "    return oof, valid_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "2261c51d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2261c51d",
        "outputId": "7a132e32-b357-4eef-d842-c1d39cbb727f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OOF coverage: 0.829 (dropping 35 earliest train rows with no OOF coverage)\n",
            "train gate value_counts: {1.0: 166, 0.0: 4}\n",
            "val gate value_counts: {1.0: 216, 0.0: 15}\n",
            "test gate value_counts: {1.0: 158, 0.0: 4}\n",
            "meta_train/meta_val/meta_test shapes: (170, 3) (231, 3) (162, 3)\n"
          ]
        }
      ],
      "source": [
        "# Generate expert probabilities (meta features) - OOF-safe for TRAIN\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import clone\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# --- Sanity: perfect row alignment across modalities ---\n",
        "def _assert_aligned(df_base, cols, name):\n",
        "    if len(df_base) == 0:\n",
        "        raise ValueError(f\"{name}: empty dataframe.\")\n",
        "    if df_base[cols].isna().any().any():\n",
        "        # Allow NaNs only if you intentionally model missingness; here we want clean matrices.\n",
        "        nan_cols = df_base[cols].columns[df_base[cols].isna().any()].tolist()\n",
        "        raise ValueError(f\"{name}: NaNs found in feature columns: {nan_cols[:10]} (showing up to 10).\")\n",
        "\n",
        "# Prepare matrices (all share the same index/order because they come from train_df/val_df/test_df)\n",
        "X_ohlcv_train = train_df[ohlcv_X_cols].copy()\n",
        "X_sent_train  = train_df[sent_X_cols].copy()\n",
        "X_pat_train   = train_df[pat_X_cols].copy()\n",
        "y_train       = train_df[label_col].astype(int).copy()\n",
        "\n",
        "X_ohlcv_val = val_df[ohlcv_X_cols].copy()\n",
        "X_sent_val  = val_df[sent_X_cols].copy()\n",
        "X_pat_val   = val_df[pat_X_cols].copy()\n",
        "y_val       = val_df[label_col].astype(int).copy()\n",
        "\n",
        "X_ohlcv_test = test_df[ohlcv_X_cols].copy()\n",
        "X_sent_test  = test_df[sent_X_cols].copy()\n",
        "X_pat_test   = test_df[pat_X_cols].copy()\n",
        "y_test       = test_df[label_col].astype(int).copy()\n",
        "\n",
        "_assert_aligned(train_df, ohlcv_X_cols, \"OHLCV/train\")\n",
        "_assert_aligned(train_df, sent_X_cols,   \"Sentiment/train\")\n",
        "_assert_aligned(train_df, pat_X_cols,    \"Pattern/train\")\n",
        "\n",
        "# (A) OOF predictions for TRAIN (meta-train) using expanding-window CV\n",
        "N_SPLITS_OOF = 5\n",
        "p_ohlcv_train_oof, m1 = oof_proba_timeseries(m_ohlcv, X_ohlcv_train, y_train, n_splits=N_SPLITS_OOF)\n",
        "p_sent_train_oof,  m2 = oof_proba_timeseries(m_sent,  X_sent_train,  y_train, n_splits=N_SPLITS_OOF)\n",
        "p_pat_train_oof,   m3 = oof_proba_timeseries(m_pat,   X_pat_train,   y_train, n_splits=N_SPLITS_OOF)\n",
        "\n",
        "valid_oof = (m1 & m2 & m3)\n",
        "dropped = int((~valid_oof).sum())\n",
        "print(f\"OOF coverage: {valid_oof.mean():.3f} (dropping {dropped} earliest train rows with no OOF coverage)\")\n",
        "\n",
        "meta_train = pd.DataFrame(\n",
        "    {\n",
        "        \"p_ohlcv\": p_ohlcv_train_oof,\n",
        "        \"p_sent\":  p_sent_train_oof,\n",
        "        \"p_pat\":   p_pat_train_oof,\n",
        "    },\n",
        "    index=train_df.index,\n",
        ").loc[valid_oof].reset_index(drop=True)\n",
        "\n",
        "# (B) Fit each expert on FULL TRAIN, then predict VAL/TEST (this is safe: no val/test leakage)\n",
        "m_ohlcv_fit = clone(m_ohlcv).fit(X_ohlcv_train, y_train)\n",
        "m_sent_fit  = clone(m_sent).fit(X_sent_train,  y_train)\n",
        "m_pat_fit   = clone(m_pat).fit(X_pat_train,   y_train)\n",
        "\n",
        "meta_val = pd.DataFrame(\n",
        "    {\n",
        "        \"p_ohlcv\": m_ohlcv_fit.predict_proba(X_ohlcv_val)[:, 1],\n",
        "        \"p_sent\":  m_sent_fit.predict_proba(X_sent_val)[:, 1],\n",
        "        \"p_pat\":   m_pat_fit.predict_proba(X_pat_val)[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "meta_test = pd.DataFrame(\n",
        "    {\n",
        "        \"p_ohlcv\": m_ohlcv_fit.predict_proba(X_ohlcv_test)[:, 1],\n",
        "        \"p_sent\":  m_sent_fit.predict_proba(X_sent_test)[:, 1],\n",
        "        \"p_pat\":   m_pat_fit.predict_proba(X_pat_test)[:, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "meta_train[\"p_sent\"] = 1 - meta_train[\"p_sent\"]\n",
        "meta_val[\"p_sent\"]   = 1 - meta_val[\"p_sent\"]\n",
        "meta_test[\"p_sent\"]  = 1 - meta_test[\"p_sent\"]\n",
        "\n",
        "y_meta_train = y_train.loc[valid_oof].reset_index(drop=True)\n",
        "y_meta_val = y_val\n",
        "y_meta_test = y_test\n",
        "\n",
        "# ----- Sentiment gating using lagged news presence -----\n",
        "# IMPORTANT: Use the lagged flag (news_present_lag_1) so it's leakage-safe.\n",
        "\n",
        "GATE_COL = \"news_present_lag_1\"   # must exist in your sentiment feature columns (sent_X_cols)\n",
        "\n",
        "# Build gate vectors aligned to the SAME rows used in meta_* frames\n",
        "gate_train = train_df.loc[valid_oof, GATE_COL].astype(float).reset_index(drop=True)\n",
        "gate_val   = val_df[GATE_COL].astype(float).reset_index(drop=True)\n",
        "gate_test  = test_df[GATE_COL].astype(float).reset_index(drop=True)\n",
        "\n",
        "# gate_train = train_df.loc[valid_oof, GATE_COL].values\n",
        "# gate_val   = val_df[GATE_COL].values\n",
        "# gate_test  = test_df[GATE_COL].values\n",
        "\n",
        "# Sanity: gate must be 0/1 (or close)\n",
        "for name, g in [(\"train\", gate_train), (\"val\", gate_val), (\"test\", gate_test)]:\n",
        "    print(name, \"gate value_counts:\", g.value_counts(dropna=False).to_dict())\n",
        "\n",
        "# Create gated sentiment probability\n",
        "meta_train[\"p_sent_gated\"] = meta_train[\"p_sent\"] * gate_train\n",
        "meta_val[\"p_sent_gated\"]   = meta_val[\"p_sent\"]   * gate_val\n",
        "meta_test[\"p_sent_gated\"]  = meta_test[\"p_sent\"]  * gate_test\n",
        "\n",
        "# Add news_present_lag_1 as separate feature\n",
        "# meta_train[GATE_COL] = gate_train\n",
        "# meta_val[GATE_COL]   = gate_val\n",
        "# meta_test[GATE_COL]  = gate_test\n",
        "\n",
        "# Optionally drop raw p_sent to force usage via gating only\n",
        "meta_train = meta_train.drop(columns=[\"p_sent\"])\n",
        "meta_val   = meta_val.drop(columns=[\"p_sent\"])\n",
        "meta_test  = meta_test.drop(columns=[\"p_sent\"])\n",
        "\n",
        "print(\"meta_train/meta_val/meta_test shapes:\", meta_train.shape, meta_val.shape, meta_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "3PYRvWkNg8W2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "3PYRvWkNg8W2",
        "outputId": "6b5237e2-ffb6-41c3-c4cd-45cdb9d04cce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"meta_train\",\n  \"rows\": 170,\n  \"fields\": [\n    {\n      \"column\": \"p_ohlcv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3760900480527885,\n        \"min\": 1.60645624189986e-07,\n        \"max\": 0.9984560985718312,\n        \"num_unique_values\": 170,\n        \"samples\": [\n          0.8702440769492726,\n          0.4369201455762097,\n          0.8897482422356694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_pat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009602229628184451,\n        \"min\": 0.479385531747014,\n        \"max\": 0.5335696390757925,\n        \"num_unique_values\": 170,\n        \"samples\": [\n          0.506208633082063,\n          0.5041712512366476,\n          0.5173068218336127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_sent_gated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1498529612484475,\n        \"min\": 0.0,\n        \"max\": 0.8370500425631179,\n        \"num_unique_values\": 167,\n        \"samples\": [\n          0.4062288705278686,\n          0.3325450448850302,\n          0.5743512581854436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "meta_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8391f6f0-611b-4349-8500-0e76c999d5af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p_ohlcv</th>\n",
              "      <th>p_pat</th>\n",
              "      <th>p_sent_gated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.027064</td>\n",
              "      <td>0.482420</td>\n",
              "      <td>0.676924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008420</td>\n",
              "      <td>0.490947</td>\n",
              "      <td>0.548423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8391f6f0-611b-4349-8500-0e76c999d5af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8391f6f0-611b-4349-8500-0e76c999d5af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8391f6f0-611b-4349-8500-0e76c999d5af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    p_ohlcv     p_pat  p_sent_gated\n",
              "0  0.027064  0.482420      0.676924\n",
              "1  0.008420  0.490947      0.548423"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "Edj9K4FAf-cY",
      "metadata": {
        "id": "Edj9K4FAf-cY"
      },
      "outputs": [],
      "source": [
        "assert len(meta_train) == len(gate_train)\n",
        "assert len(meta_val) == len(gate_val)\n",
        "assert len(meta_test) == len(gate_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "x9KfhlFzkFF7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9KfhlFzkFF7",
        "outputId": "6ef04677-6beb-4c45-e351-96c8a7dcbc26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "== meta_train ==\n",
            "p_ohlcv min 1.60645624189986e-07 max 0.9984560985718312 mean 0.4242770599575667 std 0.3749822693635382 unique~ 162\n",
            "p_pat min 0.479385531747014 max 0.5335696390757925 mean 0.5048939512426592 std 0.00957394612159749 unique~ 170\n",
            "p_sent_gated min 0.0 max 0.8370500425631179 mean 0.4900867508695377 std 0.14941156717845927 unique~ 167\n",
            "\n",
            "== meta_val ==\n",
            "p_ohlcv min 0.13095935213198978 max 0.8037656381286176 mean 0.473666669790789 std 0.1286899205680463 unique~ 230\n",
            "p_pat min 0.4751596376556519 max 0.5340669720453525 mean 0.4997305292606429 std 0.011546023003653623 unique~ 231\n",
            "p_sent_gated min 0.0 max 0.9235052125484218 mean 0.4205900183055187 std 0.2074229469441116 unique~ 217\n",
            "\n",
            "== meta_test ==\n",
            "p_ohlcv min 0.2578894961584779 max 0.812039457309756 mean 0.591403629042295 std 0.11802803084366054 unique~ 162\n",
            "p_pat min 0.4726631809902667 max 0.5439980699505257 mean 0.5018996098098693 std 0.010008041867135288 unique~ 161\n",
            "p_sent_gated min 0.0 max 0.8767059092051304 mean 0.47241866786906145 std 0.16078005425700226 unique~ 159\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def describe_probs(df, name):\n",
        "    print(\"\\n==\", name, \"==\")\n",
        "    for c in df.columns:\n",
        "        arr = df[c].to_numpy()\n",
        "        print(c,\n",
        "              \"min\", float(np.min(arr)),\n",
        "              \"max\", float(np.max(arr)),\n",
        "              \"mean\", float(np.mean(arr)),\n",
        "              \"std\", float(np.std(arr)),\n",
        "              \"unique~\", len(np.unique(np.round(arr, 6))))\n",
        "\n",
        "describe_probs(meta_train, \"meta_train\")\n",
        "describe_probs(meta_val, \"meta_val\")\n",
        "describe_probs(meta_test, \"meta_test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4e40d67",
      "metadata": {
        "id": "a4e40d67"
      },
      "source": [
        "## 9) Train meta-model (LogReg baseline + TimeSeries CV on TRAIN, pick by VAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "e5ab0894",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ab0894",
        "outputId": "08a077c2-045d-40d1-b6de-51f77a384c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meta features columns: ['p_ohlcv', 'p_pat', 'p_sent_gated']\n",
            "Meta TRAIN/VAL/TEST sizes: 170 231 162\n",
            "Label pos-rate train/val/test: 0.5882352941176471 0.49783549783549785 0.5493827160493827\n",
            "Best VAL params: {'C': 0.001, 'penalty': 'l1', 'class_weight': 'None'} VAL AUC: 0.5\n",
            "VAL: {'val_accuracy': 0.49783549783549785, 'val_roc_auc': 0.5, 'val_balanced_accuracy': 0.5, 'val_mcc': 0.0}\n",
            "TEST: {'test_accuracy': 0.5493827160493827, 'test_roc_auc': 0.5, 'test_balanced_accuracy': 0.5, 'test_mcc': 0.0}\n"
          ]
        }
      ],
      "source": [
        "# ---- Meta-model training (OOF-safe meta features already built) ----\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef\n",
        ")\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "def eval_split(estimator, X, y, prefix: str):\n",
        "    p = estimator.predict_proba(X)[:, 1]\n",
        "    pred = (p >= 0.5).astype(int)\n",
        "    return {\n",
        "        f\"{prefix}_accuracy\": float(accuracy_score(y, pred)),\n",
        "        f\"{prefix}_roc_auc\": float(roc_auc_score(y, p)) if len(np.unique(y)) > 1 else float(\"nan\"),\n",
        "        f\"{prefix}_balanced_accuracy\": float(balanced_accuracy_score(y, pred)),\n",
        "        f\"{prefix}_mcc\": float(matthews_corrcoef(y, pred)) if len(np.unique(y)) > 1 else float(\"nan\"),\n",
        "    }\n",
        "\n",
        "# Sanity: lengths + index alignment\n",
        "assert len(meta_train) == len(y_meta_train), \"meta_train and y_meta_train length mismatch\"\n",
        "assert len(meta_val)   == len(y_meta_val),   \"meta_val and y_meta_val length mismatch\"\n",
        "assert len(meta_test)  == len(y_meta_test),  \"meta_test and y_meta_test length mismatch\"\n",
        "\n",
        "print(\"Meta features columns:\", list(meta_train.columns))\n",
        "print(\"Meta TRAIN/VAL/TEST sizes:\", len(meta_train), len(meta_val), len(meta_test))\n",
        "print(\"Label pos-rate train/val/test:\",\n",
        "      float(np.mean(y_meta_train)),\n",
        "      float(np.mean(y_meta_val)),\n",
        "      float(np.mean(y_meta_test)))\n",
        "\n",
        "# Grid for meta LR\n",
        "C_grid = [1e-3, 1e-2, 1e-1, 1.0, 10.0]\n",
        "pen_grid = [\"l1\", \"l2\"]\n",
        "cw_grid = [None, \"balanced\"]\n",
        "\n",
        "rows = []\n",
        "cands = []\n",
        "for C in C_grid:\n",
        "    for pen in pen_grid:\n",
        "        for cw in cw_grid:\n",
        "            # liblinear supports l1/l2; saga also works but keep it simple/reproducible.\n",
        "            clf = LogisticRegression(\n",
        "                C=C, penalty=pen, class_weight=cw, solver=\"liblinear\", max_iter=2000, random_state=SEED\n",
        "            )\n",
        "            model = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", clf)])\n",
        "            model.fit(meta_train, y_meta_train)\n",
        "\n",
        "            val_p = model.predict_proba(meta_val)[:, 1]\n",
        "            val_auc = roc_auc_score(y_meta_val, val_p) if len(np.unique(y_meta_val)) > 1 else float(\"nan\")\n",
        "\n",
        "            rows.append({\n",
        "                \"C\": C, \"penalty\": pen, \"class_weight\": str(cw),\n",
        "                \"val_roc_auc\": float(val_auc),\n",
        "            })\n",
        "            cands.append(model)\n",
        "\n",
        "rank = pd.DataFrame(rows).sort_values(\"val_roc_auc\", ascending=False).reset_index(drop=True)\n",
        "best_params = rank.iloc[0].to_dict()\n",
        "best_idx = int(rank.index[0])\n",
        "\n",
        "# Pick best and refit only on meta_train (do NOT use val for fitting)\n",
        "final_meta = cands[rank.index[0]]\n",
        "\n",
        "print(\"Best VAL params:\", {k: best_params[k] for k in [\"C\",\"penalty\",\"class_weight\"]}, \"VAL AUC:\", best_params[\"val_roc_auc\"])\n",
        "\n",
        "val_metrics = eval_split(final_meta, meta_val, y_meta_val, \"val\")\n",
        "test_metrics = eval_split(final_meta, meta_test, y_meta_test, \"test\")\n",
        "print(\"VAL:\", val_metrics)\n",
        "print(\"TEST:\", test_metrics)\n",
        "\n",
        "# Keep these names expected by the MLflow cell below\n",
        "X_train, y_train = meta_train, y_meta_train\n",
        "X_val, y_val     = meta_val,   y_meta_val\n",
        "X_test, y_test   = meta_test,  y_meta_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "YBT5ru2FxHkN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBT5ru2FxHkN",
        "outputId": "770b79ba-5342-4710-c6e0-c6da4c5ce0d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0.]] [0.]\n"
          ]
        }
      ],
      "source": [
        "print(final_meta.named_steps['clf'].coef_, final_meta.named_steps['clf'].intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6dbf83",
      "metadata": {},
      "source": [
        "## 10) Visualizations (ROC-Curve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "6ef394ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ef394ab",
        "outputId": "1ccfae50-e93a-487d-877f-ea928bb9cb09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Successfully registered model 'fusion_meta_lr_tcs_2021_2023_h5d_sent_lag_1_gated'.\n",
            "2026/01/26 15:05:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: fusion_meta_lr_tcs_2021_2023_h5d_sent_lag_1_gated, version 1\n",
            "Created version '1' of model 'fusion_meta_lr_tcs_2021_2023_h5d_sent_lag_1_gated'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run stacked_meta_lr_tcs_2021_2023_h5d_sent_lag_1_gated at: https://dagshub.com/Roncool13/dissertation-mlflow.mlflow/#/experiments/3/runs/fba000bff6a64c5180f40b3317fd51de\n",
            "🧪 View experiment at: https://dagshub.com/Roncool13/dissertation-mlflow.mlflow/#/experiments/3\n",
            "Done. Run: None\n"
          ]
        }
      ],
      "source": [
        "# ---- MLflow logging + registration for meta-model ----\n",
        "import mlflow\n",
        "from mlflow.models.signature import infer_signature\n",
        "\n",
        "mlflow.sklearn.autolog(disable=True)\n",
        "\n",
        "run_name = f\"stacked_meta_lr_tcs_{meta_ohlcv.get('start_year','2021')}_{meta_ohlcv.get('end_year','2023')}_h{horizon_days}d_sent_lag_1_gated\"\n",
        "with mlflow.start_run(run_name=run_name):\n",
        "    mlflow.set_tag(\"stacking_inputs\", \"p_ohlcv,p_sent,p_pat\")\n",
        "    mlflow.set_tag(\"horizon_days\", str(horizon_days))\n",
        "\n",
        "    # Log chosen params\n",
        "    mlflow.log_params({\n",
        "        \"meta_C\": best_params[\"C\"],\n",
        "        \"meta_penalty\": best_params[\"penalty\"],\n",
        "        \"meta_class_weight\": best_params[\"class_weight\"],\n",
        "    })\n",
        "\n",
        "    # Metrics\n",
        "    mlflow.log_metrics({**val_metrics, **test_metrics})\n",
        "\n",
        "    # Ranking artifact\n",
        "    rank.to_csv(\"meta_val_candidate_ranking.csv\", index=False)\n",
        "    mlflow.log_artifact(\"meta_val_candidate_ranking.csv\", artifact_path=\"model_selection\")\n",
        "\n",
        "    # Signature\n",
        "    input_example = X_train.head(5)\n",
        "    sig = infer_signature(input_example, final_meta.predict_proba(input_example)[:, 1])\n",
        "\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=final_meta,\n",
        "        artifact_path=\"model_final\",\n",
        "        input_example=input_example,\n",
        "        signature=sig,\n",
        "    )\n",
        "\n",
        "    mlflow.set_tag('model_stage', 'frozen_baseline')\n",
        "    mlflow.set_tag('baseline_name', 'fusion_lr_baseline_tcs_2021_2023_sent_lag_1_gated')\n",
        "    mlflow.set_tag('selection_protocol', 'train_timeseries_cv_val_select_refit_trainval')\n",
        "    mlflow.set_tag(\"expert_type\", \"fusion\")\n",
        "    mlflow.set_tag(\"label_col\", label_col)\n",
        "    mlflow.set_tag(\"sentiment_expert\", \"lag-1 minimal (6 features)\")\n",
        "    mlflow.set_tag(\"fusion_result\", \"same as OHLCV baseline\")\n",
        "    mlflow.set_tag(\"additional_comments\", \"Sentiment did not improve ensemble performance under constrained single-symbol data.\")\n",
        "\n",
        "\n",
        "    # Optional registry\n",
        "    model_name = f\"fusion_meta_lr_tcs_{meta_ohlcv.get('start_year','2021')}_{meta_ohlcv.get('end_year','2023')}_h{horizon_days}d_sent_lag_1_gated\"\n",
        "    mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/model_final\", model_name)\n",
        "\n",
        "print(\"Done. Run:\", mlflow.active_run())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d61f57db",
      "metadata": {},
      "source": [
        "## 11) Visualizations (ROC-Curve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c263a665",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "val_scores = final_meta.predict_proba(meta_val)[:, 1]\n",
        "test_scores = final_meta.predict_proba(meta_test)[:, 1]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "RocCurveDisplay.from_predictions(y_meta_val, val_scores, name=\"Val\", ax=ax)\n",
        "RocCurveDisplay.from_predictions(y_meta_test, test_scores, name=\"Test\", ax=ax)\n",
        "ax.set_title(\"Fusion Meta-Model ROC Curves\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dissertation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003c7cfd1101406fa8df6ee7692f2728": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "095a0c876daf428ba171a2d7f43dbdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d620b44d5b7f41a885603123b2fd15e3",
            "placeholder": "​",
            "style": "IPY_MODEL_f5acf5498b9c4949a1b1fe6583c5b909",
            "value": " 7/7 [00:07&lt;00:00,  1.03s/it]"
          }
        },
        "0a5e872215b64135b6462d351e59e198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bf5a3f4d65846d386dff293fb4f7d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10aabc8d687249c0b95309b2a4f994fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1405a466765d4ad3a1d6d3b1ee17c3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8690eb529a9d40a9afff68ce31c14fc0",
              "IPY_MODEL_40d16bde6f9d4a4cb46e635af4e5a6e9",
              "IPY_MODEL_e3f15103dc524433b028758d83d99dad"
            ],
            "layout": "IPY_MODEL_10aabc8d687249c0b95309b2a4f994fb"
          }
        },
        "2298b74e9f374e3da006a511f78f96c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39db53090f364c02a7c8985138ee8664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ba09500f02c412ba73d73c725bbf840": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db1feaf146f43f19a1cc3a7a44dd579": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d16bde6f9d4a4cb46e635af4e5a6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4618c18be6f1448593b215297eaa38e7",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8249495af45d431c9a8c49ffdf65f220",
            "value": 7
          }
        },
        "41b117c5e5334bd0bf192fc25efd0d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44f715fdc4f44ec5a888bfdb3ed76a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "451060c3c533419892c7f8daeac398ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4618c18be6f1448593b215297eaa38e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1cec83311d40bdbe5193307716ed94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc9c0540905464e8e77a50eb8a6c3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea0e8a9b1f44c49b56cb467114e0440",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39db53090f364c02a7c8985138ee8664",
            "value": 7
          }
        },
        "5e9035156bfc47dea619c3cf055331f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_451060c3c533419892c7f8daeac398ad",
            "placeholder": "​",
            "style": "IPY_MODEL_44f715fdc4f44ec5a888bfdb3ed76a1c",
            "value": "Downloading artifacts: 100%"
          }
        },
        "5ea0e8a9b1f44c49b56cb467114e0440": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0fc5d83f5841c482009fac6f903f11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd8606785064a908d007ee9b1eae888": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2078371ab464b8c9dad81eaf17887e5",
              "IPY_MODEL_5dc9c0540905464e8e77a50eb8a6c3fa",
              "IPY_MODEL_8f851481543940a5b89f8c455f70cabb"
            ],
            "layout": "IPY_MODEL_3db1feaf146f43f19a1cc3a7a44dd579"
          }
        },
        "8249495af45d431c9a8c49ffdf65f220": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8690eb529a9d40a9afff68ce31c14fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2686011044f4eb8b0f924620d06f0ef",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf5a3f4d65846d386dff293fb4f7d10",
            "value": "Downloading artifacts: 100%"
          }
        },
        "8f851481543940a5b89f8c455f70cabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ba09500f02c412ba73d73c725bbf840",
            "placeholder": "​",
            "style": "IPY_MODEL_0a5e872215b64135b6462d351e59e198",
            "value": " 7/7 [00:07&lt;00:00,  1.01s/it]"
          }
        },
        "93fc4eadaff341e28d460352f1c8bf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d0fc5d83f5841c482009fac6f903f11",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_003c7cfd1101406fa8df6ee7692f2728",
            "value": 7
          }
        },
        "a2686011044f4eb8b0f924620d06f0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8c8d02558a4a139e2ae262d72df1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e9035156bfc47dea619c3cf055331f6",
              "IPY_MODEL_93fc4eadaff341e28d460352f1c8bf04",
              "IPY_MODEL_095a0c876daf428ba171a2d7f43dbdb1"
            ],
            "layout": "IPY_MODEL_d381cb361a7b4da6a3954a31c90ccc37"
          }
        },
        "d381cb361a7b4da6a3954a31c90ccc37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49a9d2bd670466caa56941104f4d9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d620b44d5b7f41a885603123b2fd15e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2078371ab464b8c9dad81eaf17887e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d49a9d2bd670466caa56941104f4d9dc",
            "placeholder": "​",
            "style": "IPY_MODEL_41b117c5e5334bd0bf192fc25efd0d45",
            "value": "Downloading artifacts: 100%"
          }
        },
        "e3f15103dc524433b028758d83d99dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2298b74e9f374e3da006a511f78f96c5",
            "placeholder": "​",
            "style": "IPY_MODEL_4d1cec83311d40bdbe5193307716ed94",
            "value": " 7/7 [00:01&lt;00:00,  6.49it/s]"
          }
        },
        "f5acf5498b9c4949a1b1fe6583c5b909": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
