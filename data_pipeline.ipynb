{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "576a050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from jugaad_data.nse import stock_df   # NEW\n",
    "# from nsepy import get_history       # OLD â€“ can be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae6a1e",
   "metadata": {},
   "source": [
    "#### =========================\n",
    "#### 1. DATA DOWNLOAD (NSEPY)\n",
    "#### ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b93b538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ohlcv_nsepy(\n",
    "    symbols: List[str],\n",
    "    start_date: dt.date,\n",
    "    end_date: dt.date\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download daily OHLCV data from NSE using jugaad-data (stock_df)\n",
    "    and merge into a single DataFrame.\n",
    "\n",
    "    NOTE:\n",
    "    - We keep the function name `download_ohlcv_nsepy` so the rest of the\n",
    "      pipeline (build_ohlcv_ml_ready) does not need to change.\n",
    "    - Under the hood, this no longer uses nsepy; it uses `stock_df` from\n",
    "      the `jugaad_data.nse` module, which works with the current NSE site.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for sym in tqdm(symbols, desc=\"Downloading OHLCV (jugaad-data)\"):\n",
    "        try:\n",
    "            df = stock_df(\n",
    "                symbol=sym,\n",
    "                from_date=start_date,\n",
    "                to_date=end_date,\n",
    "                series=\"EQ\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to download {sym} {start_date} to {end_date}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if df is None or df.empty:\n",
    "            print(f\"[WARN] No data for {sym}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # jugaad-data returns columns like: DATE, OPEN, HIGH, LOW, CLOSE, VOLUME, SYMBOL\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"DATE\": \"date\",\n",
    "                \"OPEN\": \"open\",\n",
    "                \"HIGH\": \"high\",\n",
    "                \"LOW\": \"low\",\n",
    "                \"CLOSE\": \"close\",\n",
    "                \"VOLUME\": \"volume\",\n",
    "                \"SYMBOL\": \"symbol\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        df = df[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"symbol\"]]\n",
    "        df.dropna(inplace=True)\n",
    "        all_data.append(df)\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"No data downloaded for any symbol (jugaad-data).\")\n",
    "\n",
    "    ohlcv = pd.concat(all_data, ignore_index=True)\n",
    "    ohlcv.sort_values([\"symbol\", \"date\"], inplace=True)\n",
    "    ohlcv.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return ohlcv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724fce1e",
   "metadata": {},
   "source": [
    "#### =========================\n",
    "#### 2. BASIC CLEANING\n",
    "#### ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5180d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ohlcv(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Basic cleaning:\n",
    "      - Ensure correct dtypes\n",
    "      - Drop duplicates\n",
    "      - Remove non-sensical rows\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\", \"volume\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    df.dropna(subset=[\"open\", \"high\", \"low\", \"close\"], inplace=True)\n",
    "    df.drop_duplicates(subset=[\"symbol\", \"date\"], inplace=True)\n",
    "\n",
    "    # filter out obviously bad rows (e.g. zero or negative prices)\n",
    "    df = df[(df[\"open\"] > 0) & (df[\"high\"] > 0) & (df[\"low\"] > 0) & (df[\"close\"] > 0)]\n",
    "    df = df[df[\"high\"] >= df[\"low\"]]\n",
    "\n",
    "    df.sort_values([\"symbol\", \"date\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018abb7a",
   "metadata": {},
   "source": [
    "#### =========================\n",
    "#### 3. TECHNICAL INDICATORS\n",
    "#### ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d549e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    return series.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "\n",
    "def rsi(series: pd.Series, period: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    gain = np.where(delta > 0, delta, 0.0)\n",
    "    loss = np.where(delta < 0, -delta, 0.0)\n",
    "\n",
    "    gain = pd.Series(gain, index=series.index)\n",
    "    loss = pd.Series(loss, index=series.index)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "\n",
    "    # Use Wilderâ€™s smoothing after first period\n",
    "    avg_gain = avg_gain.where(avg_gain.index < series.index[period],\n",
    "                              (avg_gain.shift(1) * (period - 1) + gain) / period)\n",
    "    avg_loss = avg_loss.where(avg_loss.index < series.index[period],\n",
    "                              (avg_loss.shift(1) * (period - 1) + loss) / period)\n",
    "\n",
    "    rs = avg_gain / (avg_loss + 1e-9)\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "\n",
    "def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add common technical indicators per symbol:\n",
    "      - Log returns\n",
    "      - Rolling volatility (20d)\n",
    "      - EMA 20 / 50 / 200\n",
    "      - MACD (12,26,9)\n",
    "      - Bollinger Bands (20, 2)\n",
    "      - ATR (14)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def _per_symbol(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = g.sort_values(\"date\").copy()\n",
    "\n",
    "        # returns\n",
    "        g[\"ret_1d\"] = g[\"close\"].pct_change()\n",
    "        g[\"log_ret_1d\"] = np.log(g[\"close\"] / g[\"close\"].shift(1))\n",
    "\n",
    "        # vol\n",
    "        g[\"vol_20d\"] = g[\"log_ret_1d\"].rolling(20, min_periods=10).std()\n",
    "\n",
    "        # EMA\n",
    "        g[\"ema_20\"] = ema(g[\"close\"], 20)\n",
    "        g[\"ema_50\"] = ema(g[\"close\"], 50)\n",
    "        g[\"ema_200\"] = ema(g[\"close\"], 200)\n",
    "\n",
    "        # MACD\n",
    "        ema_fast = ema(g[\"close\"], 12)\n",
    "        ema_slow = ema(g[\"close\"], 26)\n",
    "        g[\"macd\"] = ema_fast - ema_slow\n",
    "        g[\"macd_signal\"] = ema(g[\"macd\"], 9)\n",
    "        g[\"macd_hist\"] = g[\"macd\"] - g[\"macd_signal\"]\n",
    "\n",
    "        # Bollinger\n",
    "        ma20 = g[\"close\"].rolling(20, min_periods=10).mean()\n",
    "        sd20 = g[\"close\"].rolling(20, min_periods=10).std()\n",
    "        g[\"bb_mid_20\"] = ma20\n",
    "        g[\"bb_up_20\"] = ma20 + 2 * sd20\n",
    "        g[\"bb_low_20\"] = ma20 - 2 * sd20\n",
    "\n",
    "        # ATR (14)\n",
    "        high_low = g[\"high\"] - g[\"low\"]\n",
    "        high_close_prev = (g[\"high\"] - g[\"close\"].shift(1)).abs()\n",
    "        low_close_prev = (g[\"low\"] - g[\"close\"].shift(1)).abs()\n",
    "        tr = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1)\n",
    "        g[\"atr_14\"] = tr.rolling(14, min_periods=5).mean()\n",
    "\n",
    "        return g\n",
    "\n",
    "    df = df.groupby(\"symbol\", group_keys=False).apply(_per_symbol)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7e901",
   "metadata": {},
   "source": [
    "#### =========================\n",
    "#### 4. CANDLESTICK PATTERNS\n",
    "#### ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60648ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_candlestick_patterns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds some basic candlestick pattern flags:\n",
    "      - bullish_engulfing\n",
    "      - bearish_engulfing\n",
    "      - hammer\n",
    "      - shooting_star\n",
    "      - doji\n",
    "    Values are 1 if pattern present, else 0.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def _per_symbol(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = g.sort_values(\"date\").copy()\n",
    "\n",
    "        body = g[\"close\"] - g[\"open\"]\n",
    "        body_abs = body.abs()\n",
    "        range_ = g[\"high\"] - g[\"low\"]\n",
    "        upper_shadow = g[\"high\"] - g[[\"open\", \"close\"]].max(axis=1)\n",
    "        lower_shadow = g[[\"open\", \"close\"]].min(axis=1) - g[\"low\"]\n",
    "\n",
    "        # Engulfing\n",
    "        prev_body = body.shift(1)\n",
    "        prev_open = g[\"open\"].shift(1)\n",
    "        prev_close = g[\"close\"].shift(1)\n",
    "\n",
    "        bullish_engulf = (\n",
    "            (prev_body < 0)\n",
    "            & (body > 0)\n",
    "            & (g[\"open\"] < prev_close)\n",
    "            & (g[\"close\"] > prev_open)\n",
    "        )\n",
    "\n",
    "        bearish_engulf = (\n",
    "            (prev_body > 0)\n",
    "            & (body < 0)\n",
    "            & (g[\"open\"] > prev_close)\n",
    "            & (g[\"close\"] < prev_open)\n",
    "        )\n",
    "\n",
    "        # Hammer: small body near top, long lower shadow\n",
    "        hammer = (\n",
    "            (lower_shadow >= 2 * body_abs)\n",
    "            & (upper_shadow <= body_abs)\n",
    "            & (body_abs / range_ < 0.4)\n",
    "        )\n",
    "\n",
    "        # Shooting star: small body near bottom, long upper shadow\n",
    "        shooting_star = (\n",
    "            (upper_shadow >= 2 * body_abs)\n",
    "            & (lower_shadow <= body_abs)\n",
    "            & (body_abs / range_ < 0.4)\n",
    "        )\n",
    "\n",
    "        # Doji: very small body\n",
    "        doji = body_abs <= (0.1 * range_)\n",
    "\n",
    "        g[\"pat_bull_engulf\"] = bullish_engulf.astype(int)\n",
    "        g[\"pat_bear_engulf\"] = bearish_engulf.astype(int)\n",
    "        g[\"pat_hammer\"] = hammer.astype(int)\n",
    "        g[\"pat_shooting_star\"] = shooting_star.astype(int)\n",
    "        g[\"pat_doji\"] = doji.astype(int)\n",
    "\n",
    "        return g\n",
    "\n",
    "    df = df.groupby(\"symbol\", group_keys=False).apply(_per_symbol)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe33959",
   "metadata": {},
   "source": [
    "#### =========================\n",
    "#### 5. PRICE STRUCTURE (SWINGS + HH/HL/LH/LL)\n",
    "#### ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "770e1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_price_structure(\n",
    "    df: pd.DataFrame,\n",
    "    left: int = 2,\n",
    "    right: int = 2\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify swing highs/lows and classify swings into HH/HL/LH/LL.\n",
    "    Simple approach:\n",
    "      - A swing high is a high that is greater than neighbors in +/- (left/right) days\n",
    "      - A swing low is a low that is less than neighbors in +/- (left/right) days\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    def _find_swings(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = g.sort_values(\"date\").copy()\n",
    "        n = len(g)\n",
    "        swing_high = np.zeros(n, dtype=int)\n",
    "        swing_low = np.zeros(n, dtype=int)\n",
    "\n",
    "        highs = g[\"high\"].values\n",
    "        lows = g[\"low\"].values\n",
    "\n",
    "        for i in range(left, n - right):\n",
    "            window_high = highs[i - left : i + right + 1]\n",
    "            window_low = lows[i - left : i + right + 1]\n",
    "\n",
    "            if highs[i] == window_high.max() and (highs[i] > window_high[[0, -1]]).all():\n",
    "                swing_high[i] = 1\n",
    "\n",
    "            if lows[i] == window_low.min() and (lows[i] < window_low[[0, -1]]).all():\n",
    "                swing_low[i] = 1\n",
    "\n",
    "        g[\"swing_high\"] = swing_high\n",
    "        g[\"swing_low\"] = swing_low\n",
    "\n",
    "        # Now label HH/HL/LH/LL only on swing points\n",
    "        structure = []\n",
    "        last_swing_high = None\n",
    "        last_swing_low = None\n",
    "\n",
    "        for i, row in g.iterrows():\n",
    "            label = \"NONE\"\n",
    "            if row[\"swing_high\"] == 1:\n",
    "                if last_swing_high is None:\n",
    "                    label = \"SH\"\n",
    "                else:\n",
    "                    if row[\"high\"] > last_swing_high:\n",
    "                        label = \"HH\"\n",
    "                    else:\n",
    "                        label = \"LH\"\n",
    "                last_swing_high = row[\"high\"]\n",
    "\n",
    "            elif row[\"swing_low\"] == 1:\n",
    "                if last_swing_low is None:\n",
    "                    label = \"SL\"\n",
    "                else:\n",
    "                    if row[\"low\"] > last_swing_low:\n",
    "                        label = \"HL\"\n",
    "                    else:\n",
    "                        label = \"LL\"\n",
    "                last_swing_low = row[\"low\"]\n",
    "\n",
    "            structure.append(label)\n",
    "\n",
    "        g[\"structure_label\"] = structure\n",
    "        return g\n",
    "\n",
    "    df = df.groupby(\"symbol\", group_keys=False).apply(_find_swings)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85f4ea",
   "metadata": {},
   "source": [
    "#### =========================\n",
    "#### 6. TARGETS (FUTURE RETURNS)\n",
    "#### ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f299a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_targets(\n",
    "    df: pd.DataFrame,\n",
    "    horizons: List[int] = [1, 5, 21]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add future returns and classification labels.\n",
    "    For each horizon h:\n",
    "      - future_ret_h = close(t+h) / close(t) - 1\n",
    "      - target_up_h = 1 if future_ret_h > 0 else 0\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    def _per_symbol(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = g.sort_values(\"date\").copy()\n",
    "        for h in horizons:\n",
    "            fut_close = g[\"close\"].shift(-h)\n",
    "            fut_ret = fut_close / g[\"close\"] - 1.0\n",
    "            col_ret = f\"future_ret_{h}d\"\n",
    "            col_target = f\"target_up_{h}d\"\n",
    "\n",
    "            g[col_ret] = fut_ret\n",
    "            g[col_target] = (fut_ret > 0).astype(int)\n",
    "        return g\n",
    "\n",
    "    df = df.groupby(\"symbol\", group_keys=False).apply(_per_symbol)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc809b0a",
   "metadata": {},
   "source": [
    "#### =========================\n",
    "#### 7. MASTER PIPELINE\n",
    "#### ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62c857cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ohlcv_ml_ready(\n",
    "    symbols: List[str],\n",
    "    start_date: dt.date,\n",
    "    end_date: dt.date,\n",
    "    output_parquet: str\n",
    ") -> pd.DataFrame:\n",
    "    print(\"Step 1: Downloading data...\")\n",
    "    ohlcv = download_ohlcv_nsepy(symbols, start_date, end_date)\n",
    "\n",
    "    print(\"Step 2: Cleaning data...\")\n",
    "    ohlcv = clean_ohlcv(ohlcv)\n",
    "\n",
    "    print(\"Step 3: Adding technical indicators...\")\n",
    "    ohlcv = add_technical_indicators(ohlcv)\n",
    "\n",
    "    print(\"Step 4: Adding candlestick patterns...\")\n",
    "    ohlcv = add_candlestick_patterns(ohlcv)\n",
    "\n",
    "    print(\"Step 5: Adding price structure (swings + HH/HL/LH/LL)...\")\n",
    "    ohlcv = add_price_structure(ohlcv)\n",
    "\n",
    "    print(\"Step 6: Adding targets (future returns)...\")\n",
    "    ohlcv = add_targets(ohlcv, horizons=[1, 5, 21])\n",
    "\n",
    "    print(f\"Step 7: Saving to Parquet at: {output_parquet}\")\n",
    "    ohlcv.to_parquet(output_parquet, index=False)\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return ohlcv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e9d50",
   "metadata": {},
   "source": [
    "#### =========================\n",
    "#### 8. SCRIPT ENTRY POINT\n",
    "#### ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b252ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Downloading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading OHLCV (jugaad-data): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.15s/it]\n",
      "/var/folders/p3/60vrwk2d3hd35fqf22v9w1z40000gn/T/ipykernel_47270/3990357214.py:77: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"symbol\", group_keys=False).apply(_per_symbol)\n",
      "/var/folders/p3/60vrwk2d3hd35fqf22v9w1z40000gn/T/ipykernel_47270/3368666428.py:66: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"symbol\", group_keys=False).apply(_per_symbol)\n",
      "/var/folders/p3/60vrwk2d3hd35fqf22v9w1z40000gn/T/ipykernel_47270/73925026.py:69: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"symbol\", group_keys=False).apply(_find_swings)\n",
      "/var/folders/p3/60vrwk2d3hd35fqf22v9w1z40000gn/T/ipykernel_47270/4120066488.py:25: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(\"symbol\", group_keys=False).apply(_per_symbol)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Cleaning data...\n",
      "Step 3: Adding technical indicators...\n",
      "Step 4: Adding candlestick patterns...\n",
      "Step 5: Adding price structure (swings + HH/HL/LH/LL)...\n",
      "Step 6: Adding targets (future returns)...\n",
      "Step 7: Saving to Parquet at: data/ohlcv_ml_ready.parquet\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>symbol</th>\n",
       "      <th>ret_1d</th>\n",
       "      <th>log_ret_1d</th>\n",
       "      <th>vol_20d</th>\n",
       "      <th>...</th>\n",
       "      <th>pat_doji</th>\n",
       "      <th>swing_high</th>\n",
       "      <th>swing_low</th>\n",
       "      <th>structure_label</th>\n",
       "      <th>future_ret_1d</th>\n",
       "      <th>target_up_1d</th>\n",
       "      <th>future_ret_5d</th>\n",
       "      <th>target_up_5d</th>\n",
       "      <th>future_ret_21d</th>\n",
       "      <th>target_up_21d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>1216.4</td>\n",
       "      <td>1223.2</td>\n",
       "      <td>1208.10</td>\n",
       "      <td>1210.70</td>\n",
       "      <td>8818766</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1219.1</td>\n",
       "      <td>1206.15</td>\n",
       "      <td>1215.45</td>\n",
       "      <td>6405475</td>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    open    high      low    close   volume    symbol    ret_1d  \\\n",
       "0 2024-12-30  1216.4  1223.2  1208.10  1210.70  8818766  RELIANCE       NaN   \n",
       "1 2024-12-31  1208.0  1219.1  1206.15  1215.45  6405475  RELIANCE  0.003923   \n",
       "\n",
       "   log_ret_1d  vol_20d  ...  pat_doji  swing_high  swing_low  structure_label  \\\n",
       "0         NaN      NaN  ...         0           0          0             NONE   \n",
       "1    0.003916      NaN  ...         0           0          0             NONE   \n",
       "\n",
       "   future_ret_1d  target_up_1d  future_ret_5d  target_up_5d  future_ret_21d  \\\n",
       "0       0.003923             1            NaN             0             NaN   \n",
       "1            NaN             0            NaN             0             NaN   \n",
       "\n",
       "   target_up_21d  \n",
       "0              0  \n",
       "1              0  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ðŸ”§ TODO: customise this list for your dissertation universe\n",
    "SYMBOLS = [\n",
    "    \"RELIANCE\",\n",
    "    # \"TCS\",\n",
    "    # \"HDFCBANK\",\n",
    "    # \"INFY\",\n",
    "    # \"ICICIBANK\",\n",
    "    # add more symbols as needed\n",
    "]\n",
    "\n",
    "START = dt.date(2024, 12, 30)\n",
    "END = dt.date(2024, 12, 31)\n",
    "\n",
    "OUTPUT_PATH = \"data/sample_ohlcv_ml_ready.parquet\"\n",
    "\n",
    "# Make sure 'data' folder exists\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "build_ohlcv_ml_ready(SYMBOLS, START, END, OUTPUT_PATH)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
