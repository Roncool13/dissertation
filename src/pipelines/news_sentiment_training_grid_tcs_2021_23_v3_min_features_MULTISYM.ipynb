{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb18537",
   "metadata": {
    "id": "0fb18537"
   },
   "source": "# Sentiment Expert Training (MULTI-SYMBOL) (DVC + MLflow)\n\nThis notebook trains a **sentiment-only** baseline expert using the **daily aggregated FinBERT features** produced by the news feature-build pipeline, and joins them with the OHLCV-derived label (`y_up_*d`).\n\nFlow:\n- Clone repo + `dvc pull` (reproducible dataset version)\n- Load `news_sentiment_features.parquet` + OHLCV labels\n- Apply the same metadata-driven date splits (from OHLCV metadata)\n- TrainCV (TimeSeriesSplit) on TRAIN only, select via VAL, refit on TRAIN+VAL\n- Log to MLflow + register model\n"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a0552d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8a0552d",
    "outputId": "42f62b2c-cf95-40ec-e491-84e103f267ef"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.3/261.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.3/113.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.5/445.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.2/214.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.1/74.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.7/469.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.3/788.3 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2026.1.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2026.1.0 which is incompatible.\n",
      "google-adk 1.21.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install deps (Colab)\n",
    "!pip -q install feast==0.58.0 s3fs boto3 pyarrow pandas scikit-learn \"mlflow>=2.12,<3\" \"dagshub==0.6.4\" \"dvc[s3]\" transformers torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8e730",
   "metadata": {
    "id": "8cd8e730"
   },
   "source": "## 1) Credentials / Environment\nSet these using Colab `userdata` (or replace with your own method)."
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d12a5f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d12a5f7",
    "outputId": "b22e3f55-f405-42e2-9a91-1a09c3c8ac27"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Secrets loaded: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION, DAGSHUB_USER_TOKEN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# AWS\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWS_ACCESS_KEY_ID')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
    "os.environ['AWS_DEFAULT_REGION'] = userdata.get('AWS_DEFAULT_REGION') or 'us-east-1'\n",
    "\n",
    "# MLflow (DAGsHub)\n",
    "os.environ[\"DAGSHUB_USER_TOKEN\"] = userdata.get('DAGSHUB_TOKEN')\n",
    "\n",
    "missing = [k for k in ['AWS_ACCESS_KEY_ID','AWS_SECRET_ACCESS_KEY','DAGSHUB_USER_TOKEN'] if not os.environ.get(k)]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing secrets in Colab userdata: {missing}\")\n",
    "print('Secrets loaded:', ', '.join(['AWS_ACCESS_KEY_ID','AWS_SECRET_ACCESS_KEY','AWS_DEFAULT_REGION','DAGSHUB_USER_TOKEN']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bdb0d",
   "metadata": {
    "id": "ed8bdb0d"
   },
   "source": "## 2) Clone repo + pull DVC dataset\nThis ensures `git_sha` and `.dvc` pointers exist locally, and that the dataset version is reproducible."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdf2eae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fdf2eae",
    "outputId": "7f0acd4b-0a78-4abc-c2ae-8913068d8408"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'dissertation'...\n",
      "remote: Enumerating objects: 815, done.\u001b[K\n",
      "remote: Counting objects: 100% (345/345), done.\u001b[K\n",
      "remote: Compressing objects: 100% (206/206), done.\u001b[K\n",
      "remote: Total 815 (delta 196), reused 262 (delta 118), pack-reused 470 (from 1)\u001b[K\n",
      "Receiving objects: 100% (815/815), 275.04 KiB | 1.96 MiB/s, done.\n",
      "Resolving deltas: 100% (493/493), done.\n",
      "/content/dissertation\n",
      "Already on 'main'\n",
      "Your branch is up to date with 'origin/main'.\n",
      "Collecting          |1.00 [00:00, 36.0entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "Fetching from s3:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
      "Fetching from s3:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
      "\n",
      "  0% 0.00/550k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 0.00/550k [00:00<?, ?B/s{'info': ''}]\u001b[A\u001b[A\n",
      "\n",
      " 12% 67.5k/550k [00:00<00:00, 618kB/s{'info': ''}]\u001b[A\u001b[A\n",
      "\n",
      " 53% 289k/550k [00:00<00:00, 1.41MB/s{'info': ''}]\u001b[A\u001b[A\n",
      "\n",
      "                                                  \u001b[A\u001b[A\n",
      "Fetching from s3: 100% 1/1 [00:00<00:00,  2.53file/s{'info': ''}]\u001b[A\n",
      "Fetching\n",
      "Building workspace index          |2.00 [00:00, 47.3entry/s]\n",
      "Comparing indexes          |4.00 [00:00,  661entry/s]\n",
      "Applying changes          |1.00 [00:00,  74.1file/s]\n",
      "\u001b[32mA\u001b[0m       data/features/ohlcv_features.parquet\n",
      "1 file fetched and 1 file added\n",
      "Collecting          |1.00 [00:00, 25.7entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "Fetching from s3:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
      "Fetching from s3:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
      "\n",
      "  0% 0.00/2.22k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 0.00/2.22k [00:00<?, ?B/s{'info': ''}]\u001b[A\u001b[A\n",
      "\n",
      "                                           \u001b[A\u001b[A\n",
      "Fetching from s3: 100% 1/1 [00:00<00:00,  9.19file/s{'info': ''}]\u001b[A\n",
      "Fetching\n",
      "Building workspace index          |2.00 [00:00, 15.7entry/s]\n",
      "Comparing indexes          |4.00 [00:00, 72.2entry/s]\n",
      "Applying changes          |1.00 [00:00,  41.1file/s]\n",
      "\u001b[32mA\u001b[0m       data/features/ohlcv_feature_metadata.json\n",
      "1 file fetched and 1 file added\n",
      "Collecting          |1.00 [00:00, 34.3entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "Fetching from s3:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
      "Fetching from s3:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
      "\n",
      "  0% 0.00/333k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 0.00/333k [00:00<?, ?B/s{'info': ''}]\u001b[A\u001b[A\n",
      "\n",
      " 34% 115k/333k [00:00<00:00, 992kB/s{'info': ''}]\u001b[A\u001b[A\n",
      "\n",
      "100% 333k/333k [00:00<00:00, 1.52MB/s{'info': ''}]\u001b[A\u001b[A\n",
      "\n",
      "                                                  \u001b[A\u001b[A\n",
      "Fetching from s3: 100% 1/1 [00:00<00:00,  2.64file/s{'info': ''}]\u001b[A\n",
      "Fetching\n",
      "Building workspace index          |2.00 [00:00, 39.5entry/s]\n",
      "Comparing indexes          |4.00 [00:00,  335entry/s]\n",
      "Applying changes          |1.00 [00:00,  94.7file/s]\n",
      "\u001b[32mA\u001b[0m       data/features/news_sentiment_features.parquet\n",
      "1 file fetched and 1 file added\n",
      "Collecting          |1.00 [00:00, 52.0entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "!\u001b[A\n",
      "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "                                           \u001b[A\n",
      "Fetching from s3:   0% 0/1 [00:00<?, ?file/s]\u001b[A\n",
      "Fetching from s3:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\u001b[A\n",
      "\n",
      "  0% 0.00/4.32k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 0.00/4.32k [00:00<?, ?B/s{'info': ''}]\u001b[A\u001b[A\n",
      "\n",
      "                                           \u001b[A\u001b[A\n",
      "Fetching\n",
      "Building workspace index          |2.00 [00:00, 49.9entry/s]\n",
      "Comparing indexes          |4.00 [00:00,  701entry/s]\n",
      "Applying changes          |1.00 [00:00,   147file/s]\n",
      "\u001b[32mA\u001b[0m       data/features/news_sentiment_feature_metadata.json\n",
      "1 file fetched and 1 file added\n",
      "\u001b[0m/content\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "REPO_NAME = \"dissertation\"  # change if needed\n",
    "REPO_URL = f\"https://github.com/Roncool13/{REPO_NAME}.git\"\n",
    "BRANCH_OR_COMMIT = \"main\"  # or a specific commit hash for perfect reproducibility\n",
    "\n",
    "if not Path(REPO_NAME).exists():\n",
    "    !git clone {REPO_URL}\n",
    "%cd {REPO_NAME}\n",
    "!git checkout {BRANCH_OR_COMMIT}\n",
    "\n",
    "# Pull DVC-versioned dataset artifacts\n",
    "!dvc pull data/features/ohlcv_features.parquet\n",
    "!dvc pull data/features/ohlcv_feature_metadata.json\n",
    "!dvc pull data/features/news_sentiment_features.parquet\n",
    "!dvc pull data/features/news_sentiment_feature_metadata.json\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d00cd",
   "metadata": {
    "id": "d85d00cd"
   },
   "source": "## 3) MLflow setup"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43c5cab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "d43c5cab",
    "outputId": "a5813f8f-0492-4550-8a8c-0ff519a4a9d2"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Accessing as Roncool13\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Roncool13\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Roncool13/dissertation-mlflow\"\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Roncool13/dissertation-mlflow\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Repository Roncool13/dissertation-mlflow initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Roncool13/dissertation-mlflow initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLflow tracking URI: https://dagshub.com/Roncool13/dissertation-mlflow.mlflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import dagshub\n",
    "\n",
    "dagshub.init(repo_owner='Roncool13', repo_name='dissertation-mlflow', mlflow=True)\n",
    "mlflow.set_experiment(\"dissertation-sentiment-prediction\")\n",
    "mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "print('MLflow tracking URI:', mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c1823",
   "metadata": {
    "id": "650c1823"
   },
   "source": "## 4) Reproducibility + dataset lineage logging (Git + DVC)"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4102528",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c4102528",
    "outputId": "5380ff42-8ff2-40f7-8c22-effc9510a8d4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import hashlib\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "def _run(cmd):\n",
    "    return subprocess.check_output(cmd, text=True).strip()\n",
    "\n",
    "def _sha256_file(path):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, 'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(1024*1024), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def log_code_and_data_version():\n",
    "    # Git commit\n",
    "    try:\n",
    "        mlflow.set_tag('git_sha', _run(['git','rev-parse','HEAD']))\n",
    "    except Exception:\n",
    "        mlflow.set_tag('git_sha', 'unavailable')\n",
    "\n",
    "    # DVC pointer hashes (these change when the dataset changes)\n",
    "    for tag, p in [\n",
    "        ('dvc_ptr_features_sha256', f'{REPO_NAME}/data/features/ohlcv_features.parquet.dvc'),\n",
    "        ('dvc_ptr_metadata_sha256', f'{REPO_NAME}/data/features/ohlcv_feature_metadata.json.dvc'),\n",
    "    ]:\n",
    "        try:\n",
    "            mlflow.set_tag(tag, _sha256_file(p))\n",
    "        except Exception:\n",
    "            mlflow.set_tag(tag, 'unavailable')\n",
    "\n",
    "    # Log pointer files + metadata as artifacts (small, very useful)\n",
    "    for p, ap in [\n",
    "        (f'{REPO_NAME}/data/features/ohlcv_features.parquet.dvc', 'dataset_pointers'),\n",
    "        (f'{REPO_NAME}/data/features/ohlcv_feature_metadata.json.dvc', 'dataset_pointers'),\n",
    "        (f'{REPO_NAME}/data/features/ohlcv_feature_metadata.json', 'dataset_metadata'),\n",
    "    ]:\n",
    "        try:\n",
    "            mlflow.log_artifact(p, artifact_path=ap)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Log key metadata as params/tags\n",
    "    meta = json.loads(Path(f'{REPO_NAME}/data/features/ohlcv_feature_metadata.json').read_text())\n",
    "    splits = meta.get('splits', {})\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'dataset_name': 'ohlcv_features',\n",
    "        'symbols_count': meta.get('symbols_count', len(meta.get('symbols', []))),\n",
    "        'start_year': meta.get('start_year'),\n",
    "        'end_year': meta.get('end_year'),\n",
    "        'horizon_days': meta.get('horizon_days'),\n",
    "        'lags': ','.join(map(str, meta.get('lags', []))),\n",
    "        'split_scheme': splits.get('scheme'),\n",
    "        'seed': SEED,\n",
    "    })\n",
    "\n",
    "    if 'train' in splits and 'val' in splits and 'test' in splits:\n",
    "        mlflow.set_tags({\n",
    "            'train_period': f\"{splits['train']['start']}:{splits['train']['end']}\",\n",
    "            'val_period': f\"{splits['val']['start']}:{splits['val']['end']}\",\n",
    "            'test_period': f\"{splits['test']['start']}:{splits['test']['end']}\",\n",
    "        })\n",
    "\n",
    "print('Seed set to', SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57dffe5",
   "metadata": {
    "id": "c57dffe5"
   },
   "source": "## 5) Load dataset + apply metadata-driven splits\nWe use OHLCV metadata splits (train/val/test date ranges) so that expert models are comparable on the same time windows."
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d1d8ba7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d1d8ba7",
    "outputId": "3c7c6ac6-6953-4976-cfcb-c3e4641ee25c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentiment features columns: 130\n",
      "Sentiment head:\n",
      "   symbol       date  article_count  pos_count  neg_count  neu_count  \\\n",
      "0    TCS 2021-01-01           10.0          6          0          4   \n",
      "1    TCS 2021-01-04           19.0         17          0          2   \n",
      "\n",
      "   highrel_count  rel_score_mean  sent_conf_mean  polarity_mean  polarity_std  \\\n",
      "0              0        0.016140        0.862809       0.600000      0.516398   \n",
      "1              0        0.009732        0.858335       0.894737      0.315302   \n",
      "\n",
      "   polarity_wmean  highrel_polarity_mean  highrel_polarity_wmean  pos_ratio  \\\n",
      "0        0.736733                    0.0                     0.0   0.600000   \n",
      "1        0.935498                    0.0                     0.0   0.894737   \n",
      "\n",
      "   neg_ratio  neu_ratio  highrel_ratio  sent_cov  sent_abs  imbalance  \\\n",
      "0        0.0   0.400000            0.0  1.766608  0.736733   0.600000   \n",
      "1        0.0   0.105263            0.0  2.802500  0.935498   0.894737   \n",
      "\n",
      "   highrel_impact  news_present  article_count_lag_1  pos_ratio_lag_1  \\\n",
      "0             0.0           1.0                  0.0              0.0   \n",
      "1             0.0           1.0                  5.0              1.0   \n",
      "\n",
      "   neg_ratio_lag_1  neu_ratio_lag_1  highrel_ratio_lag_1  \\\n",
      "0              0.0              0.0                  0.0   \n",
      "1              0.0              0.0                  0.0   \n",
      "\n",
      "   rel_score_mean_lag_1  sent_conf_mean_lag_1  polarity_mean_lag_1  \\\n",
      "0              0.000000               0.00000                  0.0   \n",
      "1              0.018137               0.78323                  1.0   \n",
      "\n",
      "   polarity_std_lag_1  polarity_wmean_lag_1  highrel_polarity_mean_lag_1  \\\n",
      "0                 0.0                   0.0                          0.0   \n",
      "1                 0.0                   1.0                          0.0   \n",
      "\n",
      "   highrel_polarity_wmean_lag_1  sent_cov_lag_1  sent_abs_lag_1  \\\n",
      "0                           0.0        0.000000             0.0   \n",
      "1                           0.0        1.791759             1.0   \n",
      "\n",
      "   imbalance_lag_1  highrel_impact_lag_1  news_present_lag_1  \\\n",
      "0              0.0                   0.0                 0.0   \n",
      "1              1.0                   0.0                 1.0   \n",
      "\n",
      "   article_count_lag_2  pos_ratio_lag_2  neg_ratio_lag_2  neu_ratio_lag_2  \\\n",
      "0                  0.0              0.0              0.0              0.0   \n",
      "1                  1.0              1.0              0.0              0.0   \n",
      "\n",
      "   highrel_ratio_lag_2  rel_score_mean_lag_2  sent_conf_mean_lag_2  \\\n",
      "0                  0.0              0.000000              0.000000   \n",
      "1                  0.0              0.000359              0.940881   \n",
      "\n",
      "   polarity_mean_lag_2  polarity_std_lag_2  polarity_wmean_lag_2  \\\n",
      "0                  0.0                 0.0                   0.0   \n",
      "1                  1.0                 0.0                   1.0   \n",
      "\n",
      "   highrel_polarity_mean_lag_2  highrel_polarity_wmean_lag_2  sent_cov_lag_2  \\\n",
      "0                          0.0                           0.0        0.000000   \n",
      "1                          0.0                           0.0        0.693147   \n",
      "\n",
      "   sent_abs_lag_2  imbalance_lag_2  highrel_impact_lag_2  news_present_lag_2  \\\n",
      "0             0.0              0.0                   0.0                 0.0   \n",
      "1             1.0              1.0                   0.0                 1.0   \n",
      "\n",
      "   article_count_lag_3  pos_ratio_lag_3  neg_ratio_lag_3  neu_ratio_lag_3  \\\n",
      "0                  0.0              0.0              0.0              0.0   \n",
      "1                 10.0              0.6              0.0              0.4   \n",
      "\n",
      "   highrel_ratio_lag_3  rel_score_mean_lag_3  sent_conf_mean_lag_3  \\\n",
      "0                  0.0               0.00000              0.000000   \n",
      "1                  0.0               0.01614              0.862809   \n",
      "\n",
      "   polarity_mean_lag_3  polarity_std_lag_3  polarity_wmean_lag_3  \\\n",
      "0                  0.0            0.000000              0.000000   \n",
      "1                  0.6            0.516398              0.736733   \n",
      "\n",
      "   highrel_polarity_mean_lag_3  highrel_polarity_wmean_lag_3  sent_cov_lag_3  \\\n",
      "0                          0.0                           0.0        0.000000   \n",
      "1                          0.0                           0.0        1.766608   \n",
      "\n",
      "   sent_abs_lag_3  imbalance_lag_3  highrel_impact_lag_3  news_present_lag_3  \\\n",
      "0        0.000000              0.0                   0.0                 0.0   \n",
      "1        0.736733              0.6                   0.0                 1.0   \n",
      "\n",
      "   article_count_lag_4  pos_ratio_lag_4  neg_ratio_lag_4  neu_ratio_lag_4  \\\n",
      "0                  0.0              0.0              0.0              0.0   \n",
      "1                  0.0              0.0              0.0              0.0   \n",
      "\n",
      "   highrel_ratio_lag_4  rel_score_mean_lag_4  sent_conf_mean_lag_4  \\\n",
      "0                  0.0                   0.0                   0.0   \n",
      "1                  0.0                   0.0                   0.0   \n",
      "\n",
      "   polarity_mean_lag_4  polarity_std_lag_4  polarity_wmean_lag_4  \\\n",
      "0                  0.0                 0.0                   0.0   \n",
      "1                  0.0                 0.0                   0.0   \n",
      "\n",
      "   highrel_polarity_mean_lag_4  highrel_polarity_wmean_lag_4  sent_cov_lag_4  \\\n",
      "0                          0.0                           0.0             0.0   \n",
      "1                          0.0                           0.0             0.0   \n",
      "\n",
      "   sent_abs_lag_4  imbalance_lag_4  highrel_impact_lag_4  news_present_lag_4  \\\n",
      "0             0.0              0.0                   0.0                 0.0   \n",
      "1             0.0              0.0                   0.0                 0.0   \n",
      "\n",
      "   article_count_lag_5  pos_ratio_lag_5  neg_ratio_lag_5  neu_ratio_lag_5  \\\n",
      "0                  0.0              0.0              0.0              0.0   \n",
      "1                  0.0              0.0              0.0              0.0   \n",
      "\n",
      "   highrel_ratio_lag_5  rel_score_mean_lag_5  sent_conf_mean_lag_5  \\\n",
      "0                  0.0                   0.0                   0.0   \n",
      "1                  0.0                   0.0                   0.0   \n",
      "\n",
      "   polarity_mean_lag_5  polarity_std_lag_5  polarity_wmean_lag_5  \\\n",
      "0                  0.0                 0.0                   0.0   \n",
      "1                  0.0                 0.0                   0.0   \n",
      "\n",
      "   highrel_polarity_mean_lag_5  highrel_polarity_wmean_lag_5  sent_cov_lag_5  \\\n",
      "0                          0.0                           0.0             0.0   \n",
      "1                          0.0                           0.0             0.0   \n",
      "\n",
      "   sent_abs_lag_5  imbalance_lag_5  highrel_impact_lag_5  news_present_lag_5  \\\n",
      "0             0.0              0.0                   0.0                 0.0   \n",
      "1             0.0              0.0                   0.0                 0.0   \n",
      "\n",
      "   sent_cov_roll_mean_3  sent_cov_roll_std_3  article_count_roll_mean_3  \\\n",
      "0              0.000000              0.00000                   0.000000   \n",
      "1              1.417172              0.62715                   5.333333   \n",
      "\n",
      "   sent_cov_roll_mean_5  sent_cov_roll_std_5  article_count_roll_mean_5  \\\n",
      "0              0.000000              0.00000                   0.000000   \n",
      "1              1.417172              0.62715                   5.333333   \n",
      "\n",
      "   sent_cov_roll_mean_10  sent_cov_roll_std_10  article_count_roll_mean_10  \\\n",
      "0                    0.0                   0.0                         0.0   \n",
      "1                    0.0                   0.0                         0.0   \n",
      "\n",
      "   sent_cov_roll_mean_20  sent_cov_roll_std_20  article_count_roll_mean_20  \\\n",
      "0                    0.0                   0.0                         0.0   \n",
      "1                    0.0                   0.0                         0.0   \n",
      "\n",
      "   polarity_wmean_z20  polarity_wmean_pos_shock  polarity_wmean_neg_shock  \\\n",
      "0                 0.0                       0.0                       0.0   \n",
      "1                 0.0                       0.0                       0.0   \n",
      "\n",
      "   sent_cov_z20  sent_cov_pos_shock  sent_cov_neg_shock  article_count_z20  \\\n",
      "0           0.0                 0.0                 0.0                0.0   \n",
      "1           0.0                 0.0                 0.0                0.0   \n",
      "\n",
      "   article_count_pos_shock  article_count_neg_shock  y_up_5d  \n",
      "0                      0.0                      0.0        1  \n",
      "1                      0.0                      0.0        1  \n",
      "Label col: y_up_5d\n",
      "Skipping notebook shift: sentiment features already leakage-safe (lags/rolls present or metadata says shifted).\n",
      "Using label from sentiment features parquet: y_up_5d\n",
      "Duplicate (symbol,date) rows: 0\n",
      "Merged df rows: 636\n",
      "Date min/max: 2021-01-01 00:00:00 2023-09-07 00:00:00\n",
      "Shapes -> train/val/test: (243, 130) (231, 130) (162, 130)\n",
      "train class balance: {1: 0.5925925925925926, 0: 0.4074074074074074}\n",
      "train feature variance sanity (std of 3 cols): {'article_count': 9.823736495245626, 'pos_count': 5.598204827388173, 'neg_count': 2.9850151212266343}\n",
      "val class balance: {0: 0.5021645021645021, 1: 0.49783549783549785}\n",
      "val feature variance sanity (std of 3 cols): {'article_count': 8.632161399513688, 'pos_count': 4.056434195829279, 'neg_count': 2.610732312441768}\n",
      "test class balance: {1: 0.5493827160493827, 0: 0.4506172839506173}\n",
      "test feature variance sanity (std of 3 cols): {'article_count': 8.949630712255393, 'pos_count': 3.5348994536886114, 'neg_count': 2.818541477452144}\n"
     ]
    }
   ],
   "source": "import re\nimport pandas as pd\nimport numpy as np\nimport json\nfrom pathlib import Path\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# --- Load sentiment features ---\nsent = pd.read_parquet(f'{REPO_NAME}/data/features/news_sentiment_features.parquet')\nnews_meta = json.loads(Path(f'{REPO_NAME}/data/features/news_sentiment_feature_metadata.json').read_text())\n\nprint(f\"Sentiment features columns: {len(sent.columns)}\")\nprint(\"Sentiment head:\\n\", sent.head(2))\n\n# --- Load OHLCV for splits (and labels only if needed) ---\nohlcv = pd.read_parquet(f'{REPO_NAME}/data/features/ohlcv_features.parquet')\nohlcv_meta = json.loads(Path(f'{REPO_NAME}/data/features/ohlcv_feature_metadata.json').read_text())\n\n# Ensure datetime\nfor _df in (sent, ohlcv):\n    _df[\"date\"] = pd.to_datetime(_df[\"date\"])\n\n# Optional: single symbol baseline\nSYMBOL = None  # set to \"TCS\" for debugging, else None for multisymbol\nif SYMBOL:\n    sent = sent[sent[\"symbol\"] == SYMBOL].copy()\n    ohlcv = ohlcv[ohlcv[\"symbol\"] == SYMBOL].copy()\n\n# Label column name (from sentiment metadata supervision)\nlabel_col = news_meta[\"supervision\"][\"label_col_name\"]\nprint(\"Label col:\", label_col)\n\nkey_cols = [\"symbol\", \"date\"]\n\n# ---------- (1) leakage-safe shift ----------\nsent = sent.sort_values(key_cols).reset_index(drop=True)\n\nsent_feature_cols = [c for c in sent.columns if c not in key_cols and c != label_col]\n\n# Detect if pipeline already produced lag/roll features (so shifting again would double-shift)\nalready_lagged = any((\"_lag_\" in c) or (\"_roll_\" in c) for c in sent_feature_cols)\n\n# Optional: metadata-driven flag (use if you store it in news_meta)\nmeta_shift = None\ntry:\n    meta_shift = news_meta.get(\"supervision\", {}).get(\"feature_shift_days\", None)\nexcept Exception:\n    meta_shift = None\n\nif (meta_shift == 1) or already_lagged:\n    print(\"Skipping notebook shift: sentiment features already leakage-safe (lags/rolls present or metadata says shifted).\")\nelse:\n    print(\"WARNING: No lag/roll features detected and metadata does not indicate pre-shifting.\\n\"\n          \"In multi-symbol training, we *do not* apply notebook shifting by default to avoid mismatching the feature-build logic.\\n\"\n          \"If you are sure your features are same-day (leaky), set meta_shift=0 and enable shifting explicitly.\")\n\n# ---------- (2) Build df with a SINGLE label source (avoid _x/_y collisions) ----------\nif label_col in sent.columns:\n    # Use label already present in sentiment parquet\n    df = sent.copy()\n    # Ensure label not NaN\n    df = df.dropna(subset=[label_col]).reset_index(drop=True)\n    print(f\"Using label from sentiment features parquet: {label_col}\")\nelse:\n    # Merge label from OHLCV only if sentiment parquet doesn't have it\n    labels = ohlcv[[\"symbol\", \"date\", label_col]].dropna(subset=[label_col]).copy()\n    df = sent.merge(labels, on=key_cols, how=\"inner\").reset_index(drop=True)\n    print(f\"Using label from OHLCV merge: {label_col}\")\n\ndf = df.sort_values(key_cols).reset_index(drop=True)\n\n# ---------- (3) sanity checks: alignment + duplicates ----------\n# No duplicate (symbol,date)\ndup_cnt = int(df.duplicated(subset=key_cols).sum())\nprint(\"Duplicate (symbol,date) rows:\", dup_cnt)\nif dup_cnt > 0:\n    # Keep the first occurrence deterministically\n    df = df.drop_duplicates(subset=key_cols, keep=\"first\").reset_index(drop=True)\n    print(\"Dropped duplicates. New rows:\", len(df))\n\n# Confirm label column exists exactly\nassert label_col in df.columns, f\"Label column {label_col} missing. Columns contain: {[c for c in df.columns if 'y_' in c][:20]}\"\n\n# Confirm no leftover suffix label columns\nsuffix_cols = [c for c in df.columns if c in [f\"{label_col}_x\", f\"{label_col}_y\"]]\nif suffix_cols:\n    raise RuntimeError(f\"Found suffix label columns {suffix_cols}. This should not happen with single-source label logic.\")\n\n# ---------- (4) Apply OHLCV metadata-driven splits ----------\nsplits = None\n# Prefer NEWS metadata supervision splits (comes from OHLCV metadata inside feature build)\ntry:\n    if news_meta.get(\"supervision\", {}).get(\"enabled\") and news_meta.get(\"supervision\", {}).get(\"splits\"):\n        splits = news_meta[\"supervision\"][\"splits\"]\nexcept Exception:\n    splits = None\n# Fallback to OHLCV metadata\nif not splits:\n    splits = ohlcv_meta[\"splits\"]\n\n\ndef split_by_date(frame, split):\n    start = pd.to_datetime(split[\"start\"])\n    end = pd.to_datetime(split[\"end\"])\n    return frame[(frame[\"date\"] >= start) & (frame[\"date\"] <= end)].copy()\n\ntrain_df = split_by_date(df, splits[\"train\"])\nval_df   = split_by_date(df, splits[\"val\"])\ntest_df  = split_by_date(df, splits[\"test\"])\n\nprint(\"Merged df rows:\", len(df))\nprint(\"Date min/max:\", df[\"date\"].min(), df[\"date\"].max())\nprint(\"Shapes -> train/val/test:\", train_df.shape, val_df.shape, test_df.shape)\n\nfor name, part in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n    if len(part) == 0:\n        print(name, \"EMPTY\")\n        continue\n    print(name, \"class balance:\", part[label_col].value_counts(normalize=True).to_dict())\n    # quick signal check: do we have variance in features?\n    print(name, \"feature variance sanity (std of 3 cols):\",\n          {c: float(part[c].std()) for c in sent_feature_cols[:3]})"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "97a41d54",
    "outputId": "e1b01e48-0fcf-47cf-b800-15bf1a1b6861"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame with many columns and rows\n",
    "data = np.random.rand(50, 20)\n",
    "columns = [f'col_{i}' for i in range(20)]\n",
    "df_example = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Display the DataFrame with default options (likely truncated)\n",
    "print(\"Default display (might be truncated):\")\n",
    "display(df_example.head())\n",
    "\n",
    "# Set options to display all columns and up to 100 rows\n",
    "pd.set_option('display.max_columns', None) # Display all columns\n",
    "pd.set_option('display.max_rows', 100)    # Display up to 100 rows\n",
    "\n",
    "print(\"\\nDisplay with increased limits (all columns, more rows):\")\n",
    "display(df_example)\n",
    "\n",
    "# To reset to default display options:\n",
    "# pd.reset_option('display.max_columns')\n",
    "# pd.reset_option('display.max_rows')\n",
    "\n",
    "print(\"\\nDisplaying first 10 rows to illustrate row handling (if max_rows < actual rows):\")\n",
    "display(df_example.head(10))"
   ],
   "id": "97a41d54",
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Default display (might be truncated):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0  0.261706  0.246979  0.906255  0.249546  0.271950  0.759398  0.449740   \n",
       "1  0.963394  0.560168  0.936822  0.052258  0.418793  0.260158  0.730821   \n",
       "2  0.850616  0.561223  0.523391  0.114769  0.860140  0.722814  0.067668   \n",
       "3  0.062273  0.512503  0.806404  0.459240  0.051957  0.786278  0.201364   \n",
       "4  0.027167  0.065205  0.463931  0.909220  0.538702  0.497813  0.105474   \n",
       "\n",
       "      col_7     col_8     col_9    col_10    col_11    col_12    col_13  \\\n",
       "0  0.776711  0.065366  0.487571  0.033614  0.062653  0.906437  0.139245   \n",
       "1  0.981297  0.256530  0.654175  0.198098  0.565330  0.463932  0.972005   \n",
       "2  0.707835  0.543538  0.081725  0.458301  0.484696  0.165775  0.945698   \n",
       "3  0.258621  0.164706  0.330215  0.756752  0.519386  0.204881  0.877830   \n",
       "4  0.656780  0.822103  0.380420  0.775612  0.964477  0.203766  0.523330   \n",
       "\n",
       "     col_14    col_15    col_16    col_17    col_18    col_19  \n",
       "0  0.532421  0.411096  0.347343  0.899833  0.021823  0.663790  \n",
       "1  0.608527  0.349506  0.114096  0.151247  0.225317  0.250967  \n",
       "2  0.849975  0.669022  0.462296  0.411766  0.650973  0.545432  \n",
       "3  0.879582  0.870578  0.238796  0.451239  0.984990  0.772012  \n",
       "4  0.287138  0.792854  0.577593  0.634582  0.797914  0.395970  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-33ad1366-8efb-4991-a375-15414d5aab86\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_17</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.261706</td>\n",
       "      <td>0.246979</td>\n",
       "      <td>0.906255</td>\n",
       "      <td>0.249546</td>\n",
       "      <td>0.271950</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>0.449740</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>0.487571</td>\n",
       "      <td>0.033614</td>\n",
       "      <td>0.062653</td>\n",
       "      <td>0.906437</td>\n",
       "      <td>0.139245</td>\n",
       "      <td>0.532421</td>\n",
       "      <td>0.411096</td>\n",
       "      <td>0.347343</td>\n",
       "      <td>0.899833</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>0.663790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963394</td>\n",
       "      <td>0.560168</td>\n",
       "      <td>0.936822</td>\n",
       "      <td>0.052258</td>\n",
       "      <td>0.418793</td>\n",
       "      <td>0.260158</td>\n",
       "      <td>0.730821</td>\n",
       "      <td>0.981297</td>\n",
       "      <td>0.256530</td>\n",
       "      <td>0.654175</td>\n",
       "      <td>0.198098</td>\n",
       "      <td>0.565330</td>\n",
       "      <td>0.463932</td>\n",
       "      <td>0.972005</td>\n",
       "      <td>0.608527</td>\n",
       "      <td>0.349506</td>\n",
       "      <td>0.114096</td>\n",
       "      <td>0.151247</td>\n",
       "      <td>0.225317</td>\n",
       "      <td>0.250967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850616</td>\n",
       "      <td>0.561223</td>\n",
       "      <td>0.523391</td>\n",
       "      <td>0.114769</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>0.067668</td>\n",
       "      <td>0.707835</td>\n",
       "      <td>0.543538</td>\n",
       "      <td>0.081725</td>\n",
       "      <td>0.458301</td>\n",
       "      <td>0.484696</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.945698</td>\n",
       "      <td>0.849975</td>\n",
       "      <td>0.669022</td>\n",
       "      <td>0.462296</td>\n",
       "      <td>0.411766</td>\n",
       "      <td>0.650973</td>\n",
       "      <td>0.545432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062273</td>\n",
       "      <td>0.512503</td>\n",
       "      <td>0.806404</td>\n",
       "      <td>0.459240</td>\n",
       "      <td>0.051957</td>\n",
       "      <td>0.786278</td>\n",
       "      <td>0.201364</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.330215</td>\n",
       "      <td>0.756752</td>\n",
       "      <td>0.519386</td>\n",
       "      <td>0.204881</td>\n",
       "      <td>0.877830</td>\n",
       "      <td>0.879582</td>\n",
       "      <td>0.870578</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.451239</td>\n",
       "      <td>0.984990</td>\n",
       "      <td>0.772012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027167</td>\n",
       "      <td>0.065205</td>\n",
       "      <td>0.463931</td>\n",
       "      <td>0.909220</td>\n",
       "      <td>0.538702</td>\n",
       "      <td>0.497813</td>\n",
       "      <td>0.105474</td>\n",
       "      <td>0.656780</td>\n",
       "      <td>0.822103</td>\n",
       "      <td>0.380420</td>\n",
       "      <td>0.775612</td>\n",
       "      <td>0.964477</td>\n",
       "      <td>0.203766</td>\n",
       "      <td>0.523330</td>\n",
       "      <td>0.287138</td>\n",
       "      <td>0.792854</td>\n",
       "      <td>0.577593</td>\n",
       "      <td>0.634582</td>\n",
       "      <td>0.797914</td>\n",
       "      <td>0.395970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33ad1366-8efb-4991-a375-15414d5aab86')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-33ad1366-8efb-4991-a375-15414d5aab86 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-33ad1366-8efb-4991-a375-15414d5aab86');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"display(df_example\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"col_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44362193292878466,\n        \"min\": 0.027167421225559818,\n        \"max\": 0.9633944342135504,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9633944342135504,\n          0.027167421225559818,\n          0.8506160578411378\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22317336105036456,\n        \"min\": 0.06520459126049205,\n        \"max\": 0.5612227882825249,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5601681834618419,\n          0.06520459126049205,\n          0.5612227882825249\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21972921744365106,\n        \"min\": 0.46393137681233276,\n        \"max\": 0.9368224620330918,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9368224620330918,\n          0.46393137681233276,\n          0.5233909113743664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34586491107588346,\n        \"min\": 0.05225787928602377,\n        \"max\": 0.9092202058615602,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.05225787928602377,\n          0.9092202058615602,\n          0.11476887186921747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30201168609231704,\n        \"min\": 0.05195657755426841,\n        \"max\": 0.860139693349435,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4187933190741614,\n          0.5387017979527142,\n          0.860139693349435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22415714335961348,\n        \"min\": 0.26015779096205116,\n        \"max\": 0.7862781993840331,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.26015779096205116,\n          0.4978125080342902,\n          0.7228143032084837\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2779252741338682,\n        \"min\": 0.06766836190000158,\n        \"max\": 0.7308209649807298,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7308209649807298,\n          0.10547369995663058,\n          0.06766836190000158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2640723696535562,\n        \"min\": 0.2586208348880388,\n        \"max\": 0.9812970904972467,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9812970904972467,\n          0.656780104724294,\n          0.7078350972297687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3091659989579517,\n        \"min\": 0.06536615756438524,\n        \"max\": 0.8221031606002255,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2565300624442478,\n          0.8221031606002255,\n          0.5435382173426461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2109248163368586,\n        \"min\": 0.08172534574677826,\n        \"max\": 0.6541746014740745,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6541746014740745,\n          0.38042000750756233,\n          0.08172534574677826\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33048005815673254,\n        \"min\": 0.03361360018328263,\n        \"max\": 0.7756118509253275,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.19809763275974013,\n          0.7756118509253275,\n          0.45830064152865646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32016587820527515,\n        \"min\": 0.06265320345535452,\n        \"max\": 0.9644766539008116,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5653302545716099,\n          0.9644766539008116,\n          0.484696287130047\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31280871265102866,\n        \"min\": 0.16577454016327575,\n        \"max\": 0.906437453344411,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4639324866883362,\n          0.2037664591276891,\n          0.16577454016327575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3575210517969577,\n        \"min\": 0.13924537111759516,\n        \"max\": 0.9720053296315371,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9720053296315371,\n          0.5233296311947413,\n          0.9456981470002823\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24403163929844923,\n        \"min\": 0.28713795808457554,\n        \"max\": 0.8795818549515292,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6085272726964666,\n          0.28713795808457554,\n          0.8499753714806619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23014647304128683,\n        \"min\": 0.3495063720868188,\n        \"max\": 0.8705784250460069,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3495063720868188,\n          0.7928544190338394,\n          0.6690223373291083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18194344337576385,\n        \"min\": 0.11409578488793337,\n        \"max\": 0.5775933658811575,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.11409578488793337,\n          0.5775933658811575,\n          0.4622955610006072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_17\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27807243770036866,\n        \"min\": 0.15124682873493456,\n        \"max\": 0.8998333456872725,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.15124682873493456,\n          0.6345824175503038,\n          0.4117655415845085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40134491982896103,\n        \"min\": 0.0218233967754895,\n        \"max\": 0.9849896561408751,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2253169299512351,\n          0.7979141596158941,\n          0.6509734671509542\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_19\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2076271177449366,\n        \"min\": 0.250966661340298,\n        \"max\": 0.7720124763099904,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.250966661340298,\n          0.3959704726624549,\n          0.5454318694069055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Display with increased limits (all columns, more rows):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "       col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0   0.261706  0.246979  0.906255  0.249546  0.271950  0.759398  0.449740   \n",
       "1   0.963394  0.560168  0.936822  0.052258  0.418793  0.260158  0.730821   \n",
       "2   0.850616  0.561223  0.523391  0.114769  0.860140  0.722814  0.067668   \n",
       "3   0.062273  0.512503  0.806404  0.459240  0.051957  0.786278  0.201364   \n",
       "4   0.027167  0.065205  0.463931  0.909220  0.538702  0.497813  0.105474   \n",
       "5   0.915090  0.533029  0.157955  0.695899  0.793261  0.316762  0.857179   \n",
       "6   0.803604  0.505207  0.967127  0.417761  0.984110  0.667920  0.634671   \n",
       "7   0.819064  0.540794  0.710243  0.314350  0.471168  0.821637  0.459265   \n",
       "8   0.651148  0.620929  0.352375  0.841448  0.471287  0.979105  0.634142   \n",
       "9   0.305311  0.212644  0.033189  0.303946  0.653163  0.938305  0.871204   \n",
       "10  0.976800  0.110721  0.422548  0.042025  0.739904  0.918077  0.280037   \n",
       "11  0.703686  0.540698  0.096534  0.241894  0.012404  0.468768  0.301265   \n",
       "12  0.794578  0.034670  0.582807  0.995438  0.855696  0.521446  0.063641   \n",
       "13  0.773880  0.601923  0.892523  0.443380  0.607090  0.631308  0.591697   \n",
       "14  0.254392  0.361853  0.472493  0.045649  0.140024  0.276814  0.971533   \n",
       "15  0.802586  0.572049  0.512668  0.293489  0.931754  0.397015  0.087093   \n",
       "16  0.907611  0.714033  0.607905  0.309373  0.823790  0.955061  0.821198   \n",
       "17  0.751178  0.071008  0.080180  0.354771  0.941726  0.668573  0.678670   \n",
       "18  0.011707  0.422034  0.295041  0.486000  0.577200  0.043739  0.123003   \n",
       "19  0.822422  0.857562  0.916635  0.430985  0.318867  0.582199  0.371172   \n",
       "20  0.340604  0.071712  0.409629  0.311217  0.677121  0.605779  0.364594   \n",
       "21  0.160025  0.023352  0.756214  0.458523  0.289245  0.900083  0.116139   \n",
       "22  0.553711  0.541705  0.761902  0.833650  0.440441  0.302333  0.259335   \n",
       "23  0.993848  0.880315  0.623406  0.569377  0.620660  0.201312  0.395138   \n",
       "24  0.275768  0.877091  0.944042  0.148796  0.462676  0.980987  0.483407   \n",
       "25  0.827519  0.764528  0.573529  0.956047  0.200475  0.109264  0.853962   \n",
       "26  0.692532  0.134435  0.299396  0.358716  0.804437  0.278760  0.210705   \n",
       "27  0.658541  0.766116  0.845921  0.613604  0.088605  0.487628  0.077649   \n",
       "28  0.794516  0.707086  0.050226  0.072902  0.402873  0.295290  0.232384   \n",
       "29  0.122921  0.888659  0.503084  0.449350  0.585865  0.624784  0.071776   \n",
       "30  0.629558  0.054332  0.748645  0.317587  0.000135  0.511129  0.046852   \n",
       "31  0.788932  0.891872  0.433817  0.909943  0.377318  0.964078  0.089290   \n",
       "32  0.298052  0.105365  0.781824  0.644149  0.048186  0.360050  0.956800   \n",
       "33  0.472282  0.880157  0.215741  0.677813  0.607752  0.295301  0.136601   \n",
       "34  0.267593  0.835480  0.014693  0.379094  0.337346  0.019328  0.124368   \n",
       "35  0.521296  0.976014  0.125550  0.016948  0.770158  0.807156  0.120207   \n",
       "36  0.898561  0.783198  0.780376  0.457996  0.398005  0.302916  0.065695   \n",
       "37  0.365681  0.225381  0.195833  0.140803  0.622414  0.781322  0.578298   \n",
       "38  0.147303  0.007842  0.630922  0.447673  0.134275  0.957934  0.529660   \n",
       "39  0.049979  0.843650  0.981193  0.793143  0.853785  0.241977  0.960627   \n",
       "40  0.792595  0.907899  0.943702  0.960136  0.521460  0.977308  0.757310   \n",
       "41  0.926194  0.228677  0.634364  0.222076  0.321670  0.848042  0.728861   \n",
       "42  0.392458  0.754265  0.918426  0.950929  0.577123  0.357121  0.787549   \n",
       "43  0.866770  0.282479  0.950459  0.581622  0.436614  0.580089  0.516698   \n",
       "44  0.331565  0.855030  0.207076  0.071158  0.069008  0.940785  0.506920   \n",
       "45  0.127867  0.765547  0.000012  0.416566  0.522510  0.054634  0.973078   \n",
       "46  0.325295  0.712621  0.816779  0.181614  0.370941  0.901940  0.806694   \n",
       "47  0.265326  0.601554  0.296560  0.714424  0.759005  0.102516  0.513854   \n",
       "48  0.195241  0.345342  0.335610  0.978525  0.856537  0.701170  0.727057   \n",
       "49  0.437661  0.234973  0.704871  0.817128  0.546430  0.967035  0.051669   \n",
       "\n",
       "       col_7     col_8     col_9    col_10    col_11    col_12    col_13  \\\n",
       "0   0.776711  0.065366  0.487571  0.033614  0.062653  0.906437  0.139245   \n",
       "1   0.981297  0.256530  0.654175  0.198098  0.565330  0.463932  0.972005   \n",
       "2   0.707835  0.543538  0.081725  0.458301  0.484696  0.165775  0.945698   \n",
       "3   0.258621  0.164706  0.330215  0.756752  0.519386  0.204881  0.877830   \n",
       "4   0.656780  0.822103  0.380420  0.775612  0.964477  0.203766  0.523330   \n",
       "5   0.906143  0.276904  0.983521  0.140712  0.202016  0.184225  0.893990   \n",
       "6   0.165955  0.881928  0.427490  0.162233  0.012608  0.559756  0.527400   \n",
       "7   0.357798  0.494212  0.828249  0.335208  0.173762  0.712014  0.825978   \n",
       "8   0.126265  0.676178  0.325104  0.686327  0.069641  0.174881  0.855737   \n",
       "9   0.766065  0.788447  0.664985  0.260287  0.907195  0.670732  0.560441   \n",
       "10  0.858342  0.292218  0.910770  0.753962  0.804907  0.018007  0.962810   \n",
       "11  0.598357  0.297238  0.299919  0.743193  0.048143  0.902895  0.852264   \n",
       "12  0.831374  0.598979  0.114933  0.093857  0.909627  0.669200  0.829287   \n",
       "13  0.702634  0.237433  0.512364  0.104225  0.384511  0.487667  0.652224   \n",
       "14  0.331347  0.482041  0.196098  0.610780  0.280683  0.206993  0.516573   \n",
       "15  0.617067  0.113838  0.345223  0.507412  0.874223  0.493547  0.702259   \n",
       "16  0.001565  0.636401  0.051135  0.257607  0.059525  0.603795  0.686590   \n",
       "17  0.361920  0.593661  0.010131  0.636096  0.913287  0.612573  0.873699   \n",
       "18  0.558642  0.343167  0.729173  0.652292  0.845604  0.692493  0.429931   \n",
       "19  0.601074  0.705586  0.688405  0.374553  0.166860  0.430529  0.142594   \n",
       "20  0.217893  0.988036  0.454002  0.688274  0.140553  0.485590  0.027537   \n",
       "21  0.955919  0.313967  0.888404  0.602943  0.826707  0.984013  0.288405   \n",
       "22  0.194624  0.057648  0.342448  0.270248  0.966417  0.557709  0.347277   \n",
       "23  0.039460  0.475546  0.543025  0.227750  0.964029  0.909455  0.722143   \n",
       "24  0.863548  0.588732  0.375330  0.285784  0.203223  0.761798  0.386541   \n",
       "25  0.439150  0.846969  0.893090  0.062458  0.883465  0.448319  0.510432   \n",
       "26  0.957448  0.008863  0.997821  0.676821  0.828469  0.294619  0.014315   \n",
       "27  0.407543  0.407106  0.066010  0.348821  0.110998  0.808235  0.947688   \n",
       "28  0.281004  0.803483  0.929228  0.405103  0.906111  0.321496  0.476437   \n",
       "29  0.682617  0.241932  0.713953  0.822535  0.803959  0.552501  0.520170   \n",
       "30  0.276170  0.706976  0.062690  0.839338  0.003820  0.246824  0.740904   \n",
       "31  0.687019  0.493814  0.387649  0.632712  0.703857  0.004363  0.166953   \n",
       "32  0.500401  0.432729  0.457700  0.208883  0.368707  0.369813  0.052355   \n",
       "33  0.651640  0.738597  0.315627  0.644833  0.395131  0.713207  0.199215   \n",
       "34  0.413643  0.492865  0.404290  0.530938  0.595132  0.009924  0.464095   \n",
       "35  0.265583  0.017552  0.293309  0.773142  0.517961  0.348096  0.371739   \n",
       "36  0.228235  0.246604  0.484077  0.747444  0.473810  0.057844  0.957790   \n",
       "37  0.146963  0.811124  0.635955  0.388166  0.674130  0.259905  0.345192   \n",
       "38  0.241893  0.500604  0.679620  0.076239  0.274704  0.806965  0.459665   \n",
       "39  0.196926  0.951430  0.994819  0.711723  0.981144  0.569540  0.259542   \n",
       "40  0.161671  0.476900  0.718331  0.247340  0.640615  0.666600  0.162700   \n",
       "41  0.095399  0.428702  0.029170  0.480890  0.662434  0.118503  0.288885   \n",
       "42  0.251001  0.564074  0.358578  0.656631  0.240399  0.191593  0.918239   \n",
       "43  0.758776  0.282496  0.353050  0.894094  0.946457  0.892558  0.419448   \n",
       "44  0.409412  0.810879  0.835826  0.332191  0.693618  0.771123  0.654651   \n",
       "45  0.226125  0.304199  0.303943  0.230417  0.001474  0.729345  0.966845   \n",
       "46  0.984858  0.754248  0.393195  0.590638  0.661014  0.078456  0.544497   \n",
       "47  0.508891  0.369281  0.932925  0.827506  0.697209  0.714327  0.461716   \n",
       "48  0.562073  0.947091  0.496259  0.380518  0.163035  0.786206  0.734444   \n",
       "49  0.504796  0.718454  0.862640  0.179256  0.800003  0.552707  0.396554   \n",
       "\n",
       "      col_14    col_15    col_16    col_17    col_18    col_19  \n",
       "0   0.532421  0.411096  0.347343  0.899833  0.021823  0.663790  \n",
       "1   0.608527  0.349506  0.114096  0.151247  0.225317  0.250967  \n",
       "2   0.849975  0.669022  0.462296  0.411766  0.650973  0.545432  \n",
       "3   0.879582  0.870578  0.238796  0.451239  0.984990  0.772012  \n",
       "4   0.287138  0.792854  0.577593  0.634582  0.797914  0.395970  \n",
       "5   0.654293  0.152104  0.440323  0.615298  0.083464  0.882416  \n",
       "6   0.719354  0.890258  0.079407  0.731496  0.187412  0.858177  \n",
       "7   0.100637  0.239874  0.141972  0.347941  0.450351  0.748826  \n",
       "8   0.227180  0.837041  0.279276  0.642882  0.694151  0.512655  \n",
       "9   0.110989  0.447056  0.460358  0.864564  0.546648  0.380401  \n",
       "10  0.726671  0.304751  0.829395  0.281521  0.872754  0.112580  \n",
       "11  0.667805  0.593222  0.892302  0.185330  0.078969  0.239510  \n",
       "12  0.878979  0.571772  0.517446  0.430427  0.316947  0.434596  \n",
       "13  0.950531  0.600651  0.743594  0.506266  0.634104  0.070932  \n",
       "14  0.005506  0.007664  0.219069  0.036721  0.108026  0.338861  \n",
       "15  0.992817  0.131489  0.274732  0.394576  0.421828  0.411021  \n",
       "16  0.114488  0.383839  0.456237  0.369053  0.121025  0.418948  \n",
       "17  0.723973  0.120558  0.902453  0.066444  0.533967  0.142137  \n",
       "18  0.672967  0.275381  0.306313  0.788985  0.446420  0.798380  \n",
       "19  0.890097  0.345877  0.154460  0.025448  0.645822  0.636902  \n",
       "20  0.505455  0.964017  0.384207  0.038996  0.030956  0.387987  \n",
       "21  0.961135  0.389482  0.385512  0.340387  0.541408  0.154145  \n",
       "22  0.580468  0.139197  0.444044  0.626234  0.488898  0.401779  \n",
       "23  0.533387  0.869969  0.130652  0.790510  0.124821  0.794211  \n",
       "24  0.511275  0.492325  0.577279  0.865577  0.980739  0.407584  \n",
       "25  0.626593  0.926383  0.019116  0.476843  0.687722  0.722707  \n",
       "26  0.737870  0.834145  0.740476  0.142850  0.753428  0.768923  \n",
       "27  0.072316  0.955115  0.522577  0.299566  0.076862  0.500624  \n",
       "28  0.226029  0.640476  0.978981  0.603493  0.357814  0.647817  \n",
       "29  0.142876  0.775346  0.271409  0.496695  0.284274  0.133828  \n",
       "30  0.316270  0.101892  0.360234  0.270393  0.842712  0.313348  \n",
       "31  0.713046  0.666385  0.966048  0.761038  0.950773  0.702541  \n",
       "32  0.767568  0.416504  0.822180  0.850348  0.211994  0.657353  \n",
       "33  0.890215  0.287410  0.367786  0.058092  0.111512  0.515862  \n",
       "34  0.963499  0.519032  0.677542  0.311864  0.773991  0.772921  \n",
       "35  0.001354  0.299801  0.646459  0.974194  0.847061  0.023595  \n",
       "36  0.942724  0.785190  0.991328  0.544482  0.962768  0.075605  \n",
       "37  0.917486  0.290505  0.469988  0.890141  0.707721  0.062203  \n",
       "38  0.546577  0.432816  0.043900  0.165750  0.445542  0.209185  \n",
       "39  0.436996  0.593561  0.073082  0.622343  0.981178  0.190108  \n",
       "40  0.565085  0.771627  0.498896  0.012103  0.009038  0.357029  \n",
       "41  0.397837  0.919531  0.993255  0.044911  0.761008  0.371724  \n",
       "42  0.101804  0.505958  0.220853  0.038930  0.036019  0.175222  \n",
       "43  0.780366  0.476336  0.497540  0.204680  0.591130  0.186136  \n",
       "44  0.151595  0.875883  0.539095  0.282472  0.425228  0.037571  \n",
       "45  0.224293  0.663047  0.741896  0.848425  0.422629  0.302931  \n",
       "46  0.709321  0.167321  0.780632  0.583773  0.952222  0.042422  \n",
       "47  0.920995  0.694595  0.728981  0.861691  0.274072  0.807071  \n",
       "48  0.384355  0.025193  0.838997  0.011418  0.703700  0.970257  \n",
       "49  0.131715  0.865296  0.157273  0.309788  0.290046  0.871414  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-92f04e2d-9b80-4fcc-86f0-432b40b67ab8\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_17</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.261706</td>\n",
       "      <td>0.246979</td>\n",
       "      <td>0.906255</td>\n",
       "      <td>0.249546</td>\n",
       "      <td>0.271950</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>0.449740</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>0.487571</td>\n",
       "      <td>0.033614</td>\n",
       "      <td>0.062653</td>\n",
       "      <td>0.906437</td>\n",
       "      <td>0.139245</td>\n",
       "      <td>0.532421</td>\n",
       "      <td>0.411096</td>\n",
       "      <td>0.347343</td>\n",
       "      <td>0.899833</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>0.663790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963394</td>\n",
       "      <td>0.560168</td>\n",
       "      <td>0.936822</td>\n",
       "      <td>0.052258</td>\n",
       "      <td>0.418793</td>\n",
       "      <td>0.260158</td>\n",
       "      <td>0.730821</td>\n",
       "      <td>0.981297</td>\n",
       "      <td>0.256530</td>\n",
       "      <td>0.654175</td>\n",
       "      <td>0.198098</td>\n",
       "      <td>0.565330</td>\n",
       "      <td>0.463932</td>\n",
       "      <td>0.972005</td>\n",
       "      <td>0.608527</td>\n",
       "      <td>0.349506</td>\n",
       "      <td>0.114096</td>\n",
       "      <td>0.151247</td>\n",
       "      <td>0.225317</td>\n",
       "      <td>0.250967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850616</td>\n",
       "      <td>0.561223</td>\n",
       "      <td>0.523391</td>\n",
       "      <td>0.114769</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>0.067668</td>\n",
       "      <td>0.707835</td>\n",
       "      <td>0.543538</td>\n",
       "      <td>0.081725</td>\n",
       "      <td>0.458301</td>\n",
       "      <td>0.484696</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.945698</td>\n",
       "      <td>0.849975</td>\n",
       "      <td>0.669022</td>\n",
       "      <td>0.462296</td>\n",
       "      <td>0.411766</td>\n",
       "      <td>0.650973</td>\n",
       "      <td>0.545432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062273</td>\n",
       "      <td>0.512503</td>\n",
       "      <td>0.806404</td>\n",
       "      <td>0.459240</td>\n",
       "      <td>0.051957</td>\n",
       "      <td>0.786278</td>\n",
       "      <td>0.201364</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.330215</td>\n",
       "      <td>0.756752</td>\n",
       "      <td>0.519386</td>\n",
       "      <td>0.204881</td>\n",
       "      <td>0.877830</td>\n",
       "      <td>0.879582</td>\n",
       "      <td>0.870578</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.451239</td>\n",
       "      <td>0.984990</td>\n",
       "      <td>0.772012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027167</td>\n",
       "      <td>0.065205</td>\n",
       "      <td>0.463931</td>\n",
       "      <td>0.909220</td>\n",
       "      <td>0.538702</td>\n",
       "      <td>0.497813</td>\n",
       "      <td>0.105474</td>\n",
       "      <td>0.656780</td>\n",
       "      <td>0.822103</td>\n",
       "      <td>0.380420</td>\n",
       "      <td>0.775612</td>\n",
       "      <td>0.964477</td>\n",
       "      <td>0.203766</td>\n",
       "      <td>0.523330</td>\n",
       "      <td>0.287138</td>\n",
       "      <td>0.792854</td>\n",
       "      <td>0.577593</td>\n",
       "      <td>0.634582</td>\n",
       "      <td>0.797914</td>\n",
       "      <td>0.395970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.533029</td>\n",
       "      <td>0.157955</td>\n",
       "      <td>0.695899</td>\n",
       "      <td>0.793261</td>\n",
       "      <td>0.316762</td>\n",
       "      <td>0.857179</td>\n",
       "      <td>0.906143</td>\n",
       "      <td>0.276904</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>0.140712</td>\n",
       "      <td>0.202016</td>\n",
       "      <td>0.184225</td>\n",
       "      <td>0.893990</td>\n",
       "      <td>0.654293</td>\n",
       "      <td>0.152104</td>\n",
       "      <td>0.440323</td>\n",
       "      <td>0.615298</td>\n",
       "      <td>0.083464</td>\n",
       "      <td>0.882416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.803604</td>\n",
       "      <td>0.505207</td>\n",
       "      <td>0.967127</td>\n",
       "      <td>0.417761</td>\n",
       "      <td>0.984110</td>\n",
       "      <td>0.667920</td>\n",
       "      <td>0.634671</td>\n",
       "      <td>0.165955</td>\n",
       "      <td>0.881928</td>\n",
       "      <td>0.427490</td>\n",
       "      <td>0.162233</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>0.559756</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.719354</td>\n",
       "      <td>0.890258</td>\n",
       "      <td>0.079407</td>\n",
       "      <td>0.731496</td>\n",
       "      <td>0.187412</td>\n",
       "      <td>0.858177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.819064</td>\n",
       "      <td>0.540794</td>\n",
       "      <td>0.710243</td>\n",
       "      <td>0.314350</td>\n",
       "      <td>0.471168</td>\n",
       "      <td>0.821637</td>\n",
       "      <td>0.459265</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>0.828249</td>\n",
       "      <td>0.335208</td>\n",
       "      <td>0.173762</td>\n",
       "      <td>0.712014</td>\n",
       "      <td>0.825978</td>\n",
       "      <td>0.100637</td>\n",
       "      <td>0.239874</td>\n",
       "      <td>0.141972</td>\n",
       "      <td>0.347941</td>\n",
       "      <td>0.450351</td>\n",
       "      <td>0.748826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.651148</td>\n",
       "      <td>0.620929</td>\n",
       "      <td>0.352375</td>\n",
       "      <td>0.841448</td>\n",
       "      <td>0.471287</td>\n",
       "      <td>0.979105</td>\n",
       "      <td>0.634142</td>\n",
       "      <td>0.126265</td>\n",
       "      <td>0.676178</td>\n",
       "      <td>0.325104</td>\n",
       "      <td>0.686327</td>\n",
       "      <td>0.069641</td>\n",
       "      <td>0.174881</td>\n",
       "      <td>0.855737</td>\n",
       "      <td>0.227180</td>\n",
       "      <td>0.837041</td>\n",
       "      <td>0.279276</td>\n",
       "      <td>0.642882</td>\n",
       "      <td>0.694151</td>\n",
       "      <td>0.512655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.212644</td>\n",
       "      <td>0.033189</td>\n",
       "      <td>0.303946</td>\n",
       "      <td>0.653163</td>\n",
       "      <td>0.938305</td>\n",
       "      <td>0.871204</td>\n",
       "      <td>0.766065</td>\n",
       "      <td>0.788447</td>\n",
       "      <td>0.664985</td>\n",
       "      <td>0.260287</td>\n",
       "      <td>0.907195</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>0.560441</td>\n",
       "      <td>0.110989</td>\n",
       "      <td>0.447056</td>\n",
       "      <td>0.460358</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>0.546648</td>\n",
       "      <td>0.380401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.976800</td>\n",
       "      <td>0.110721</td>\n",
       "      <td>0.422548</td>\n",
       "      <td>0.042025</td>\n",
       "      <td>0.739904</td>\n",
       "      <td>0.918077</td>\n",
       "      <td>0.280037</td>\n",
       "      <td>0.858342</td>\n",
       "      <td>0.292218</td>\n",
       "      <td>0.910770</td>\n",
       "      <td>0.753962</td>\n",
       "      <td>0.804907</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.962810</td>\n",
       "      <td>0.726671</td>\n",
       "      <td>0.304751</td>\n",
       "      <td>0.829395</td>\n",
       "      <td>0.281521</td>\n",
       "      <td>0.872754</td>\n",
       "      <td>0.112580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.703686</td>\n",
       "      <td>0.540698</td>\n",
       "      <td>0.096534</td>\n",
       "      <td>0.241894</td>\n",
       "      <td>0.012404</td>\n",
       "      <td>0.468768</td>\n",
       "      <td>0.301265</td>\n",
       "      <td>0.598357</td>\n",
       "      <td>0.297238</td>\n",
       "      <td>0.299919</td>\n",
       "      <td>0.743193</td>\n",
       "      <td>0.048143</td>\n",
       "      <td>0.902895</td>\n",
       "      <td>0.852264</td>\n",
       "      <td>0.667805</td>\n",
       "      <td>0.593222</td>\n",
       "      <td>0.892302</td>\n",
       "      <td>0.185330</td>\n",
       "      <td>0.078969</td>\n",
       "      <td>0.239510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.794578</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>0.582807</td>\n",
       "      <td>0.995438</td>\n",
       "      <td>0.855696</td>\n",
       "      <td>0.521446</td>\n",
       "      <td>0.063641</td>\n",
       "      <td>0.831374</td>\n",
       "      <td>0.598979</td>\n",
       "      <td>0.114933</td>\n",
       "      <td>0.093857</td>\n",
       "      <td>0.909627</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.829287</td>\n",
       "      <td>0.878979</td>\n",
       "      <td>0.571772</td>\n",
       "      <td>0.517446</td>\n",
       "      <td>0.430427</td>\n",
       "      <td>0.316947</td>\n",
       "      <td>0.434596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.773880</td>\n",
       "      <td>0.601923</td>\n",
       "      <td>0.892523</td>\n",
       "      <td>0.443380</td>\n",
       "      <td>0.607090</td>\n",
       "      <td>0.631308</td>\n",
       "      <td>0.591697</td>\n",
       "      <td>0.702634</td>\n",
       "      <td>0.237433</td>\n",
       "      <td>0.512364</td>\n",
       "      <td>0.104225</td>\n",
       "      <td>0.384511</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>0.652224</td>\n",
       "      <td>0.950531</td>\n",
       "      <td>0.600651</td>\n",
       "      <td>0.743594</td>\n",
       "      <td>0.506266</td>\n",
       "      <td>0.634104</td>\n",
       "      <td>0.070932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.254392</td>\n",
       "      <td>0.361853</td>\n",
       "      <td>0.472493</td>\n",
       "      <td>0.045649</td>\n",
       "      <td>0.140024</td>\n",
       "      <td>0.276814</td>\n",
       "      <td>0.971533</td>\n",
       "      <td>0.331347</td>\n",
       "      <td>0.482041</td>\n",
       "      <td>0.196098</td>\n",
       "      <td>0.610780</td>\n",
       "      <td>0.280683</td>\n",
       "      <td>0.206993</td>\n",
       "      <td>0.516573</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.219069</td>\n",
       "      <td>0.036721</td>\n",
       "      <td>0.108026</td>\n",
       "      <td>0.338861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.802586</td>\n",
       "      <td>0.572049</td>\n",
       "      <td>0.512668</td>\n",
       "      <td>0.293489</td>\n",
       "      <td>0.931754</td>\n",
       "      <td>0.397015</td>\n",
       "      <td>0.087093</td>\n",
       "      <td>0.617067</td>\n",
       "      <td>0.113838</td>\n",
       "      <td>0.345223</td>\n",
       "      <td>0.507412</td>\n",
       "      <td>0.874223</td>\n",
       "      <td>0.493547</td>\n",
       "      <td>0.702259</td>\n",
       "      <td>0.992817</td>\n",
       "      <td>0.131489</td>\n",
       "      <td>0.274732</td>\n",
       "      <td>0.394576</td>\n",
       "      <td>0.421828</td>\n",
       "      <td>0.411021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.907611</td>\n",
       "      <td>0.714033</td>\n",
       "      <td>0.607905</td>\n",
       "      <td>0.309373</td>\n",
       "      <td>0.823790</td>\n",
       "      <td>0.955061</td>\n",
       "      <td>0.821198</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.636401</td>\n",
       "      <td>0.051135</td>\n",
       "      <td>0.257607</td>\n",
       "      <td>0.059525</td>\n",
       "      <td>0.603795</td>\n",
       "      <td>0.686590</td>\n",
       "      <td>0.114488</td>\n",
       "      <td>0.383839</td>\n",
       "      <td>0.456237</td>\n",
       "      <td>0.369053</td>\n",
       "      <td>0.121025</td>\n",
       "      <td>0.418948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.751178</td>\n",
       "      <td>0.071008</td>\n",
       "      <td>0.080180</td>\n",
       "      <td>0.354771</td>\n",
       "      <td>0.941726</td>\n",
       "      <td>0.668573</td>\n",
       "      <td>0.678670</td>\n",
       "      <td>0.361920</td>\n",
       "      <td>0.593661</td>\n",
       "      <td>0.010131</td>\n",
       "      <td>0.636096</td>\n",
       "      <td>0.913287</td>\n",
       "      <td>0.612573</td>\n",
       "      <td>0.873699</td>\n",
       "      <td>0.723973</td>\n",
       "      <td>0.120558</td>\n",
       "      <td>0.902453</td>\n",
       "      <td>0.066444</td>\n",
       "      <td>0.533967</td>\n",
       "      <td>0.142137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.011707</td>\n",
       "      <td>0.422034</td>\n",
       "      <td>0.295041</td>\n",
       "      <td>0.486000</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>0.043739</td>\n",
       "      <td>0.123003</td>\n",
       "      <td>0.558642</td>\n",
       "      <td>0.343167</td>\n",
       "      <td>0.729173</td>\n",
       "      <td>0.652292</td>\n",
       "      <td>0.845604</td>\n",
       "      <td>0.692493</td>\n",
       "      <td>0.429931</td>\n",
       "      <td>0.672967</td>\n",
       "      <td>0.275381</td>\n",
       "      <td>0.306313</td>\n",
       "      <td>0.788985</td>\n",
       "      <td>0.446420</td>\n",
       "      <td>0.798380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.822422</td>\n",
       "      <td>0.857562</td>\n",
       "      <td>0.916635</td>\n",
       "      <td>0.430985</td>\n",
       "      <td>0.318867</td>\n",
       "      <td>0.582199</td>\n",
       "      <td>0.371172</td>\n",
       "      <td>0.601074</td>\n",
       "      <td>0.705586</td>\n",
       "      <td>0.688405</td>\n",
       "      <td>0.374553</td>\n",
       "      <td>0.166860</td>\n",
       "      <td>0.430529</td>\n",
       "      <td>0.142594</td>\n",
       "      <td>0.890097</td>\n",
       "      <td>0.345877</td>\n",
       "      <td>0.154460</td>\n",
       "      <td>0.025448</td>\n",
       "      <td>0.645822</td>\n",
       "      <td>0.636902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.340604</td>\n",
       "      <td>0.071712</td>\n",
       "      <td>0.409629</td>\n",
       "      <td>0.311217</td>\n",
       "      <td>0.677121</td>\n",
       "      <td>0.605779</td>\n",
       "      <td>0.364594</td>\n",
       "      <td>0.217893</td>\n",
       "      <td>0.988036</td>\n",
       "      <td>0.454002</td>\n",
       "      <td>0.688274</td>\n",
       "      <td>0.140553</td>\n",
       "      <td>0.485590</td>\n",
       "      <td>0.027537</td>\n",
       "      <td>0.505455</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>0.384207</td>\n",
       "      <td>0.038996</td>\n",
       "      <td>0.030956</td>\n",
       "      <td>0.387987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.160025</td>\n",
       "      <td>0.023352</td>\n",
       "      <td>0.756214</td>\n",
       "      <td>0.458523</td>\n",
       "      <td>0.289245</td>\n",
       "      <td>0.900083</td>\n",
       "      <td>0.116139</td>\n",
       "      <td>0.955919</td>\n",
       "      <td>0.313967</td>\n",
       "      <td>0.888404</td>\n",
       "      <td>0.602943</td>\n",
       "      <td>0.826707</td>\n",
       "      <td>0.984013</td>\n",
       "      <td>0.288405</td>\n",
       "      <td>0.961135</td>\n",
       "      <td>0.389482</td>\n",
       "      <td>0.385512</td>\n",
       "      <td>0.340387</td>\n",
       "      <td>0.541408</td>\n",
       "      <td>0.154145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.553711</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>0.761902</td>\n",
       "      <td>0.833650</td>\n",
       "      <td>0.440441</td>\n",
       "      <td>0.302333</td>\n",
       "      <td>0.259335</td>\n",
       "      <td>0.194624</td>\n",
       "      <td>0.057648</td>\n",
       "      <td>0.342448</td>\n",
       "      <td>0.270248</td>\n",
       "      <td>0.966417</td>\n",
       "      <td>0.557709</td>\n",
       "      <td>0.347277</td>\n",
       "      <td>0.580468</td>\n",
       "      <td>0.139197</td>\n",
       "      <td>0.444044</td>\n",
       "      <td>0.626234</td>\n",
       "      <td>0.488898</td>\n",
       "      <td>0.401779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.993848</td>\n",
       "      <td>0.880315</td>\n",
       "      <td>0.623406</td>\n",
       "      <td>0.569377</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.201312</td>\n",
       "      <td>0.395138</td>\n",
       "      <td>0.039460</td>\n",
       "      <td>0.475546</td>\n",
       "      <td>0.543025</td>\n",
       "      <td>0.227750</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.909455</td>\n",
       "      <td>0.722143</td>\n",
       "      <td>0.533387</td>\n",
       "      <td>0.869969</td>\n",
       "      <td>0.130652</td>\n",
       "      <td>0.790510</td>\n",
       "      <td>0.124821</td>\n",
       "      <td>0.794211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.275768</td>\n",
       "      <td>0.877091</td>\n",
       "      <td>0.944042</td>\n",
       "      <td>0.148796</td>\n",
       "      <td>0.462676</td>\n",
       "      <td>0.980987</td>\n",
       "      <td>0.483407</td>\n",
       "      <td>0.863548</td>\n",
       "      <td>0.588732</td>\n",
       "      <td>0.375330</td>\n",
       "      <td>0.285784</td>\n",
       "      <td>0.203223</td>\n",
       "      <td>0.761798</td>\n",
       "      <td>0.386541</td>\n",
       "      <td>0.511275</td>\n",
       "      <td>0.492325</td>\n",
       "      <td>0.577279</td>\n",
       "      <td>0.865577</td>\n",
       "      <td>0.980739</td>\n",
       "      <td>0.407584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.827519</td>\n",
       "      <td>0.764528</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.956047</td>\n",
       "      <td>0.200475</td>\n",
       "      <td>0.109264</td>\n",
       "      <td>0.853962</td>\n",
       "      <td>0.439150</td>\n",
       "      <td>0.846969</td>\n",
       "      <td>0.893090</td>\n",
       "      <td>0.062458</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.448319</td>\n",
       "      <td>0.510432</td>\n",
       "      <td>0.626593</td>\n",
       "      <td>0.926383</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>0.476843</td>\n",
       "      <td>0.687722</td>\n",
       "      <td>0.722707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.692532</td>\n",
       "      <td>0.134435</td>\n",
       "      <td>0.299396</td>\n",
       "      <td>0.358716</td>\n",
       "      <td>0.804437</td>\n",
       "      <td>0.278760</td>\n",
       "      <td>0.210705</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>0.997821</td>\n",
       "      <td>0.676821</td>\n",
       "      <td>0.828469</td>\n",
       "      <td>0.294619</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>0.737870</td>\n",
       "      <td>0.834145</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.142850</td>\n",
       "      <td>0.753428</td>\n",
       "      <td>0.768923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.658541</td>\n",
       "      <td>0.766116</td>\n",
       "      <td>0.845921</td>\n",
       "      <td>0.613604</td>\n",
       "      <td>0.088605</td>\n",
       "      <td>0.487628</td>\n",
       "      <td>0.077649</td>\n",
       "      <td>0.407543</td>\n",
       "      <td>0.407106</td>\n",
       "      <td>0.066010</td>\n",
       "      <td>0.348821</td>\n",
       "      <td>0.110998</td>\n",
       "      <td>0.808235</td>\n",
       "      <td>0.947688</td>\n",
       "      <td>0.072316</td>\n",
       "      <td>0.955115</td>\n",
       "      <td>0.522577</td>\n",
       "      <td>0.299566</td>\n",
       "      <td>0.076862</td>\n",
       "      <td>0.500624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.794516</td>\n",
       "      <td>0.707086</td>\n",
       "      <td>0.050226</td>\n",
       "      <td>0.072902</td>\n",
       "      <td>0.402873</td>\n",
       "      <td>0.295290</td>\n",
       "      <td>0.232384</td>\n",
       "      <td>0.281004</td>\n",
       "      <td>0.803483</td>\n",
       "      <td>0.929228</td>\n",
       "      <td>0.405103</td>\n",
       "      <td>0.906111</td>\n",
       "      <td>0.321496</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.226029</td>\n",
       "      <td>0.640476</td>\n",
       "      <td>0.978981</td>\n",
       "      <td>0.603493</td>\n",
       "      <td>0.357814</td>\n",
       "      <td>0.647817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.122921</td>\n",
       "      <td>0.888659</td>\n",
       "      <td>0.503084</td>\n",
       "      <td>0.449350</td>\n",
       "      <td>0.585865</td>\n",
       "      <td>0.624784</td>\n",
       "      <td>0.071776</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>0.241932</td>\n",
       "      <td>0.713953</td>\n",
       "      <td>0.822535</td>\n",
       "      <td>0.803959</td>\n",
       "      <td>0.552501</td>\n",
       "      <td>0.520170</td>\n",
       "      <td>0.142876</td>\n",
       "      <td>0.775346</td>\n",
       "      <td>0.271409</td>\n",
       "      <td>0.496695</td>\n",
       "      <td>0.284274</td>\n",
       "      <td>0.133828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.629558</td>\n",
       "      <td>0.054332</td>\n",
       "      <td>0.748645</td>\n",
       "      <td>0.317587</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.511129</td>\n",
       "      <td>0.046852</td>\n",
       "      <td>0.276170</td>\n",
       "      <td>0.706976</td>\n",
       "      <td>0.062690</td>\n",
       "      <td>0.839338</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.246824</td>\n",
       "      <td>0.740904</td>\n",
       "      <td>0.316270</td>\n",
       "      <td>0.101892</td>\n",
       "      <td>0.360234</td>\n",
       "      <td>0.270393</td>\n",
       "      <td>0.842712</td>\n",
       "      <td>0.313348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.788932</td>\n",
       "      <td>0.891872</td>\n",
       "      <td>0.433817</td>\n",
       "      <td>0.909943</td>\n",
       "      <td>0.377318</td>\n",
       "      <td>0.964078</td>\n",
       "      <td>0.089290</td>\n",
       "      <td>0.687019</td>\n",
       "      <td>0.493814</td>\n",
       "      <td>0.387649</td>\n",
       "      <td>0.632712</td>\n",
       "      <td>0.703857</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.166953</td>\n",
       "      <td>0.713046</td>\n",
       "      <td>0.666385</td>\n",
       "      <td>0.966048</td>\n",
       "      <td>0.761038</td>\n",
       "      <td>0.950773</td>\n",
       "      <td>0.702541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.298052</td>\n",
       "      <td>0.105365</td>\n",
       "      <td>0.781824</td>\n",
       "      <td>0.644149</td>\n",
       "      <td>0.048186</td>\n",
       "      <td>0.360050</td>\n",
       "      <td>0.956800</td>\n",
       "      <td>0.500401</td>\n",
       "      <td>0.432729</td>\n",
       "      <td>0.457700</td>\n",
       "      <td>0.208883</td>\n",
       "      <td>0.368707</td>\n",
       "      <td>0.369813</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>0.767568</td>\n",
       "      <td>0.416504</td>\n",
       "      <td>0.822180</td>\n",
       "      <td>0.850348</td>\n",
       "      <td>0.211994</td>\n",
       "      <td>0.657353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.472282</td>\n",
       "      <td>0.880157</td>\n",
       "      <td>0.215741</td>\n",
       "      <td>0.677813</td>\n",
       "      <td>0.607752</td>\n",
       "      <td>0.295301</td>\n",
       "      <td>0.136601</td>\n",
       "      <td>0.651640</td>\n",
       "      <td>0.738597</td>\n",
       "      <td>0.315627</td>\n",
       "      <td>0.644833</td>\n",
       "      <td>0.395131</td>\n",
       "      <td>0.713207</td>\n",
       "      <td>0.199215</td>\n",
       "      <td>0.890215</td>\n",
       "      <td>0.287410</td>\n",
       "      <td>0.367786</td>\n",
       "      <td>0.058092</td>\n",
       "      <td>0.111512</td>\n",
       "      <td>0.515862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.267593</td>\n",
       "      <td>0.835480</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.379094</td>\n",
       "      <td>0.337346</td>\n",
       "      <td>0.019328</td>\n",
       "      <td>0.124368</td>\n",
       "      <td>0.413643</td>\n",
       "      <td>0.492865</td>\n",
       "      <td>0.404290</td>\n",
       "      <td>0.530938</td>\n",
       "      <td>0.595132</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.464095</td>\n",
       "      <td>0.963499</td>\n",
       "      <td>0.519032</td>\n",
       "      <td>0.677542</td>\n",
       "      <td>0.311864</td>\n",
       "      <td>0.773991</td>\n",
       "      <td>0.772921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.521296</td>\n",
       "      <td>0.976014</td>\n",
       "      <td>0.125550</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.770158</td>\n",
       "      <td>0.807156</td>\n",
       "      <td>0.120207</td>\n",
       "      <td>0.265583</td>\n",
       "      <td>0.017552</td>\n",
       "      <td>0.293309</td>\n",
       "      <td>0.773142</td>\n",
       "      <td>0.517961</td>\n",
       "      <td>0.348096</td>\n",
       "      <td>0.371739</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.299801</td>\n",
       "      <td>0.646459</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.847061</td>\n",
       "      <td>0.023595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.898561</td>\n",
       "      <td>0.783198</td>\n",
       "      <td>0.780376</td>\n",
       "      <td>0.457996</td>\n",
       "      <td>0.398005</td>\n",
       "      <td>0.302916</td>\n",
       "      <td>0.065695</td>\n",
       "      <td>0.228235</td>\n",
       "      <td>0.246604</td>\n",
       "      <td>0.484077</td>\n",
       "      <td>0.747444</td>\n",
       "      <td>0.473810</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>0.957790</td>\n",
       "      <td>0.942724</td>\n",
       "      <td>0.785190</td>\n",
       "      <td>0.991328</td>\n",
       "      <td>0.544482</td>\n",
       "      <td>0.962768</td>\n",
       "      <td>0.075605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.365681</td>\n",
       "      <td>0.225381</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.140803</td>\n",
       "      <td>0.622414</td>\n",
       "      <td>0.781322</td>\n",
       "      <td>0.578298</td>\n",
       "      <td>0.146963</td>\n",
       "      <td>0.811124</td>\n",
       "      <td>0.635955</td>\n",
       "      <td>0.388166</td>\n",
       "      <td>0.674130</td>\n",
       "      <td>0.259905</td>\n",
       "      <td>0.345192</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.290505</td>\n",
       "      <td>0.469988</td>\n",
       "      <td>0.890141</td>\n",
       "      <td>0.707721</td>\n",
       "      <td>0.062203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.147303</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.630922</td>\n",
       "      <td>0.447673</td>\n",
       "      <td>0.134275</td>\n",
       "      <td>0.957934</td>\n",
       "      <td>0.529660</td>\n",
       "      <td>0.241893</td>\n",
       "      <td>0.500604</td>\n",
       "      <td>0.679620</td>\n",
       "      <td>0.076239</td>\n",
       "      <td>0.274704</td>\n",
       "      <td>0.806965</td>\n",
       "      <td>0.459665</td>\n",
       "      <td>0.546577</td>\n",
       "      <td>0.432816</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.165750</td>\n",
       "      <td>0.445542</td>\n",
       "      <td>0.209185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.049979</td>\n",
       "      <td>0.843650</td>\n",
       "      <td>0.981193</td>\n",
       "      <td>0.793143</td>\n",
       "      <td>0.853785</td>\n",
       "      <td>0.241977</td>\n",
       "      <td>0.960627</td>\n",
       "      <td>0.196926</td>\n",
       "      <td>0.951430</td>\n",
       "      <td>0.994819</td>\n",
       "      <td>0.711723</td>\n",
       "      <td>0.981144</td>\n",
       "      <td>0.569540</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.436996</td>\n",
       "      <td>0.593561</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.622343</td>\n",
       "      <td>0.981178</td>\n",
       "      <td>0.190108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.792595</td>\n",
       "      <td>0.907899</td>\n",
       "      <td>0.943702</td>\n",
       "      <td>0.960136</td>\n",
       "      <td>0.521460</td>\n",
       "      <td>0.977308</td>\n",
       "      <td>0.757310</td>\n",
       "      <td>0.161671</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.718331</td>\n",
       "      <td>0.247340</td>\n",
       "      <td>0.640615</td>\n",
       "      <td>0.666600</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.565085</td>\n",
       "      <td>0.771627</td>\n",
       "      <td>0.498896</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.357029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.926194</td>\n",
       "      <td>0.228677</td>\n",
       "      <td>0.634364</td>\n",
       "      <td>0.222076</td>\n",
       "      <td>0.321670</td>\n",
       "      <td>0.848042</td>\n",
       "      <td>0.728861</td>\n",
       "      <td>0.095399</td>\n",
       "      <td>0.428702</td>\n",
       "      <td>0.029170</td>\n",
       "      <td>0.480890</td>\n",
       "      <td>0.662434</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>0.288885</td>\n",
       "      <td>0.397837</td>\n",
       "      <td>0.919531</td>\n",
       "      <td>0.993255</td>\n",
       "      <td>0.044911</td>\n",
       "      <td>0.761008</td>\n",
       "      <td>0.371724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.392458</td>\n",
       "      <td>0.754265</td>\n",
       "      <td>0.918426</td>\n",
       "      <td>0.950929</td>\n",
       "      <td>0.577123</td>\n",
       "      <td>0.357121</td>\n",
       "      <td>0.787549</td>\n",
       "      <td>0.251001</td>\n",
       "      <td>0.564074</td>\n",
       "      <td>0.358578</td>\n",
       "      <td>0.656631</td>\n",
       "      <td>0.240399</td>\n",
       "      <td>0.191593</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.101804</td>\n",
       "      <td>0.505958</td>\n",
       "      <td>0.220853</td>\n",
       "      <td>0.038930</td>\n",
       "      <td>0.036019</td>\n",
       "      <td>0.175222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.866770</td>\n",
       "      <td>0.282479</td>\n",
       "      <td>0.950459</td>\n",
       "      <td>0.581622</td>\n",
       "      <td>0.436614</td>\n",
       "      <td>0.580089</td>\n",
       "      <td>0.516698</td>\n",
       "      <td>0.758776</td>\n",
       "      <td>0.282496</td>\n",
       "      <td>0.353050</td>\n",
       "      <td>0.894094</td>\n",
       "      <td>0.946457</td>\n",
       "      <td>0.892558</td>\n",
       "      <td>0.419448</td>\n",
       "      <td>0.780366</td>\n",
       "      <td>0.476336</td>\n",
       "      <td>0.497540</td>\n",
       "      <td>0.204680</td>\n",
       "      <td>0.591130</td>\n",
       "      <td>0.186136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.331565</td>\n",
       "      <td>0.855030</td>\n",
       "      <td>0.207076</td>\n",
       "      <td>0.071158</td>\n",
       "      <td>0.069008</td>\n",
       "      <td>0.940785</td>\n",
       "      <td>0.506920</td>\n",
       "      <td>0.409412</td>\n",
       "      <td>0.810879</td>\n",
       "      <td>0.835826</td>\n",
       "      <td>0.332191</td>\n",
       "      <td>0.693618</td>\n",
       "      <td>0.771123</td>\n",
       "      <td>0.654651</td>\n",
       "      <td>0.151595</td>\n",
       "      <td>0.875883</td>\n",
       "      <td>0.539095</td>\n",
       "      <td>0.282472</td>\n",
       "      <td>0.425228</td>\n",
       "      <td>0.037571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.127867</td>\n",
       "      <td>0.765547</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.416566</td>\n",
       "      <td>0.522510</td>\n",
       "      <td>0.054634</td>\n",
       "      <td>0.973078</td>\n",
       "      <td>0.226125</td>\n",
       "      <td>0.304199</td>\n",
       "      <td>0.303943</td>\n",
       "      <td>0.230417</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.729345</td>\n",
       "      <td>0.966845</td>\n",
       "      <td>0.224293</td>\n",
       "      <td>0.663047</td>\n",
       "      <td>0.741896</td>\n",
       "      <td>0.848425</td>\n",
       "      <td>0.422629</td>\n",
       "      <td>0.302931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.325295</td>\n",
       "      <td>0.712621</td>\n",
       "      <td>0.816779</td>\n",
       "      <td>0.181614</td>\n",
       "      <td>0.370941</td>\n",
       "      <td>0.901940</td>\n",
       "      <td>0.806694</td>\n",
       "      <td>0.984858</td>\n",
       "      <td>0.754248</td>\n",
       "      <td>0.393195</td>\n",
       "      <td>0.590638</td>\n",
       "      <td>0.661014</td>\n",
       "      <td>0.078456</td>\n",
       "      <td>0.544497</td>\n",
       "      <td>0.709321</td>\n",
       "      <td>0.167321</td>\n",
       "      <td>0.780632</td>\n",
       "      <td>0.583773</td>\n",
       "      <td>0.952222</td>\n",
       "      <td>0.042422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.265326</td>\n",
       "      <td>0.601554</td>\n",
       "      <td>0.296560</td>\n",
       "      <td>0.714424</td>\n",
       "      <td>0.759005</td>\n",
       "      <td>0.102516</td>\n",
       "      <td>0.513854</td>\n",
       "      <td>0.508891</td>\n",
       "      <td>0.369281</td>\n",
       "      <td>0.932925</td>\n",
       "      <td>0.827506</td>\n",
       "      <td>0.697209</td>\n",
       "      <td>0.714327</td>\n",
       "      <td>0.461716</td>\n",
       "      <td>0.920995</td>\n",
       "      <td>0.694595</td>\n",
       "      <td>0.728981</td>\n",
       "      <td>0.861691</td>\n",
       "      <td>0.274072</td>\n",
       "      <td>0.807071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.195241</td>\n",
       "      <td>0.345342</td>\n",
       "      <td>0.335610</td>\n",
       "      <td>0.978525</td>\n",
       "      <td>0.856537</td>\n",
       "      <td>0.701170</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.562073</td>\n",
       "      <td>0.947091</td>\n",
       "      <td>0.496259</td>\n",
       "      <td>0.380518</td>\n",
       "      <td>0.163035</td>\n",
       "      <td>0.786206</td>\n",
       "      <td>0.734444</td>\n",
       "      <td>0.384355</td>\n",
       "      <td>0.025193</td>\n",
       "      <td>0.838997</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.703700</td>\n",
       "      <td>0.970257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.437661</td>\n",
       "      <td>0.234973</td>\n",
       "      <td>0.704871</td>\n",
       "      <td>0.817128</td>\n",
       "      <td>0.546430</td>\n",
       "      <td>0.967035</td>\n",
       "      <td>0.051669</td>\n",
       "      <td>0.504796</td>\n",
       "      <td>0.718454</td>\n",
       "      <td>0.862640</td>\n",
       "      <td>0.179256</td>\n",
       "      <td>0.800003</td>\n",
       "      <td>0.552707</td>\n",
       "      <td>0.396554</td>\n",
       "      <td>0.131715</td>\n",
       "      <td>0.865296</td>\n",
       "      <td>0.157273</td>\n",
       "      <td>0.309788</td>\n",
       "      <td>0.290046</td>\n",
       "      <td>0.871414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92f04e2d-9b80-4fcc-86f0-432b40b67ab8')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-92f04e2d-9b80-4fcc-86f0-432b40b67ab8 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-92f04e2d-9b80-4fcc-86f0-432b40b67ab8');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "  <div id=\"id_a516709d-065b-4ae1-8068-9a8be7bce4a4\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_example')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_a516709d-065b-4ae1-8068-9a8be7bce4a4 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_example');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df_example",
       "summary": "{\n  \"name\": \"df_example\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"col_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3067795924675233,\n        \"min\": 0.011706610730904066,\n        \"max\": 0.9938483888996982,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7738796557301564,\n          0.04997902865967874,\n          0.6295576968917366\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3028777323507824,\n        \"min\": 0.007841590771916818,\n        \"max\": 0.9760138232792136,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.6019234310151316,\n          0.8436496640518237,\n          0.05433203482290383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3060620437537841,\n        \"min\": 1.1634755366141114e-05,\n        \"max\": 0.9811925291641158,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.8925232899548461,\n          0.9811925291641158,\n          0.7486452341262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2925790488150472,\n        \"min\": 0.016947664889580993,\n        \"max\": 0.9954375161913099,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.4433800143791877,\n          0.7931428739967394,\n          0.31758679526111666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2707940244123091,\n        \"min\": 0.00013469300448532007,\n        \"max\": 0.9841103190364978,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.607089578718754,\n          0.853784921704667,\n          0.00013469300448532007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30004722248432386,\n        \"min\": 0.019327630917601035,\n        \"max\": 0.9809873781626851,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.6313075530919887,\n          0.24197713031704537,\n          0.5111291392372298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30905752760242533,\n        \"min\": 0.046851908527603126,\n        \"max\": 0.9730781629723328,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.5916971623063255,\n          0.9606269755131998,\n          0.046851908527603126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2794998974084188,\n        \"min\": 0.0015651051914729042,\n        \"max\": 0.9848584027624758,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7026337730855163,\n          0.19692570445342839,\n          0.27616955782089947\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2638791782961371,\n        \"min\": 0.0088632851134689,\n        \"max\": 0.9880359661555919,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.23743346837480628,\n          0.9514298103618323,\n          0.7069764874557162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2872942402355997,\n        \"min\": 0.010131184027743378,\n        \"max\": 0.9978208556819782,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.5123637775457907,\n          0.994819293965951,\n          0.06268962162186587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2514535335700911,\n        \"min\": 0.03361360018328263,\n        \"max\": 0.8940943025332507,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.10422480280834767,\n          0.7117228057460487,\n          0.8393384923560023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33029756783064806,\n        \"min\": 0.001473822086311416,\n        \"max\": 0.9811437317918219,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.38451132764481255,\n          0.9811437317918219,\n          0.003819922658583108\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27833433367399957,\n        \"min\": 0.004363269650309087,\n        \"max\": 0.9840131632104643,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.4876670686212644,\n          0.5695397795671037,\n          0.24682386920190225\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2851762682804897,\n        \"min\": 0.014315277667059978,\n        \"max\": 0.9720053296315371,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.6522242595454725,\n          0.25954178317609033,\n          0.7409040561520714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3065993159614401,\n        \"min\": 0.0013536257154681541,\n        \"max\": 0.9928168389990704,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.9505310525862035,\n          0.43699588566562086,\n          0.3162701497293068\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2788258272256641,\n        \"min\": 0.0076640326492253275,\n        \"max\": 0.9640174071177023,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.6006510665483559,\n          0.593560935378786,\n          0.10189238806601353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28217348631680766,\n        \"min\": 0.01911609442976403,\n        \"max\": 0.993255015422964,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7435939161765598,\n          0.07308156202701499,\n          0.3602339188004279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_17\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29418807515005835,\n        \"min\": 0.011417983454073632,\n        \"max\": 0.9741944438163571,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.5062660594952028,\n          0.6223432646172461,\n          0.27039328638452553\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31039820193146345,\n        \"min\": 0.009038469079292177,\n        \"max\": 0.9849896561408751,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.6341040313763313,\n          0.9811778367622945,\n          0.8427119021605549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_19\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2738924169696387,\n        \"min\": 0.023594964645529126,\n        \"max\": 0.970257109726057,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.07093221613377343,\n          0.19010764978372763,\n          0.31334791758514313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Displaying first 10 rows to illustrate row handling (if max_rows < actual rows):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0  0.261706  0.246979  0.906255  0.249546  0.271950  0.759398  0.449740   \n",
       "1  0.963394  0.560168  0.936822  0.052258  0.418793  0.260158  0.730821   \n",
       "2  0.850616  0.561223  0.523391  0.114769  0.860140  0.722814  0.067668   \n",
       "3  0.062273  0.512503  0.806404  0.459240  0.051957  0.786278  0.201364   \n",
       "4  0.027167  0.065205  0.463931  0.909220  0.538702  0.497813  0.105474   \n",
       "5  0.915090  0.533029  0.157955  0.695899  0.793261  0.316762  0.857179   \n",
       "6  0.803604  0.505207  0.967127  0.417761  0.984110  0.667920  0.634671   \n",
       "7  0.819064  0.540794  0.710243  0.314350  0.471168  0.821637  0.459265   \n",
       "8  0.651148  0.620929  0.352375  0.841448  0.471287  0.979105  0.634142   \n",
       "9  0.305311  0.212644  0.033189  0.303946  0.653163  0.938305  0.871204   \n",
       "\n",
       "      col_7     col_8     col_9    col_10    col_11    col_12    col_13  \\\n",
       "0  0.776711  0.065366  0.487571  0.033614  0.062653  0.906437  0.139245   \n",
       "1  0.981297  0.256530  0.654175  0.198098  0.565330  0.463932  0.972005   \n",
       "2  0.707835  0.543538  0.081725  0.458301  0.484696  0.165775  0.945698   \n",
       "3  0.258621  0.164706  0.330215  0.756752  0.519386  0.204881  0.877830   \n",
       "4  0.656780  0.822103  0.380420  0.775612  0.964477  0.203766  0.523330   \n",
       "5  0.906143  0.276904  0.983521  0.140712  0.202016  0.184225  0.893990   \n",
       "6  0.165955  0.881928  0.427490  0.162233  0.012608  0.559756  0.527400   \n",
       "7  0.357798  0.494212  0.828249  0.335208  0.173762  0.712014  0.825978   \n",
       "8  0.126265  0.676178  0.325104  0.686327  0.069641  0.174881  0.855737   \n",
       "9  0.766065  0.788447  0.664985  0.260287  0.907195  0.670732  0.560441   \n",
       "\n",
       "     col_14    col_15    col_16    col_17    col_18    col_19  \n",
       "0  0.532421  0.411096  0.347343  0.899833  0.021823  0.663790  \n",
       "1  0.608527  0.349506  0.114096  0.151247  0.225317  0.250967  \n",
       "2  0.849975  0.669022  0.462296  0.411766  0.650973  0.545432  \n",
       "3  0.879582  0.870578  0.238796  0.451239  0.984990  0.772012  \n",
       "4  0.287138  0.792854  0.577593  0.634582  0.797914  0.395970  \n",
       "5  0.654293  0.152104  0.440323  0.615298  0.083464  0.882416  \n",
       "6  0.719354  0.890258  0.079407  0.731496  0.187412  0.858177  \n",
       "7  0.100637  0.239874  0.141972  0.347941  0.450351  0.748826  \n",
       "8  0.227180  0.837041  0.279276  0.642882  0.694151  0.512655  \n",
       "9  0.110989  0.447056  0.460358  0.864564  0.546648  0.380401  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-aead0e99-7091-42c5-b5c2-1355742bbb20\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_17</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.261706</td>\n",
       "      <td>0.246979</td>\n",
       "      <td>0.906255</td>\n",
       "      <td>0.249546</td>\n",
       "      <td>0.271950</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>0.449740</td>\n",
       "      <td>0.776711</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>0.487571</td>\n",
       "      <td>0.033614</td>\n",
       "      <td>0.062653</td>\n",
       "      <td>0.906437</td>\n",
       "      <td>0.139245</td>\n",
       "      <td>0.532421</td>\n",
       "      <td>0.411096</td>\n",
       "      <td>0.347343</td>\n",
       "      <td>0.899833</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>0.663790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963394</td>\n",
       "      <td>0.560168</td>\n",
       "      <td>0.936822</td>\n",
       "      <td>0.052258</td>\n",
       "      <td>0.418793</td>\n",
       "      <td>0.260158</td>\n",
       "      <td>0.730821</td>\n",
       "      <td>0.981297</td>\n",
       "      <td>0.256530</td>\n",
       "      <td>0.654175</td>\n",
       "      <td>0.198098</td>\n",
       "      <td>0.565330</td>\n",
       "      <td>0.463932</td>\n",
       "      <td>0.972005</td>\n",
       "      <td>0.608527</td>\n",
       "      <td>0.349506</td>\n",
       "      <td>0.114096</td>\n",
       "      <td>0.151247</td>\n",
       "      <td>0.225317</td>\n",
       "      <td>0.250967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850616</td>\n",
       "      <td>0.561223</td>\n",
       "      <td>0.523391</td>\n",
       "      <td>0.114769</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>0.067668</td>\n",
       "      <td>0.707835</td>\n",
       "      <td>0.543538</td>\n",
       "      <td>0.081725</td>\n",
       "      <td>0.458301</td>\n",
       "      <td>0.484696</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.945698</td>\n",
       "      <td>0.849975</td>\n",
       "      <td>0.669022</td>\n",
       "      <td>0.462296</td>\n",
       "      <td>0.411766</td>\n",
       "      <td>0.650973</td>\n",
       "      <td>0.545432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062273</td>\n",
       "      <td>0.512503</td>\n",
       "      <td>0.806404</td>\n",
       "      <td>0.459240</td>\n",
       "      <td>0.051957</td>\n",
       "      <td>0.786278</td>\n",
       "      <td>0.201364</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.330215</td>\n",
       "      <td>0.756752</td>\n",
       "      <td>0.519386</td>\n",
       "      <td>0.204881</td>\n",
       "      <td>0.877830</td>\n",
       "      <td>0.879582</td>\n",
       "      <td>0.870578</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.451239</td>\n",
       "      <td>0.984990</td>\n",
       "      <td>0.772012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027167</td>\n",
       "      <td>0.065205</td>\n",
       "      <td>0.463931</td>\n",
       "      <td>0.909220</td>\n",
       "      <td>0.538702</td>\n",
       "      <td>0.497813</td>\n",
       "      <td>0.105474</td>\n",
       "      <td>0.656780</td>\n",
       "      <td>0.822103</td>\n",
       "      <td>0.380420</td>\n",
       "      <td>0.775612</td>\n",
       "      <td>0.964477</td>\n",
       "      <td>0.203766</td>\n",
       "      <td>0.523330</td>\n",
       "      <td>0.287138</td>\n",
       "      <td>0.792854</td>\n",
       "      <td>0.577593</td>\n",
       "      <td>0.634582</td>\n",
       "      <td>0.797914</td>\n",
       "      <td>0.395970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.533029</td>\n",
       "      <td>0.157955</td>\n",
       "      <td>0.695899</td>\n",
       "      <td>0.793261</td>\n",
       "      <td>0.316762</td>\n",
       "      <td>0.857179</td>\n",
       "      <td>0.906143</td>\n",
       "      <td>0.276904</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>0.140712</td>\n",
       "      <td>0.202016</td>\n",
       "      <td>0.184225</td>\n",
       "      <td>0.893990</td>\n",
       "      <td>0.654293</td>\n",
       "      <td>0.152104</td>\n",
       "      <td>0.440323</td>\n",
       "      <td>0.615298</td>\n",
       "      <td>0.083464</td>\n",
       "      <td>0.882416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.803604</td>\n",
       "      <td>0.505207</td>\n",
       "      <td>0.967127</td>\n",
       "      <td>0.417761</td>\n",
       "      <td>0.984110</td>\n",
       "      <td>0.667920</td>\n",
       "      <td>0.634671</td>\n",
       "      <td>0.165955</td>\n",
       "      <td>0.881928</td>\n",
       "      <td>0.427490</td>\n",
       "      <td>0.162233</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>0.559756</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.719354</td>\n",
       "      <td>0.890258</td>\n",
       "      <td>0.079407</td>\n",
       "      <td>0.731496</td>\n",
       "      <td>0.187412</td>\n",
       "      <td>0.858177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.819064</td>\n",
       "      <td>0.540794</td>\n",
       "      <td>0.710243</td>\n",
       "      <td>0.314350</td>\n",
       "      <td>0.471168</td>\n",
       "      <td>0.821637</td>\n",
       "      <td>0.459265</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>0.828249</td>\n",
       "      <td>0.335208</td>\n",
       "      <td>0.173762</td>\n",
       "      <td>0.712014</td>\n",
       "      <td>0.825978</td>\n",
       "      <td>0.100637</td>\n",
       "      <td>0.239874</td>\n",
       "      <td>0.141972</td>\n",
       "      <td>0.347941</td>\n",
       "      <td>0.450351</td>\n",
       "      <td>0.748826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.651148</td>\n",
       "      <td>0.620929</td>\n",
       "      <td>0.352375</td>\n",
       "      <td>0.841448</td>\n",
       "      <td>0.471287</td>\n",
       "      <td>0.979105</td>\n",
       "      <td>0.634142</td>\n",
       "      <td>0.126265</td>\n",
       "      <td>0.676178</td>\n",
       "      <td>0.325104</td>\n",
       "      <td>0.686327</td>\n",
       "      <td>0.069641</td>\n",
       "      <td>0.174881</td>\n",
       "      <td>0.855737</td>\n",
       "      <td>0.227180</td>\n",
       "      <td>0.837041</td>\n",
       "      <td>0.279276</td>\n",
       "      <td>0.642882</td>\n",
       "      <td>0.694151</td>\n",
       "      <td>0.512655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.212644</td>\n",
       "      <td>0.033189</td>\n",
       "      <td>0.303946</td>\n",
       "      <td>0.653163</td>\n",
       "      <td>0.938305</td>\n",
       "      <td>0.871204</td>\n",
       "      <td>0.766065</td>\n",
       "      <td>0.788447</td>\n",
       "      <td>0.664985</td>\n",
       "      <td>0.260287</td>\n",
       "      <td>0.907195</td>\n",
       "      <td>0.670732</td>\n",
       "      <td>0.560441</td>\n",
       "      <td>0.110989</td>\n",
       "      <td>0.447056</td>\n",
       "      <td>0.460358</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>0.546648</td>\n",
       "      <td>0.380401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aead0e99-7091-42c5-b5c2-1355742bbb20')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-aead0e99-7091-42c5-b5c2-1355742bbb20 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-aead0e99-7091-42c5-b5c2-1355742bbb20');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"display(df_example\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"col_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36410841677115063,\n        \"min\": 0.027167421225559818,\n        \"max\": 0.9633944342135504,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6511475848816741,\n          0.9633944342135504,\n          0.9150900684070432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1883971674231514,\n        \"min\": 0.06520459126049205,\n        \"max\": 0.6209285674784312,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6209285674784312,\n          0.5601681834618419,\n          0.53302886724614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33285532115086847,\n        \"min\": 0.03318935456242622,\n        \"max\": 0.9671266152591704,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.3523749466096544,\n          0.9368224620330918,\n          0.157954822835348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29329440330771067,\n        \"min\": 0.05225787928602377,\n        \"max\": 0.9092202058615602,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8414475530847599,\n          0.05225787928602377,\n          0.6958991181688025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28078227797162464,\n        \"min\": 0.05195657755426841,\n        \"max\": 0.9841103190364978,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.47128716739816456,\n          0.4187933190741614,\n          0.7932613504382544\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2442626130072491,\n        \"min\": 0.26015779096205116,\n        \"max\": 0.9791049380151545,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9791049380151545,\n          0.26015779096205116,\n          0.31676167706752667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29640361473038623,\n        \"min\": 0.06766836190000158,\n        \"max\": 0.871204482263052,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6341421382957368,\n          0.7308209649807298,\n          0.857179256998753\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31481852250129727,\n        \"min\": 0.12626474156450274,\n        \"max\": 0.9812970904972467,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.12626474156450274,\n          0.9812970904972467,\n          0.9061432547657664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2936505555914077,\n        \"min\": 0.06536615756438524,\n        \"max\": 0.881927758304644,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.676177562075434,\n          0.2565300624442478,\n          0.2769044873778089\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26748612676048505,\n        \"min\": 0.08172534574677826,\n        \"max\": 0.9835214727152221,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.325104015431699,\n          0.6541746014740745,\n          0.9835214727152221\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27335436938780777,\n        \"min\": 0.03361360018328263,\n        \"max\": 0.7756118509253275,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6863271966860974,\n          0.19809763275974013,\n          0.14071152804875842\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3476731227290184,\n        \"min\": 0.01260751997575904,\n        \"max\": 0.9644766539008116,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.06964114816240574,\n          0.5653302545716099,\n          0.20201566840248997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27474095298694623,\n        \"min\": 0.16577454016327575,\n        \"max\": 0.906437453344411,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.1748814371759594,\n          0.4639324866883362,\n          0.18422483923802613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2660786305126123,\n        \"min\": 0.13924537111759516,\n        \"max\": 0.9720053296315371,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8557372589057863,\n          0.9720053296315371,\n          0.8939897100078704\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29472926404709665,\n        \"min\": 0.10063747852353333,\n        \"max\": 0.8795818549515292,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.2271795570235149,\n          0.6085272726964666,\n          0.6542925523249619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2781149824938993,\n        \"min\": 0.15210428322227287,\n        \"max\": 0.8902580530178021,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.83704112524294,\n          0.3495063720868188,\n          0.15210428322227287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_16\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17042877675229803,\n        \"min\": 0.07940658464302952,\n        \"max\": 0.5775933658811575,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.27927608845441043,\n          0.11409578488793337,\n          0.440323418368349\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_17\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23492820556859495,\n        \"min\": 0.15124682873493456,\n        \"max\": 0.8998333456872725,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6428819100587077,\n          0.15124682873493456,\n          0.615298025069802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_18\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3251788638055551,\n        \"min\": 0.0218233967754895,\n        \"max\": 0.9849896561408751,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.694150573509831,\n          0.2253169299512351,\n          0.08346408498938329\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_19\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21717705725680783,\n        \"min\": 0.250966661340298,\n        \"max\": 0.8824163684073387,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5126547531450529,\n          0.250966661340298,\n          0.8824163684073387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31d16009"
   },
   "source": "### Explanation:\n\n*   `pd.set_option('display.max_columns', None)`: This tells pandas to display all columns, regardless of how many there are. If you want to limit it to a specific number, replace `None` with an integer (e.g., `50`).\n*   `pd.set_option('display.max_rows', 100)`: This sets the maximum number of rows to display to 100. If your DataFrame has more than 100 rows, it will still truncate, but if it has fewer, all rows will be shown. You can set this to `None` to display all rows without truncation, but be cautious with very large DataFrames as this can make your notebook very long.\n\nTo revert to pandas' default display settings, you can use `pd.reset_option('display.max_columns')` and `pd.reset_option('display.max_rows')`.",
   "id": "31d16009"
  },
  {
   "cell_type": "code",
   "source": [
    "df[sent_feature_cols].describe().T[['mean','std','min','max']]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ptOaJ6-UNanz",
    "outputId": "aaff67df-4386-4992-aa03-decea078d06a"
   },
   "id": "ptOaJ6-UNanz",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             mean       std      min        max\n",
       "article_count            7.424528  9.202480  1.00000  67.000000\n",
       "pos_count                3.265723  4.728885  0.00000  37.000000\n",
       "neg_count                1.602201  2.811214  0.00000  23.000000\n",
       "neu_count                2.556604  3.603359  0.00000  44.000000\n",
       "highrel_count            0.000000  0.000000  0.00000   0.000000\n",
       "...                           ...       ...      ...        ...\n",
       "sent_cov_pos_shock       0.062893  0.242962  0.00000   1.000000\n",
       "sent_cov_neg_shock       0.077044  0.266871  0.00000   1.000000\n",
       "article_count_z20        0.095133  1.015275 -1.36334   4.138936\n",
       "article_count_pos_shock  0.103774  0.305207  0.00000   1.000000\n",
       "article_count_neg_shock  0.000000  0.000000  0.00000   0.000000\n",
       "\n",
       "[127 rows x 4 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-ea029f69-e811-4f72-853c-7e25702cb680\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>article_count</th>\n",
       "      <td>7.424528</td>\n",
       "      <td>9.202480</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_count</th>\n",
       "      <td>3.265723</td>\n",
       "      <td>4.728885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_count</th>\n",
       "      <td>1.602201</td>\n",
       "      <td>2.811214</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neu_count</th>\n",
       "      <td>2.556604</td>\n",
       "      <td>3.603359</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highrel_count</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_cov_pos_shock</th>\n",
       "      <td>0.062893</td>\n",
       "      <td>0.242962</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_cov_neg_shock</th>\n",
       "      <td>0.077044</td>\n",
       "      <td>0.266871</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_count_z20</th>\n",
       "      <td>0.095133</td>\n",
       "      <td>1.015275</td>\n",
       "      <td>-1.36334</td>\n",
       "      <td>4.138936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_count_pos_shock</th>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.305207</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_count_neg_shock</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 4 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea029f69-e811-4f72-853c-7e25702cb680')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ea029f69-e811-4f72-853c-7e25702cb680 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ea029f69-e811-4f72-853c-7e25702cb680');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"df[sent_feature_cols]\",\n  \"rows\": 127,\n  \"fields\": [\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6335956771025035,\n        \"min\": 0.0,\n        \"max\": 7.4245283018867925,\n        \"num_unique_values\": 93,\n        \"samples\": [\n          0.4026406690616949,\n          0.18727720280333862,\n          0.8469254374504089\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8299377401187165,\n        \"min\": 0.0,\n        \"max\": 9.202479754686692,\n        \"num_unique_values\": 93,\n        \"samples\": [\n          0.292753550279884,\n          0.36880121155658085,\n          0.5512155312801889\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7203027367331652,\n        \"min\": -3.3335287199733488,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          -1.0295240931181573,\n          -3.3335287199733488,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.139051537506568,\n        \"min\": 0.0,\n        \"max\": 67.0,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          2.4000587815929135,\n          41.666666666666664,\n          61.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Merged rows:\", len(df))\n",
    "print(\"Date min/max:\", df[\"date\"].min(), df[\"date\"].max())\n",
    "print(\"Rows per year:\", df[\"date\"].dt.year.value_counts().sort_index().to_dict())\n",
    "\n",
    "# After masks are built:\n",
    "for name, mask in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    # part = df.loc[mask]\n",
    "    print(name, \"rows\", len(part),\n",
    "          \"date_min\", mask[\"date\"].min(),\n",
    "          \"date_max\", mask[\"date\"].max(),\n",
    "          \"pos_rate\", float(mask[label_col].mean()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOjlP2TNaz_q",
    "outputId": "4e3d67ac-8638-4389-fad0-60a3a26fc906"
   },
   "id": "OOjlP2TNaz_q",
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Merged rows: 636\n",
      "Date min/max: 2021-01-01 00:00:00 2023-09-07 00:00:00\n",
      "Rows per year: {2021: 243, 2022: 231, 2023: 162}\n",
      "train rows 162 date_min 2021-01-01 00:00:00 date_max 2021-12-31 00:00:00 pos_rate 0.5925925925925926\n",
      "val rows 162 date_min 2022-01-03 00:00:00 date_max 2022-12-30 00:00:00 pos_rate 0.49783549783549785\n",
      "test rows 162 date_min 2023-01-02 00:00:00 date_max 2023-09-07 00:00:00 pos_rate 0.5493827160493827\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e10a67",
   "metadata": {
    "id": "07e10a67"
   },
   "source": "## 6) Build feature matrix\nWe use only sentiment-derived features (daily aggregates + lags) keyed by (`symbol`, `date`).\nWe exclude:\n- keys: `symbol`, `date`\n- label column: `y_up_*d`\n"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "deb4c2a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deb4c2a6",
    "outputId": "56ff8eee-f1fb-40d3-f312-ef3d7d204939"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features: 6 | causal_only: False\n",
      "Train rows: 243 Val rows: 231 Test rows: 162\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = {'symbol','date', label_col}\n",
    "\n",
    "# If True, keep only features that are strictly \"past-only\" by construction\n",
    "# (lags/rolling/z/shock features computed from prior days). This avoids any same-day leakage.\n",
    "USE_CAUSAL_ONLY = False\n",
    "\n",
    "if USE_CAUSAL_ONLY:\n",
    "    X_cols = [\n",
    "        c for c in df.columns\n",
    "        if (c not in exclude_cols)\n",
    "        and (\n",
    "            (\"_lag_\" in c)\n",
    "            or (\"_roll_\" in c)\n",
    "            or (re.search(r\"_z\\d+$\", c) is not None)\n",
    "            or (c.endswith(\"_pos_shock\") or c.endswith(\"_neg_shock\"))\n",
    "        )\n",
    "    ]\n",
    "else:\n",
    "    X_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "MIN_SENT_FEATURES = [\n",
    "    \"polarity_wmean_lag_3\",\n",
    "    \"sent_cov_lag_3\",\n",
    "    \"imbalance_lag_3\",\n",
    "    \"article_count_lag_3\",\n",
    "    \"news_present_lag_3\",\n",
    "    \"highrel_ratio_lag_3\",   # optional but useful\n",
    "]\n",
    "\n",
    "X_cols = [c for c in X_cols if c in MIN_SENT_FEATURES]\n",
    "\n",
    "# Drop any remaining NaNs\n",
    "train_df = train_df.dropna(subset=X_cols + [label_col])\n",
    "val_df   = val_df.dropna(subset=X_cols + [label_col])\n",
    "test_df  = test_df.dropna(subset=X_cols + [label_col])\n",
    "\n",
    "X_train, y_train = train_df[X_cols], train_df[label_col]\n",
    "X_val, y_val     = val_df[X_cols], val_df[label_col]\n",
    "X_test, y_test   = test_df[X_cols], test_df[label_col]\n",
    "\n",
    "# float32 helps MLflow schema + memory\n",
    "X_train = X_train.astype('float32')\n",
    "X_val   = X_val.astype('float32')\n",
    "X_test  = X_test.astype('float32')\n",
    "\n",
    "print('Features:', len(X_cols), '| causal_only:', USE_CAUSAL_ONLY)\n",
    "print('Train rows:', len(X_train), 'Val rows:', len(X_val), 'Test rows:', len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_cols"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dh3KvDZFvucV",
    "outputId": "b2887a05-29b0-413e-e2e3-1ff6de068cdc"
   },
   "id": "Dh3KvDZFvucV",
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['article_count_lag_3',\n",
       " 'highrel_ratio_lag_3',\n",
       " 'polarity_wmean_lag_3',\n",
       " 'sent_cov_lag_3',\n",
       " 'imbalance_lag_3',\n",
       " 'news_present_lag_3']"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5f29f",
   "metadata": {
    "id": "abb5f29f"
   },
   "source": "## 7) Train sentiment expert (TrainCV on TRAIN, select via VAL)"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da01a4a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da01a4a6",
    "outputId": "4903142a-aeb2-4b8b-dad0-44dc05076b77"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLflow run: 61728aedf98f4db4a0d5094e9ea53537\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best TRAIN-CV params: {'clf__C': 0.1, 'clf__class_weight': 'balanced', 'clf__penalty': 'l1'}\n",
      "Best TRAIN-CV mean ROC-AUC: 0.5248066748066748\n",
      "\n",
      "Best VAL-selected params: {'clf__C': 0.001, 'clf__penalty': 'l2', 'clf__class_weight': 'balanced'}\n",
      "Best VAL ROC-AUC: 0.5281109445277362\n",
      "\n",
      "VAL (final model): {'val_final_accuracy': 0.5194805194805194, 'val_final_roc_auc': np.float64(0.5285607196401799), 'val_final_balanced_accuracy': np.float64(0.5197901049475262), 'val_final_mcc': np.float64(0.03999000374843818)}\n",
      "TEST: {'test_accuracy': 0.4506172839506173, 'test_roc_auc': np.float64(0.41195936586116666), 'test_balanced_accuracy': np.float64(0.44828382330306293), 'test_mcc': np.float64(-0.10299731308114696)}\n",
      "🏃 View run sentiment_lr_min6_lag3 at: https://dagshub.com/Roncool13/dissertation-mlflow.mlflow/#/experiments/1/runs/61728aedf98f4db4a0d5094e9ea53537\n",
      "🧪 View experiment at: https://dagshub.com/Roncool13/dissertation-mlflow.mlflow/#/experiments/1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Registered model 'sentiment_lr_baseline_tcs_2021_2023' already exists. Creating a new version of this model...\n",
      "2026/01/26 11:26:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: sentiment_lr_baseline_tcs_2021_2023, version 9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registered model version: 9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Created version '9' of model 'sentiment_lr_baseline_tcs_2021_2023'.\n"
     ]
    }
   ],
   "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import BaseCrossValidator\nfrom sklearn.metrics import accuracy_score, roc_auc_score, balanced_accuracy_score, matthews_corrcoef\nimport numpy as np\nimport pandas as pd\nfrom mlflow.models.signature import infer_signature\n\n# --- Multi-symbol CV: split by unique DATES (not by rows) ---\nclass DateGroupeddate-grouped split(BaseCrossValidator):\n    def __init__(self, dates, n_splits=5):\n        self.dates = pd.to_datetime(pd.Series(dates)).to_numpy()\n        self.n_splits = n_splits\n\n    def get_n_splits(self, X=None, y=None, groups=None):\n        return self.n_splits\n\n    def split(self, X, y=None, groups=None):\n        dates = self.dates\n        uniq = np.unique(dates)\n        uniq.sort()\n        # Create expanding-window splits on date buckets\n        edges = np.linspace(0, len(uniq), self.n_splits + 2, dtype=int)\n        for i in range(self.n_splits):\n            train_dates = uniq[:edges[i+1]]\n            val_dates   = uniq[edges[i+1]:edges[i+2]]\n            train_idx = np.where(np.isin(dates, train_dates))[0]\n            val_idx   = np.where(np.isin(dates, val_dates))[0]\n            yield train_idx, val_idx\n\n\n# Ensure no nested/active MLflow run\nif mlflow.active_run():\n    mlflow.end_run()\n\n# ---- Model + CV setup (CV only on TRAIN) ----\nbase_pipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('clf', LogisticRegression(max_iter=1500, solver='liblinear', random_state=SEED, class_weight='balanced'))\n])\n\nparam_grid = {\n    'clf__C': [0.001, 0.01, 0.1, 1.0, 10.0],\n    'clf__penalty': ['l1', 'l2'],\n    }\n\n# date-grouped split expects TRAIN data already time-ordered (we ensured in earlier cells)\ndates_train = train_df['date'].to_numpy()\ncv = DateGroupeddate-grouped split(dates=dates_train, n_splits=5)\n\ngrid = GridSearchCV(\n    estimator=base_pipe,\n    param_grid=param_grid,\n    scoring='roc_auc',\n    cv=cv,\n    n_jobs=-1,\n    verbose=1,\n    refit=False,  # IMPORTANT: we will pick using VAL, not CV refit\n    return_train_score=False\n)\n\nwith mlflow.start_run(run_name='sentiment_lr_multisym_min6_lag3') as run:\n    run_id = run.info.run_id\n    print('MLflow run:', run_id)\n    log_code_and_data_version()\n\n    # Multi-symbol diagnostics\n    mlflow.log_metric('n_symbols_train', int(train_df['symbol'].nunique()))\n    mlflow.log_metric('n_symbols_val', int(val_df['symbol'].nunique()))\n    mlflow.log_metric('n_symbols_test', int(test_df['symbol'].nunique()))\n\n    # ---- 1) GridSearch CV on TRAIN only ----\n    grid.fit(X_train, y_train)\n\n    # Log CV best (informational)\n    best_cv_idx = int(np.argmax(grid.cv_results_['mean_test_score']))\n    best_cv_params = grid.cv_results_['params'][best_cv_idx]\n    best_cv_score = float(grid.cv_results_['mean_test_score'][best_cv_idx])\n\n    mlflow.log_metric('traincv_best_mean_roc_auc', best_cv_score)\n    mlflow.log_params({f'traincv_best_{k}': v for k, v in best_cv_params.items()})\n\n    print('Best TRAIN-CV params:', best_cv_params)\n    print('Best TRAIN-CV mean ROC-AUC:', best_cv_score)\n\n    # ---- 2) Select final params using VAL ----\n    # Evaluate each candidate on VAL by refitting on full TRAIN\n    rows = []\n    for params in grid.cv_results_['params']:\n        m = Pipeline([\n            ('scaler', StandardScaler()),\n            ('clf', LogisticRegression(\n                max_iter=1500,\n                solver='liblinear',\n                random_state=SEED,\n                C=params['clf__C'],\n                penalty=params['clf__penalty'],\n                class_weight='balanced',\n            ))\n        ])\n        m.fit(X_train, y_train)\n        val_proba = m.predict_proba(X_val)[:, 1]\n        val_auc = roc_auc_score(y_val, val_proba)\n        rows.append({'val_roc_auc': float(val_auc), **params})\n\n    val_rank = pd.DataFrame(rows).sort_values('val_roc_auc', ascending=False).reset_index(drop=True)\n    best_val = val_rank.iloc[0].to_dict()\n\n    best_val_params = {k: best_val[k] for k in param_grid.keys()}\n    best_val_auc = float(best_val['val_roc_auc'])\n\n    mlflow.log_metric('valselect_best_roc_auc', best_val_auc)\n    mlflow.log_params({f'valselect_best_{k}': v for k, v in best_val_params.items()})\n\n    print('\\nBest VAL-selected params:', best_val_params)\n    print('Best VAL ROC-AUC:', best_val_auc)\n\n    # ---- 3) Refit final model on TRAIN+VAL with VAL-selected params ----\n    X_trval = pd.concat([X_train, X_val], axis=0)\n    y_trval = pd.concat([y_train, y_val], axis=0)\n\n    final_model = Pipeline([\n        ('scaler', StandardScaler()),\n        ('clf', LogisticRegression(\n            max_iter=1500,\n            solver='liblinear',\n            random_state=SEED,\n            C=best_val_params['clf__C'],\n            penalty=best_val_params['clf__penalty'],\n            class_weight='balanced',\n        ))\n    ])\n\n    final_model.fit(X_trval, y_trval)\n\n    # ---- 4) Evaluate on VAL and TEST (VAL reported for completeness; selection already done) ----\n    def eval_split(X, y, split_name):\n        proba = final_model.predict_proba(X)[:, 1]\n        pred = (proba >= 0.5).astype(int)\n        metrics = {\n            f'{split_name}_accuracy': accuracy_score(y, pred),\n            f'{split_name}_roc_auc': roc_auc_score(y, proba),\n            f'{split_name}_balanced_accuracy': balanced_accuracy_score(y, pred),\n            f'{split_name}_mcc': matthews_corrcoef(y, pred),\n        }\n        mlflow.log_metrics(metrics)\n        return metrics, proba\n\n    # Evaluate using the final model\n    val_metrics, val_proba = eval_split(X_val, y_val, 'val_final')\n    test_metrics, test_proba = eval_split(X_test, y_test, 'test')\n\n    print('\\nVAL (final model):', val_metrics)\n    print('TEST:', test_metrics)\n\n    # ---- Optional: Log top-10 VAL candidates table as artifact ----\n    topk = 10\n    out_csv = 'val_candidate_ranking_top10.csv'\n    val_rank.head(topk).to_csv(out_csv, index=False)\n    mlflow.log_artifact(out_csv, artifact_path='model_selection')\n\n\n    # ----- Log model with signature + input example -----\n    input_example = X_train.head(5)\n    proba_example = final_model.predict_proba(input_example)[:, 1]\n    signature = infer_signature(input_example, proba_example)\n\n    mlflow.sklearn.log_model(\n        sk_model=final_model,\n        artifact_path='model_final',\n        input_example=input_example,\n        signature=signature,\n    )\n\n    mlflow.set_tag('expert', 'sentiment')\n    mlflow.set_tag('baseline_name', 'sentiment_lr_multisym')\n    mlflow.set_tag('label_col', label_col)\n    mlflow.set_tag('selection_protocol', 'train_timeseries_cv_val_select_refit_trainval')\n\n# Register model\nresult = mlflow.register_model(\n    model_uri=f\"runs:/{run_id}/model_final\",\n    name='sentiment_lr_baseline_multisym'\n)\nprint('Registered model version:', result.version)\n"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc_permutation_summary(y_true, scores, n_perm=5000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    auc_obs = roc_auc_score(y_true, scores)\n",
    "\n",
    "    perm_aucs = np.empty(n_perm)\n",
    "    for i in range(n_perm):\n",
    "        y_perm = rng.permutation(y_true)\n",
    "        perm_aucs[i] = roc_auc_score(y_perm, scores)\n",
    "\n",
    "    summary = {\n",
    "        \"auc_observed\": auc_obs,\n",
    "        \"perm_auc_min\": float(np.min(perm_aucs)),\n",
    "        \"perm_auc_max\": float(np.max(perm_aucs)),\n",
    "        \"perm_auc_mean\": float(np.mean(perm_aucs)),\n",
    "        \"perm_auc_std\": float(np.std(perm_aucs, ddof=1)),\n",
    "        \"perm_auc_q025\": float(np.quantile(perm_aucs, 0.025)),\n",
    "        \"perm_auc_q975\": float(np.quantile(perm_aucs, 0.975)),\n",
    "    }\n",
    "\n",
    "    # p-values\n",
    "    summary[\"p_two_sided\"] = (\n",
    "        np.sum(np.abs(perm_aucs - 0.5) >= abs(auc_obs - 0.5)) + 1\n",
    "    ) / (n_perm + 1)\n",
    "\n",
    "    summary[\"p_greater_0p5\"] = (\n",
    "        np.sum(perm_aucs >= auc_obs) + 1\n",
    "    ) / (n_perm + 1)\n",
    "\n",
    "    summary[\"p_less_0p5\"] = (\n",
    "        np.sum(perm_aucs <= auc_obs) + 1\n",
    "    ) / (n_perm + 1)\n",
    "\n",
    "    return summary, perm_aucs"
   ],
   "metadata": {
    "id": "UU20S6aH_7q-"
   },
   "id": "UU20S6aH_7q-",
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "summary_p, perm_p = auc_permutation_summary(\n",
    "    y_test.to_numpy(), test_proba, n_perm=5000\n",
    ")\n",
    "\n",
    "summary_inv, perm_inv = auc_permutation_summary(\n",
    "    y_test.to_numpy(), 1 - test_proba, n_perm=5000\n",
    ")\n",
    "\n",
    "print(\"=== Using p ===\")\n",
    "for k, v in summary_p.items():\n",
    "    print(f\"{k:20s}: {v}\")\n",
    "\n",
    "print(\"\\n=== Using 1 - p ===\")\n",
    "for k, v in summary_inv.items():\n",
    "    print(f\"{k:20s}: {v}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OGnUAtA_-nQ",
    "outputId": "71645573-637a-4cd1-e66a-9ea1830695d4"
   },
   "id": "7OGnUAtA_-nQ",
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Using p ===\n",
      "auc_observed        : 0.41195936586116666\n",
      "perm_auc_min        : 0.36439895336309064\n",
      "perm_auc_max        : 0.6556872402647376\n",
      "perm_auc_mean       : 0.5020215176235185\n",
      "perm_auc_std        : 0.045330573307720945\n",
      "perm_auc_q025       : 0.4158784823764815\n",
      "perm_auc_q975       : 0.5916653840233953\n",
      "p_two_sided         : 0.05098980203959208\n",
      "p_greater_0p5       : 0.979004199160168\n",
      "p_less_0p5          : 0.021195760847830435\n",
      "\n",
      "=== Using 1 - p ===\n",
      "auc_observed        : 0.5880406341388335\n",
      "perm_auc_min        : 0.34431275973526243\n",
      "perm_auc_max        : 0.6356010466369095\n",
      "perm_auc_mean       : 0.4979784823764814\n",
      "perm_auc_std        : 0.04533057330772095\n",
      "perm_auc_q025       : 0.4083346159766046\n",
      "perm_auc_q975       : 0.5841215176235185\n",
      "p_two_sided         : 0.05118976204759048\n",
      "p_greater_0p5       : 0.021395720855828835\n",
      "p_less_0p5          : 0.979004199160168\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_p = roc_auc_score(y_test, test_proba)\n",
    "auc_inv = roc_auc_score(y_test, 1 - test_proba)   # equals 1 - auc_p (up to float noise)\n",
    "\n",
    "print(\"AUC(p):\", auc_p)\n",
    "print(\"AUC(1-p):\", auc_inv)\n",
    "print(\"AUC(p) + AUC(1-p):\", auc_p + auc_inv)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIcGECqP_PWB",
    "outputId": "bd0f72cc-b2f2-4777-b9df-5e525c62e42f"
   },
   "id": "JIcGECqP_PWB",
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AUC(p): 0.41195936586116666\n",
      "AUC(1-p): 0.5880406341388335\n",
      "AUC(p) + AUC(1-p): 1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0743e5",
   "metadata": {
    "id": "5f0743e5"
   },
   "source": "## 8) Visualizations (ROC curves)"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abf9e6c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "abf9e6c0",
    "outputId": "46719572-1b68-45fe-e0e5-7c5f9adc804f"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# ROC curves\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "RocCurveDisplay.from_predictions(y_val, val_proba, name='Val', ax=ax)\n",
    "RocCurveDisplay.from_predictions(y_test, test_proba, name='Test', ax=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}